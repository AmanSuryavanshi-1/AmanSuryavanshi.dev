{
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        3600,
        1568
      ],
      "id": "34b004fa-a214-4f49-b663-d515bdb0439b",
      "name": "When clicking 'Execute workflow'"
    },
    {
      "parameters": {
        "resource": "databasePage",
        "operation": "getAll",
        "databaseId": {
          "__rl": true,
          "value": "21a34bf1-f7e5-8035-b16f-d5ebf63a86a9",
          "mode": "list"
        },
        "returnAll": true,
        "filterType": "manual",
        "filters": {
          "conditions": [
            {
              "key": "Status|select",
              "condition": "equals",
              "selectValue": "Ready to Generate"
            }
          ]
        },
        "options": {
          "sort": {
            "sortValue": [
              {
                "key": "ManualOrder|number",
                "direction": "ascending"
              },
              {
                "key": "Priority|select",
                "direction": "ascending"
              },
              {
                "timestamp": true,
                "key": "created_time",
                "direction": "ascending"
              }
            ]
          }
        }
      },
      "id": "eef54904-25fa-4997-b59b-d71e8c88ffd1",
      "name": "Notion ‚Äì Get Ready Content",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2,
      "position": [
        3824,
        1568
      ],
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "leftValue": "={{ $input.all().length > 0 }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              },
              "id": "6855ced2-6ef0-4ea1-acd1-a9326c4b67f9"
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "983bb119-9296-4d4b-a80a-51a54222d4b2",
      "name": "Filter ‚Äì Has Content",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        4048,
        1568
      ]
    },
    {
      "parameters": {
        "jsCode": "// CONTENT SELECTION & PROFILE SETUP\nconst items = $input.all();\n\nif (!items || items.length === 0) {\n¬† console.log('‚ùå No content ready for processing');\n¬† return [];\n}\n\n// Get first item (priority + FIFO)\nconst item = items[0].json;\nconsole.log('üéØ Processing item:', item.id);\n\n// Enhanced property extraction with fallbacks\nconst getProperty = (obj, path, defaultValue = '') => {\n¬† const keys = path.split('.');\n¬† let result = obj;\n¬† for (const key of keys) {\n¬† ¬† if (result && typeof result === 'object' && key in result) {\n¬† ¬† ¬† result = result[key];\n¬† ¬† } else {\n¬† ¬† ¬† return defaultValue;\n¬† ¬† }\n¬† }\n¬† return result || defaultValue;\n};\n\nconst title = getProperty(item, 'properties.Content Pages.title.0.plain_text') || \n¬† ¬† ¬† ¬† ¬† ¬† ¬† getProperty(item, 'properties.title.title.0.plain_text') ||\n¬† ¬† ¬† ¬† ¬† ¬† ¬† getProperty(item, 'properties.Name.title.0.plain_text') ||\n¬† ¬† ¬† ¬† ¬† ¬† ¬† getProperty(item, 'name') || \n¬† ¬† ¬† ¬† ¬† ¬† ¬† 'Untitled Content';\n\nconst category = getProperty(item, 'properties.Category.select.name') || \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†'Learning';\n\nconst priority = getProperty(item, 'properties.Priority.select.name') || \n¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†'normal';\n\n// Complete user profile for authentic content\nconst userProfile = {\n¬† name: 'Aman Surya',\n¬† role: 'Fresh CS Graduate & AI/ML Enthusiast',\n¬† focus: 'Building with Next.js/React/n8n, seeking AI PM roles',\n¬† personality: 'Authentic, curious, growth-minded, detail-oriented',\n¬† expertise: ['JavaScript', 'React', 'Next.js', 'n8n', 'AI/ML', 'Automation', 'Product Management'],\n¬† audience: 'Tech community, AI enthusiasts, developers, PM aspirants',\n¬† timezone: 'Asia/Kolkata',\n¬† writing_style: {\n¬† ¬† twitter: 'Casual, engaging, thread-friendly, question-driven, community-focused',\n¬† ¬† linkedin: 'Professional, detailed, story-driven, insight-rich, career-focused'\n¬† },\n¬† content_goals: {\n¬† ¬† primary: 'Build technical credibility for AI PM roles',\n¬† ¬† secondary: 'Help fellow developers learn and grow',\n¬† ¬† engagement: 'Create genuine discussions and valuable connections'\n¬† }\n};\n\nconst sessionId = `session_${Date.now()}_${(item.id || '').toString().substring(0, 8)}`;\n\nreturn [{\n¬† json: {\n¬† ¬† id: item.id,\n¬† ¬† title: title,\n¬† ¬† category: category,\n¬† ¬† priority: priority,\n¬† ¬† sessionId: sessionId,\n¬† ¬† userProfile: userProfile,\n¬† ¬† processingStartTime: new Date().toISOString(),\n¬† ¬† remainingItems: items.length - 1,\n¬† ¬† originalId: item.id\n¬† }\n}];"
      },
      "id": "ec9834a5-60b4-4844-9bb4-3d1d13bd070f",
      "name": "Code ‚Äì Select Content & Profile",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4272,
        1568
      ]
    },
    {
      "parameters": {
        "resource": "databasePage",
        "operation": "update",
        "pageId": {
          "__rl": true,
          "value": "={{ $('Code ‚Äì Select Content & Profile').item.json.id }}",
          "mode": "id"
        },
        "propertiesUi": {
          "propertyValues": [
            {
              "key": "Status|select",
              "type": "select",
              "selectValue": "Generating"
            },
            {
              "key": "SessionID|rich_text",
              "richText": true,
              "text": {
                "text": [
                  {
                    "text": "={{ $('Code ‚Äì Select Content & Profile').item.json.sessionId }}",
                    "annotationUi": {}
                  }
                ]
              }
            },
            {
              "key": "Processing Started|date",
              "type": "date",
              "date": "={{ $('Code ‚Äì Select Content & Profile').item.json.processingStartTime }}"
            },
            {
              "key": "Notes|rich_text",
              "richText": true,
              "text": {
                "text": [
                  {
                    "text": "=üîÑ Processing started\\nSession: {{ $('Code ‚Äì Select Content & Profile').item.json.sessionId }}\\nPriority: {{ $('Code ‚Äì Select Content & Profile').item.json.priority }}\\nCategory: {{ $('Code ‚Äì Select Content & Profile').item.json.category }}\\nStarted: {{ new Date().toLocaleString('en-IN', {timeZone: 'Asia/Kolkata'}) }} IST",
                    "annotationUi": {}
                  }
                ]
              }
            }
          ]
        },
        "options": {}
      },
      "id": "0fa28304-e33c-425b-8485-ad8d565f581f",
      "name": "Notion ‚Äì Update to Processing",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2,
      "position": [
        4720,
        1568
      ],
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "resource": "block",
        "operation": "getAll",
        "blockId": {
          "__rl": true,
          "value": "={{ $json.id }}",
          "mode": "id"
        },
        "returnAll": true,
        "fetchNestedBlocks": true,
        "simplifyOutput": false
      },
      "id": "6008f8d7-90ac-40f5-b10c-b8b621a0d6dd",
      "name": "Notion ‚Äì Extract All Blocks",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        4944,
        1568
      ],
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// PRODUCTION-READY NOTION CONTENT EXTRACTION (V2 - FIXED OUTPUT)\n\ntry {\n  console.log('üîç Starting comprehensive content extraction...');\n  \n  const extractItems = $items('Notion ‚Äì Extract All Blocks');\n  if (!extractItems?.length) {\n    throw new Error('No blocks from Notion ‚Äì Extract All Blocks');\n  }\n  console.log(`üì• Processing ${extractItems.length} block items`);\n  \n  const allBlocks = extractItems.map(item => item.json);\n  const blockMap = new Map();\n  const topLevelBlocks = [];\n  \n  // Build hierarchical tree\n  allBlocks.forEach(block => {\n    blockMap.set(block.id, { ...block, children: [] });\n  });\n  \n  allBlocks.forEach(block => {\n    if (block.parent?.type === 'page_id') {\n      topLevelBlocks.push(blockMap.get(block.id));\n    } else if (block.parent?.type === 'block_id') {\n      const parent = blockMap.get(block.parent.block_id);\n      if (parent) {\n        parent.children.push(blockMap.get(block.id));\n      }\n    }\n  });\n  \n  console.log(`üå≥ Built tree with ${topLevelBlocks.length} top-level blocks`);\n  \n  // Text extraction helper\n  const extractText = (richTextArray) => {\n    if (!Array.isArray(richTextArray)) return '';\n    return richTextArray\n      .map(item => item.plain_text || item.text?.content || '')\n      .join('')\n      .trim();\n  };\n  \n  // Image processing helper\n  const processImage = (url, caption = '') => {\n    if (!url) return null;\n    try {\n      return {\n        url: url,\n        caption: caption,\n        alt_text: caption || 'Content image',\n        processing_needed: true\n      };\n    } catch {\n      return null;\n    }\n  };\n  \n  // Recursive block renderer\n  function renderBlock(block, level = 0) {\n    if (!block?.type) return { text: '', sections: [], images: [] };\n    \n    const indent = '  '.repeat(level);\n    const blockData = block[block.type] || {};\n    let content = '';\n    let sections = [];\n    let images = [];\n    let text = extractText(blockData?.rich_text || blockData?.text || []);\n    \n    switch (block.type) {\n      case 'heading_1':\n        content = `\\\\n# ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 1, title: text, content: '', id: block.id });\n        break;\n      case 'heading_2':\n        content = `\\\\n## ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 2, title: text, content: '', id: block.id });\n        break;\n      case 'heading_3':\n        content = `\\\\n### ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 3, title: text, content: '', id: block.id });\n        break;\n      case 'paragraph':\n        if (text) content = `${text}\\\\n\\\\n`;\n        break;\n      case 'bulleted_list_item':\n        if (text) content = `${indent}- ${text}\\\\n`;\n        break;\n      case 'numbered_list_item':\n        if (text) content = `${indent}1. ${text}\\\\n`;\n        break;\n      case 'toggle':\n        if (text) {\n          content = `\\\\n‚ñ∂Ô∏è ${text}\\\\n`;\n          sections.push({ level: 4, title: text, content: '', id: block.id, type: 'toggle' });\n        }\n        break;\n      case 'callout':\n        const icon = blockData?.icon?.emoji || 'üí°';\n        if (text) content = `\\\\n${icon} **${text}**\\\\n\\\\n`;\n        break;\n      case 'quote':\n        if (text) content = `\\\\n> ${text}\\\\n\\\\n`;\n        break;\n      case 'code':\n        const language = blockData?.language || 'text';\n        if (text) {\n          content = `\\\\n\\`\\`\\`${language}\\\\n${text}\\\\n\\`\\`\\`\\\\n\\\\n`;\n          sections.push({ level: 5, title: `Code: ${language}`, content: text, id: block.id, type: 'code' });\n        }\n        break;\n      case 'divider':\n        content = '\\\\n---\\\\n\\\\n';\n        break;\n      case 'image':\n        const imageUrl = blockData?.file?.url || blockData?.external?.url;\n        if (imageUrl) {\n          const processedImage = processImage(imageUrl, text);\n          if (processedImage) {\n            images.push(processedImage);\n            content = `\\\\n[üì∏ Image: ${text || 'Visual content'}]\\\\n\\\\n`;\n          }\n        }\n        break;\n      case 'video':\n        content = `\\\\n[üé• Video: ${text || 'Video content'}]\\\\n\\\\n`;\n        break;\n      case 'bookmark':\n        const bookmarkUrl = blockData?.url || '';\n        if (bookmarkUrl) content = `\\\\n[üîó ${text || bookmarkUrl}](${bookmarkUrl})\\\\n\\\\n`;\n        break;\n      default:\n        if (text) content = `${indent}${text}\\\\n\\\\n`;\n        break;\n    }\n    \n    // Process children recursively\n    if (block.children?.length) {\n      const childrenResult = block.children\n        .map(child => renderBlock(child, level + 1))\n        .reduce((acc, result) => {\n          acc.text += result.text;\n          acc.sections = acc.sections.concat(result.sections);\n          acc.images = acc.images.concat(result.images);\n          return acc;\n        }, { text: '', sections: [], images: [] });\n      \n      content += childrenResult.text;\n      sections = sections.concat(childrenResult.sections);\n      images = images.concat(childrenResult.images);\n    }\n    \n    return { text: content, sections: sections, images: images };\n  }\n  \n  // Process all blocks\n  const result = topLevelBlocks\n    .map(block => renderBlock(block))\n    .reduce((acc, blockResult) => {\n      acc.text += blockResult.text;\n      acc.sections = acc.sections.concat(blockResult.sections);\n      acc.images = acc.images.concat(blockResult.images);\n      return acc;\n    }, { text: '', sections: [], images: [] });\n  \n  // Clean up text\n  let fullText = result.text\n    .replace(/\\n{3,}/g, '\\n\\n')\n    .replace(/\\s+$/gm, '')\n    .trim();\n  \n  const stats = {\n    totalBlocks: allBlocks.length,\n    processedBlocks: topLevelBlocks.length,\n    characterCount: fullText.length,\n    wordCount: fullText.split(/\\s+/).filter(w => w.length > 0).length,\n    sections: result.sections.length,\n    images: result.images.length,\n    toggleSections: result.sections.filter(s => s.type === 'toggle').length,\n    codeSections: result.sections.filter(s => s.type === 'code').length\n  };\n  \n  console.log('‚úÖ Content extraction complete:', stats);\n  \n  // ‚≠ê KEY FIX: Wrap everything in 'sourceContent'\n  return [{\n    json: {\n      sourceContent: {\n        name: $('Notion ‚Äì Update to Processing').first().json.name,\n        categories: $('Notion ‚Äì Update to Processing').first().json.property_category,\n        fullText: fullText,\n        sections: result.sections,\n        images: result.images,\n        extractionStats: stats,\n        contentMetadata: {\n          totalSections: result.sections.length,\n          hasImages: result.images.length > 0,\n          hasCode: result.sections.some(s => s.type === 'code'),\n          hasToggles: result.sections.some(s => s.type === 'toggle'),\n          hasLists: fullText.includes('- ') || /^\\d+\\.\\s/m.test(fullText),\n          complexity: stats.wordCount > 800 ? 'high' : stats.wordCount > 400 ? 'medium' : 'low'\n        }\n      }\n    }\n  }];\n  \n} catch (error) {\n  console.error('‚ùå Content extraction failed:', error.message);\n  return [{\n    json: {\n      sourceContent: {\n        fullText: `Content extraction error: ${error.message}`,\n        sections: [],\n        images: [],\n        extractionStats: { error: true },\n        contentMetadata: { error: error.message }\n      }\n    }\n  }];\n}\n"
      },
      "id": "ab5258a3-2566-4910-833b-32a39bc76455",
      "name": "Code ‚Äì Extract & Process Content",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5168,
        1568
      ]
    },
    {
      "parameters": {
        "numberInputs": 4
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        7664,
        1440
      ],
      "id": "28779653-efde-4fc7-a4ee-4a96e75294ff",
      "name": "Merge2"
    },
    {
      "parameters": {
        "jsCode": "const items = $input.all();\n// Extract IDs, handling skipped platforms\nconst getIdOrNull = (item) => {\n  if (!item?.json) return null;\n  if (item.json.skipped) return null;\n  return item.json.id || null;\n};\nconst twitterId = getIdOrNull(items[0]);\nconst linkedinId = getIdOrNull(items[1]);\nconst blogId = getIdOrNull(items[2]);\nconst imageId = getIdOrNull(items[3]);\n// Log what was generated\nconsole.log('‚úì Twitter ID:', twitterId || 'SKIPPED');\nconsole.log('‚úì LinkedIn ID:', linkedinId || 'SKIPPED');\nconsole.log('‚úì Blog ID:', blogId || 'SKIPPED');\n// Only throw error if ALL platforms were skipped\nif (!twitterId && !linkedinId && !blogId) {\n  throw new Error('No platforms selected! At least one platform must be selected in Notion.');\n}\nreturn [{\n  json: {\n    Twitter_id: twitterId,\n    LinkedIn_id: linkedinId,\n    Blog_id: blogId,\n    Image_Tasklist_id: imageId,\n    // Pass through which platforms were selected\n    platformsSelected: {\n      twitter: !!twitterId,\n      linkedin: !!linkedinId,\n      blog: !!blogId\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        7888,
        1472
      ],
      "id": "a6944843-4483-4b1a-a744-b7c50c8b49fd",
      "name": "ID Structuring"
    },
    {
      "parameters": {
        "jsCode": "// Personal Brand Context - The Foundation\n// Handles: Toggle headings, nested sections, code blocks, variable lengths\nconst personalContext = {\n  // CORE IDENTITY\n  name: \"Aman Suryavanshi\",\n  primary_focus: \"AI Automation Developer | Full Stack Automation Developer\",\n  experience_type: \"Fresh CS Graduate | Project-based only (No Professional Experience)\",\n  \n  // LOCATION & AVAILABILITY (Corrected field, avoid duplicate)\n  location: \"Delhi/NCR + Remote (India & Global)\",\n  availability: \"Open to full-time, contract, freelance\",\n  \n  // TARGET POSITIONS (Primary focus for content positioning)\n  targetRoles: [\n    \"No-Code/Low-Code Developer\",\n    \"Automation Developer\", \n    \"Automation Specialist\",\n    \"Technical Product Coordinator\",\n    \"AI Developer\",\n    \"Automation Architect\",\n    \"Systems & Process Automation Engineer\",\n    \"AI Product Manager (after 1-2 years experience)\"\n  ],\n  \n  // TECH STACK (What makes you HIREABLE)\n  skills: {\n    frontend: [\"Next.js 14\", \"React.js\", \"TypeScript\", \"Tailwind CSS\"],\n    automation: [\"n8n Workflow Orchestration\", \"Cloudflare Tunnel\", \"AI Agent Dev\"],\n    aiml: [\"Python\", \"LLMs (Gemini, Claude, GPT)\", \"RAG\", \"LangChain\"],\n    integration: [\"RESTful APIs\", \"Webhooks\", \"Firebase\", \"Supabase\"],\n    systems: [\"Performance Optimization\", \"Modular Architecture\", \"Technical Docs\"]\n  },\n\n  // LIVE PROJECTS (Include in content when relevant)\n  projects: {\n    workflow_repo: {\n      name: \"N8N Workflows Repository\",\n      url: \"https://github.com/AmanSuryavanshi-1/N8N/tree/main/workflows\",\n      description: \"Centralized n8n workflow logic\"\n    },\n    aviators: {\n      name: \"Aviators Training Centre\",\n      url: \"https://github.com/AmanSuryavanshi-1/AviatorsTrainingCentre\",\n      tech: [\"Next.js\", \"Firebase\", \"n8n\"],\n      achievement: \"95+ Lighthouse score, 80% reduction in manual tasks, 3L+ revenue\"\n    },\n    build_in_public: {\n      name: \"Build-in-Public Automation\",\n      status: \"Ongoing\",\n      tech: [\"n8n\", \"AI/LLMs\", \"Notion API\", \"X/LinkedIn APIs\"],\n      goal: \"Multi-platform content distribution automation\"\n    },\n    efficiency_agent: {\n      name: \"Personal Efficiency Agent\",\n      status: \"Ongoing\",\n      tech: [\"n8n AI Agents\", \"Notion API\", \"Postgres Memory\"],\n      goal: \"AI task management & daily tracking\"\n    }\n  },\n\n  // SERVICES YOU OFFER (For client attraction)\n  services: [\n    \"NextJS website development (Lighthouse & SEO optimized)\",\n    \"Front-end Web Development\",\n    \"n8n workflow automation for businesses + Next JS frontend\",\n    \"API integration & backend systems\",\n    \"No-code/low-code developement/consulting\"\n  ],\n\n  // SOCIAL PROOF LINKS\n  socials: {\n    github: \"https://github.com/AmanSuryavanshi-1\",\n    linkedin: \"https://www.linkedin.com/in/amansuryavanshi-ai/\",\n    twitter: \"https://x.com/_AmanSurya\",\n    portfolio: \"https://amansuryavanshi-dev.vercel.app/\"\n  },\n\n  // CONTENT VOICE (How you sound)\n  voiceAttributes: [\n    \"Authentic & transparent (share real struggles + wins)\",\n    \"Detail-oriented with technical depth\",\n    \"Growth-minded (always learning)\",\n    \"Practical over theoretical\",\n    \"Builds in public\",\n    \"Helpful & community-focused\"\n  ],\n\n  // HIDDEN OBJECTIVES (guides content strategy but never stated explicitly)\n  hiddenGoals: {\n    primary: \"Get inbound job offers without applying\",\n    secondary: \"Attract freelance/contract clients organically\",\n    tertiary: \"Build reputation as automation expert\",\n    longTerm: \"Become go-to person for no-code/automation in network\"\n  }\n};\n\n// Main n8n code node logic\nconst incomingItems = $input.all();\n\n\n// INTELLIGENT CONTENT SUMMARIZATION (Cost-Optimized)\n// Limits to 2000 chars while preserving structure\n// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nfunction intelligentSummarize(sourceContent) {\n  if (!sourceContent) return { summary: \"No content available\", structure: \"empty\", wordCount: 0,complexity: \"unknown\" };\n\n  // Extract key structural elements\n  const { fullText, sections, extractionStats } = sourceContent;\n\n  let summary = \"\";\n  // Priority 1: Section headings (highest signal-to-noise ratio)\n  const sectionTitles = (sections || [])\n    .filter(s => s.title && s.title.length > 3) // Skip very short titles\n    .map(s => `‚Ä¢ ${s.title}`)\n    .slice(0, 12) // Max 12 headings\n    .join('\\n');\n  \n  if (sectionTitles) {\n    summary += \"**Key Sections:**\\n\" + sectionTitles + \"\\n\\n\";\n  }\n  \n  // Priority 2: First substantive section content (provides context)\n  if (sections && sections.length > 0) {\n    // Find first section with actual content (not just heading)\n    const contentSection = sections.find(s => \n      s.content && s.content.length > 50\n    );\n    \n    if (contentSection) {\n      summary += \"**Core Content Sample:**\\n\" \n        + contentSection.content.substring(0, 500)\n        .replace(/\\n+/g, ' ') // Remove line breaks for compactness\n        + \"...\\n\";\n    }\n  }\n  \n  // Priority 3: Fallback to fullText if sections are empty\n  if (!sections || sections.length === 0) {\n    summary = \"**Content Preview:**\\n\" + (fullText || \"\").substring(0, 1800) + \"...\";\n  }\n  \n  // Enforce strict 2000 char limit (API cost control)\n  summary = summary.substring(0, 2000);\n  \n  return {\n    summary,\n    structure: extractionStats?.hasToggles ? \"hierarchical\" : \"linear\",\n    wordCount: extractionStats?.wordCount || 0,\n    complexity: extractionStats?.complexity || \"unknown\",\n    sectionCount: sections?.length || 0,\n    hasCode: extractionStats?.codeSections > 0,\n    hasToggles: extractionStats?.toggleSections > 0\n  };\n}\n\n// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n// PROCESS AND MERGE\n// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nreturn incomingItems.map(item => {\n  const sourceContent = item.json.sourceContent || {};\n  const contentSummary = intelligentSummarize(sourceContent);\n  \n  return {\n    json: {\n      // Preserve all original data from previous nodes\n      ...item.json,\n      // Added personal context\n      personalContext,\n      // Add optimized content summary for AI prompts\n      contentSummary, // This is what AI nodes will use\n      // Keep full sourceContent for reference if needed\n      _fullSourceContent: sourceContent\n    }\n  };\n});\n\n// INTELLIGENT NOTION CONTENT SUMMARIZATION (Cost-Optimized)\n// Limits to 2000 chars while preserving structure\n// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nfunction intelligentSummarize(sourceContent) {\n  if (!sourceContent) return { summary: \"\", structure: \"empty\" };\n  \n  // Extract key structural elements\n  const { fullText, sections, extractionStats } = sourceContent;\n  \n  // Priority 1: Section headings (most informative)\n  let summary = \"\";\n  const sectionTitles = (sections || [])\n    .filter(s => s.title && s.title.length > 0)\n    .map(s => `‚Ä¢ ${s.title}`)\n    .slice(0, 10) // Max 10 headings\n    .join('\\n');\n  \n  if (sectionTitles) {\n    summary += \"**Key Sections:**\\n\" + sectionTitles + \"\\n\\n\";\n  }\n  \n  // Priority 2: First substantive content (context)\n  if (sections && sections.length > 0) {\n    const firstContentSection = sections.find(s => s.content && s.content.length > 100);\n    if (firstContentSection) {\n      summary += \"**Core Content:**\\n\" + firstContentSection.content.substring(0, 600) + \"...\\n\";\n    }\n  }\n  \n  // Priority 3: Full text truncation if sections unavailable\n  if (!sections || sections.length === 0) {\n    summary = \"**Content Preview:**\\n\" + (fullText || \"\").substring(0, 1500) + \"...\";\n  }\n  \n  // Enforce 2000 char limit\n  summary = summary.substring(0, 2000);\n  \n  return {\n    summary,\n    structure: extractionStats?.hasToggles ? \"hierarchical\" : \"linear\",\n    wordCount: extractionStats?.wordCount || 0,\n    complexity: extractionStats?.complexity || \"unknown\"\n  };\n}\n\n// PROCESS AND MERGE\nreturn incomingItems.map(item => {\n  const sourceContent = item.json.sourceContent || {};\n  const contentSummary = intelligentSummarize(sourceContent);\n  \n  return {\n    json: {\n      ...item.json,\n      personalContext,\n      contentSummary, // This is what AI nodes will use\n      // Keep full sourceContent for reference\n      _fullSourceContent: sourceContent\n    }\n  };\n});\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5392,
        1568
      ],
      "id": "a636cf45-5f8f-409e-a046-238071c3332d",
      "name": "Code ‚Äì Personal Context Builder"
    },
    {
      "parameters": {
        "jsCode": "// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// CONTEXT MERGER (fetches from previous node, merges with Perplexity)\n// Place after Perplexity node, queries previous (Personal Context Builder) node\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nconsole.log('üîó Starting final context merger...');\n\n// 1. Fetch JSON data from the previous Personal Context Builder node\n// const previous = $('Code ‚Äì Personal Context Builder').first().json || {};\nconst previous = $('Code ‚Äì Personal Context Builder').first().json;\n\n// 2. Get Perplexity output directly ‚Äì comes as $json in this node\n// const perplexity = $json || {};\nconst perplexity = $json;\n\n// 3. Merge key blocks: always prefer Perplexity for \"research\", but get everything else from previous\n// const personalContext = previous.personalContext || {};\nconst personalContext = previous.personalContext;\nconst sourceContent = previous.sourceContent || {};\nconst contentSummary = previous.contentSummary || {};\nconst perplexityChoices = perplexity.choices;\n\n// Use fallback/default for every key field!\nconst name = personalContext.name || 'Unknown User';\nconst title = sourceContent.name || 'Untitled Content';\nconst categories = Array.isArray(sourceContent.categories) ? sourceContent.categories : ['General'];\nconst primaryCategory = categories[0] || 'General';\nconst summary = contentSummary.summary || '';\nconst wordCount = contentSummary.wordCount || 0;\nconst structure = contentSummary.structure || 'linear';\nconst complexity = contentSummary.complexity || 'unknown';\nconst fullText = sourceContent.fullText || '';\n\n// Perplexity research block‚Äîparse its result\nlet research = {};\ntry {\n  if (\n    Array.isArray(perplexityChoices) &&\n    perplexityChoices.length > 0 &&\n    typeof perplexityChoices[0] === 'object'\n  ) {\n    let rawContent = perplexityChoices[0].message?.content ?? '';\n    rawContent = rawContent.replace(/``````/g, '').trim();\n    if (rawContent) {\n      research = JSON.parse(rawContent);\n      console.log('‚úÖ Parsed Perplexity JSON.');\n    } else {\n      throw new Error('Empty content in Perplexity choices.');\n    }\n  } else {\n    throw new Error('Perplexity choices incomplete.');\n  }\n} catch (err) {\n  console.warn(`‚ö†Ô∏è Perplexity parsing failed: ${err.message}. Using fallback research.`);\n  research = {\n    authenticHashtags: {\n      twitter: ['#BuildInPublic', `#${primaryCategory}`, '#Automation', '#NoCode', '#n8n'],\n      linkedin: ['#ProcessAutomation', `#${primaryCategory}`, '#SystemsThinking', '#AI'],\n    },\n    optimalTimesIST: {\n      twitter_primary_ist: \"9:00-11:00 am IST\",\n      twitter_secondary_ist: \"8:30-9:30 pm IST (US/EU overlap)\",\n      linkedin_ist: \"10:00-12:00 am IST (Tue-Thu)\"\n    },\n    authenticHooks: {\n      twitter_example: \"Solving a weird API quirk in n8n today‚Äîhere's the step that finally worked. Anyone else get stuck on webhook reliability?\",\n      linkedin_example: \"Client automated 50% manual onboarding steps using n8n, saving 10 hours/week. Why did we choose modular flows?\"\n    },\n    developerPainPoints: [\n      \"Lack of reliable content scheduling tools for Indian time zones\",\n      \"Complicated OAuth flows between LinkedIn, X and custom APIs\"\n    ]\n  };\n}\n\n// Optional IDs/session info\nconst originalId = previous.originalId ?? null;\nconst sessionId = previous.sessionId ?? null;\nconst notionPageId = sourceContent.id ?? null;\nconst extractionStats = sourceContent.extractionStats ?? {};\nconst hasImages = Array.isArray(sourceContent.images) && sourceContent.images.length > 0;\nconst processingTime = new Date().toISOString();\n\n// Master context object (robust, merged)\nconst masterContext = {\n  personalContext: {\n    ...personalContext,\n    name\n  },\n  sourceContent: {\n    title,\n    categories,\n    primaryCategory,\n    summary,\n    wordCount,\n    structure,\n    complexity,\n    fullText\n  },\n  contentSummary: {\n    summary,\n    wordCount,\n    structure,\n    complexity\n  },\n  research,\n  originalId,\n  sessionId,\n  workflowMetadata: {\n    notionPageId,\n    extractionStats,\n    hasImages,\n    processingTime\n  }\n};\n\nconsole.log('‚úÖ Master context object created successfully!');\nreturn [{ json: masterContext }];\n"
      },
      "id": "2cf67ac3-185e-46e8-9fe1-c89274771f73",
      "name": "Code ‚Äì CONTEXT MERGER",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        5840,
        1568
      ]
    },
    {
      "parameters": {
        "jsCode": "// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// PROCESS & FORMAT TWITTER DRAFT (PRODUCTION-READY v4.0)\n// Handles: Gemini, OpenAI, Claude, Groq, OpenRouter, GitHub Models, etc.\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nconst input = $input.first().json;\nlet rawText = null;\n\nconsole.log('üê¶ Twitter Draft Processor - Starting...');\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 1: UNIVERSAL TEXT EXTRACTION\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nif (input.choices?.[0]?.message?.content) {\n    rawText = input.choices[0].message.content;\n} else if (input.content?.[0]?.text) {\n    rawText = input.content[0].text; // Claude\n} else if (input.content?.parts?.[0]?.text) {\n    rawText = input.content.parts[0].text; // Gemini\n} else if (input.candidates?.[0]?.content?.parts?.[0]?.text) {\n    rawText = input.candidates[0].content.parts[0].text; // Gemini alt\n} else if (input.output?.[0]?.content?.[0]?.text) {\n    rawText = input.output[0].content[0].text; // LangChain\n} else if (input.output && typeof input.output === 'string') {\n    rawText = input.output; // OpenRouter\n} else if (input.response && typeof input.response === 'string') {\n    rawText = input.response;\n} else if (input.message?.content) {\n    rawText = input.message.content;\n} else if (input.text && typeof input.text === 'string') {\n    rawText = input.text;\n} else if (typeof input === 'string') {\n    rawText = input;\n} else {\n    for (const key of Object.keys(input)) {\n        if (typeof input[key] === 'string' && input[key].length > 100) {\n            rawText = input[key];\n            break;\n        }\n    }\n}\n\nif (!rawText || rawText.trim().length === 0) {\n    throw new Error(`Cannot extract text. Keys: [${Object.keys(input).join(', ')}]`);\n}\n\nconsole.log(`üìä Raw text length: ${rawText.length}`);\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 2: YAML FRONT MATTER STRIPPING\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nlet cleanText = rawText.replace(/^---\\s*[\\s\\S]*?---\\s*/, '');\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 3: JSON EXTRACTION & REPAIR\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nlet cleaned = cleanText\n    .replace(/^```json\\s*/i, '').replace(/^```\\s*/i, '').replace(/```\\s*$/g, '').trim();\n\ncleaned = cleaned.replace(/,\\s*}/g, '}').replace(/,\\s*]/g, ']');\n\nlet result = {};\nlet parseSuccess = false;\n\nconst firstBrace = cleaned.indexOf('{');\nconst lastBrace = cleaned.lastIndexOf('}');\n\nif (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n    const jsonString = cleaned.substring(firstBrace, lastBrace + 1);\n    try {\n        result = JSON.parse(jsonString);\n        parseSuccess = true;\n        console.log('‚úÖ JSON parsed successfully');\n    } catch (e) {\n        console.log(`‚ö†Ô∏è JSON parse failed: ${e.message}. Attempting regex...`);\n        const mdMatch = cleaned.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?=(?<!\\\\)\"\\s*(,|}|]|$))/);\n        if (mdMatch) {\n            result.formatted_markdown = mdMatch[1].replace(/\\\\\"/g, '\"').replace(/\\\\n/g, '\\n').replace(/\\\\\\\\/g, '\\\\');\n            parseSuccess = true;\n        }\n    }\n}\n\nif (!parseSuccess) {\n    result.formatted_markdown = cleanText;\n    console.log('‚ö†Ô∏è Using stripped raw text as markdown');\n}\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 4: DATA EXTRACTION & IMAGE DETECTION\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// [EXISTING CODE WHERE 'markdown' IS DEFINED]\nlet markdown = (result.formatted_markdown || result.markdown || '').trim();\n// [PASTE THIS BLOCK BELOW IT]\n// 1. Unescape literal newlines\nmarkdown = markdown.replace(/\\\\n/g, '\\n').replace(/\\\\\"/g, '\"');\n// 2. Aggressively collapse multiple newlines (Max 2 = 1 blank line)\n// This fixes the \"large empty spaces\" issue\nmarkdown = markdown.replace(/\\n{3,}/g, '\\n\\n');\n// 3. Standardize Separators (Force exactly one blank line around ---)\nmarkdown = markdown.replace(/\\s*---\\s*/g, '\\n\\n---\\n\\n');\n\nconst structured = result.structured_data || result.structured || result;\n\nconst imageRegex = /<<IMAGE_(\\d+)>>/g;\nconst foundMarkers = [...markdown.matchAll(imageRegex)].map(m => m[0]);\nconst distinctMarkers = [...new Set(foundMarkers)];\n\nconst images = {\n    needed: distinctMarkers.length > 0,\n    count: distinctMarkers.length,\n    markers_found: distinctMarkers\n};\n\nconsole.log(`‚úÖ Twitter Processed. Images: ${images.count}`);\n\nreturn {\n    json: {\n        markdown: markdown,\n        structured: structured,\n        images: images,\n        platform: 'twitter'\n    }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        7216,
        896
      ],
      "id": "7ca9d7b9-2b60-46de-8d46-e4e9231221a2",
      "name": "Process & Format Twitter Draft"
    },
    {
      "parameters": {
        "jsCode": "// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// PROCESS & FORMAT LINKEDIN DRAFT (PRODUCTION-READY v5.0 - with Truncation Handling)\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nconst input = $input.first().json;\nlet rawText = null;\n\nconsole.log('üíº LinkedIn Draft Processor - Starting...');\n\n// Check for truncation FIRST\nconst finishReason = input.finishReason || input.finish_reason || '';\nif (finishReason === 'MAX_TOKENS' || finishReason === 'length') {\n    console.log('‚ö†Ô∏è WARNING: Response was truncated by MAX_TOKENS limit!');\n}\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 1: UNIVERSAL TEXT EXTRACTION\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nif (input.choices?.[0]?.message?.content) {\n    rawText = input.choices[0].message.content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawText = input.content.parts[0].text; // Gemini\n} else if (input.candidates?.[0]?.content?.parts?.[0]?.text) {\n    rawText = input.candidates[0].content.parts[0].text; // Gemini alt\n} else if (input.output?.[0]?.content?.[0]?.text) {\n    rawText = input.output[0].content[0].text; // LangChain\n} else if (input.output && typeof input.output === 'string') {\n    rawText = input.output;\n} else if (input.response && typeof input.response === 'string') {\n    rawText = input.response;\n} else if (input.message?.content) {\n    rawText = input.message.content;\n} else if (input.text && typeof input.text === 'string') {\n    rawText = input.text;\n} else if (typeof input === 'string') {\n    rawText = input;\n} else {\n    for (const key of Object.keys(input)) {\n        if (typeof input[key] === 'string' && input[key].length > 100) {\n            rawText = input[key];\n            break;\n        }\n    }\n}\n\nif (!rawText || rawText.trim().length === 0) {\n    throw new Error(`Cannot extract text. Keys: [${Object.keys(input).join(', ')}]`);\n}\n\nconsole.log(`üìä Raw text length: ${rawText.length}`);\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 2: YAML FRONT MATTER STRIPPING\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nlet cleanText = rawText.replace(/^---\\s*[\\s\\S]*?---\\s*/, '');\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 3: JSON EXTRACTION & REPAIR (with Truncation Handling)\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nlet cleaned = cleanText\n    .replace(/^```json\\s*/i, '').replace(/^```\\s*/i, '').replace(/```\\s*$/g, '').trim();\n\ncleaned = cleaned.replace(/,\\s*}/g, '}').replace(/,\\s*]/g, ']');\n\nlet result = {};\nlet parseSuccess = false;\nlet markdown = '';\n\nconst firstBrace = cleaned.indexOf('{');\nconst lastBrace = cleaned.lastIndexOf('}');\n\nif (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n    const jsonString = cleaned.substring(firstBrace, lastBrace + 1);\n    try {\n        result = JSON.parse(jsonString);\n        parseSuccess = true;\n        console.log('‚úÖ JSON parsed successfully');\n    } catch (e) {\n        console.log(`‚ö†Ô∏è JSON parse failed: ${e.message}. Attempting regex recovery...`);\n        \n        // ENHANCED REGEX: Extract formatted_markdown even if truncated\n        const mdMatch = cleaned.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n        if (mdMatch) {\n            markdown = mdMatch[1]\n                .replace(/\\\\\"/g, '\"')\n                .replace(/\\\\n/g, '\\n')\n                .replace(/\\\\\\\\/g, '\\\\');\n            parseSuccess = true;\n            console.log('‚úÖ Recovered markdown via regex (possibly truncated)');\n        }\n    }\n}\n\n// Get markdown from parsed JSON if not already set\nif (!markdown && result.formatted_markdown) {\n    markdown = result.formatted_markdown;\n}\n\n// Fallback: Use raw text\nif (!parseSuccess && !markdown) {\n    markdown = cleanText;\n    console.log('‚ö†Ô∏è Using stripped raw text as markdown');\n}\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 4: CLEAN MARKDOWN & DETECT IMAGES\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nmarkdown = markdown.replace(/^---\\s*[\\s\\S]*?---\\s*/, '').trim();\n// 1. [CRITICAL] Unescape literal newlines (Fixes Drive readability)\nmarkdown = markdown.replace(/\\\\n/g, '\\n').replace(/\\\\\"/g, '\"');\n// 2. Remove Metadata Header (Robustly handles newlines & variations)\nmarkdown = markdown.replace(/^#\\s*LinkedIn\\s*Draft[\\s\\S]*?---/i, '').trim();\nmarkdown = markdown.replace(/^#\\s*LinkedIn\\s*Draft/i, '').trim();\n// 3. Ensure consistent separator spacing (for Part 2 splitting)\nif (markdown.includes('---')) {\n    markdown = markdown.replace(/\\s*---\\s*/g, '\\n\\n---\\n\\n');\n}\n\nconst structured = result.structured_data || result.structured || result;\n\nconst imageRegex = /<<IMAGE_(\\d+)>>/g;\nconst foundMarkers = [...markdown.matchAll(imageRegex)].map(m => m[0]);\nconst distinctMarkers = [...new Set(foundMarkers)];\n\nconst images = {\n    needed: distinctMarkers.length > 0,\n    count: distinctMarkers.length,\n    markers_found: distinctMarkers\n};\n\n// Flag if content was truncated\nconst wasTruncated = finishReason === 'MAX_TOKENS' || finishReason === 'length';\n\nconsole.log(`‚úÖ LinkedIn Processed. Images: ${images.count}. Truncated: ${wasTruncated}`);\n\nreturn {\n    json: {\n        markdown: markdown,\n        structured: structured,\n        images: images,\n        platform: 'linkedin',\n        processing_stats: {\n            was_truncated: wasTruncated,\n            method: parseSuccess ? 'json' : 'fallback'\n        }\n    }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        7216,
        1280
      ],
      "id": "6828111d-07ff-4779-802a-48fb187d480d",
      "name": "Process & Format LinkedIn Draft"
    },
    {
      "parameters": {
        "resource": "folder",
        "name": "={{ $('Notion ‚Äì Get Ready Content').item.json.name }}-SocialDrafts-{{ $json.sessionId }}",
        "driveId": {
          "__rl": true,
          "mode": "list",
          "value": "My Drive"
        },
        "folderId": {
          "__rl": true,
          "value": "1F25H1IcOyYzJa41LwbD-r31_Ogs6ASZd",
          "mode": "list",
          "cachedResultName": "N8N Build in public Drafts - LinkedIn & X",
          "cachedResultUrl": "https://drive.google.com/drive/folders/1F25H1IcOyYzJa41LwbD-r31_Ogs6ASZd"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        4496,
        1568
      ],
      "id": "3199b02d-d2c2-4c1b-9cea-872272bf8946",
      "name": "Create folder for title",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "1hcyFpBqSOMDRDna",
          "name": "Google Drive Adude"
        }
      }
    },
    {
      "parameters": {
        "content": "Creating a separate folder in Drive to store all the assets & generated drafts",
        "height": 224,
        "width": 224
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        4432,
        1504
      ],
      "typeVersion": 1,
      "id": "9d3de995-099b-4a5e-9c87-9e27b5a0c0a2",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "content": "### 1. **Content Extraction** From Notion Database (4 nodes)\n",
        "height": 240,
        "width": 1536,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3552,
        1488
      ],
      "typeVersion": 1,
      "id": "b0424145-e67f-4970-abeb-19e2d61b23e1",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "content": "### 2. Notion Content Analysis & Processing (2 nodes)\n   - Content Extraction & processing - Code: Process & structure content\n   - Context Processing - Code: Personal context builder (user profile + summary)\n### 3. **Research Integration** (1 node)\n   - Perplexity API: Automated keyword research, hashtags, optimal posting times\n### 4. **Context Merging** (1 node)\n   - Code: Merge personal profile + source content + research into master context\n",
        "height": 208,
        "width": 1536,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        4784,
        1520
      ],
      "typeVersion": 1,
      "id": "bac34e09-e326-465e-88be-49c1991e2795",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "content": "## MULTI-LLM GENERATION -> Generating Content for LinkedIn, Twitter & Portfolio Blog website using Gemini\n### 5.**Multi-LLM Content Generation** (9 nodes - Parallel Execution)\n   - **Tier 1 (Primary)**: Gemini 2.5 Pro\n     * Twitter generation (280 char focus)\n     * LinkedIn generation (1500-2800 char range)\n     * Blog generation (2500+ words, SEO optimized)\n### 6.**Content Formatting** (6 nodes)\n   - Code: Rebuild Twitter (280 char limit, thread structure)\n   - Code: Rebuild LinkedIn (platform-specific formatting, 1 image max)\n   - Code: Rebuild Blog (Sanity CMS blocks, image embedding)\n   - Markdown validation for each platform\n\n### 7.**Image Task Generation** (2 nodes)\n   - Extract image placeholders from all drafts\n   - Generate image generation prompts for manual image generation\n\n### 8.**Storage & Linking** (2 nodes)\n   - Google Drive: Create session folder\n   - Google Drive: Save all drafts (Twitter, LinkedIn, Blog, Image manifest)\n\n### 9.**Notion Status Update** (1 node)\n   - Update Notion with draft URLs, set status to \"Pending Approval\"",
        "height": 1408,
        "width": 1552,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        6024,
        800
      ],
      "typeVersion": 1,
      "id": "a8046985-f260-415b-9710-c8c56800f017",
      "name": "Sticky Note5"
    },
    {
      "parameters": {
        "content": "## Updating Content to Notion \n",
        "height": 240,
        "width": 448,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        7824,
        1392
      ],
      "typeVersion": 1,
      "id": "a99c9f48-8e09-4bff-a77e-67a75a6b52c1",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "model": "sonar-pro",
        "messages": {
          "message": [
            {
              "content": "=<role>\nYou are a Senior Technical Market Intelligence Analyst. Your job is NOT to write content, but to find the \"Heat\" in the market. You act as the eyes and ears for Aman Suryavanshi, a Build-in-Public founder (Next.js/n8n/AI/no-code/low-code).\n</role>\n\n<instructions>\n1. **The \"Newsjack\" (Urgency)**\n   - Search for recent software updates (e.g., \"Next.js 15\", \"n8n v1.0\", \"Claude 3.5\") or industry news related to this topic.\n   - *Goal:* Find ONE specific event that makes this content timely. (e.g., \"This is relevant because Vercel just changed their caching policy\").\n\n2. **The \"Gap Analysis\" (The Void)**\n   - Search Reddit (r/webdev, r/selfhosted) and HackerNews.\n   - What question is everyone asking but getting bad answers for?\n   - Identify \"Contrarian Angles\": What is the common advice that is actually wrong/inefficient?\n\n3. **Technical Vibe Check**\n   - Find 2-3 specific technical keywords that are trending in this niche RIGHT NOW (e.g., don't just say \"AI\", say \"Agentic Loops\" or \"MCP Servers\").\n\n4. **Platform Intelligence**\n   - **Twitter:** Find a \"Village\" (group of devs) discussing this. What is their sentiment? (Excited? Angry? Confused?)\n   - **LinkedIn:** Find a \"Business Stat\" or \"Cost Argument\". (e.g., \"Manual API integrations cost devs 10hrs/week\").\n   - **Blog:** Find \"Zero-Volume, High-Intent\" keywords (e.g., \"fix n8n webhook timeout 502\").\n\n5. **Timing**\n   - Provide optimal posting times for Asia/Kolkata (IST).\n</instructions>\n\n<outputformat>\nReturn ONLY valid JSON with this EXACT structure (no markdown fences):\n\n{\n  \"market_pulse\": {\n    \"urgency_trigger\": \"The recent event/update that makes this relevant NOW.\",\n    \"community_sentiment\": \"What are devs feeling? (e.g., 'Frustrated with complex setups').\",\n    \"the_gap\": \"The specific unanswered question or bad advice you found.\"\n  },\n  \"twitter\": {\n    \"hashtags\": [\"#SpecificTag1\", \"#SpecificTag2\"],\n    \"optimal_posting_times_ist\": [\"09:00 AM\", \"06:00 PM\"],\n    \"hook_inspiration\": \"A specific angle based on the urgency_trigger.\"\n  },\n  \"linkedin\": {\n    \"hashtags\": [\"#SpecificTag1\", \"#SpecificTag2\"],\n    \"optimal_posting_times_ist\": [\"10:00 AM\", \"02:00 PM\"],\n    \"business_value_stat\": \"A specific data point or cost argument found in research.\"\n  },\n  \"blog\": {\n    \"seo_keywords_primary\": [\n      {\"keyword\": \"main topic\", \"volume\": \"high\"}\n    ],\n    \"seo_keywords_longtail\": [\n      {\"keyword\": \"very specific problem fix\", \"volume\": \"low\"}\n    ],\n    \"competitor_gap\": \"What technical detail is missing in current top articles?\"\n  }\n}\n</outputformat>\n\n<constraints>\n- Research MUST be from the last 14 days.\n- Do NOT return generic advice. If no specific news is found, focus on a specific \"Eternal Struggle\" (e.g., \"Dependency Hell\").\n- Output must be strict JSON.\n</constraints>\n",
              "role": "system"
            },
            {
              "content": "=<context>\n<profile>\n- primary_focus: {{ $json.personalContext.primary_focus }}\n- target_roles: {{$json.personalContext.targetRoles}}\n</profile>\n\n<topic>\n<name>{{$json.sourceContent.name}}</name>\n<categories>{{$json.sourceContent.categories}}</categories>\n<summary>{{$json.contentSummary.summary}}</summary>\n<date>{{ $now }}</date>\n</topic>\n</context>\n\n<task>\nConduct deep real-time research (last 14 days) to validate this topic. Find specific discussions, news, and technical arguments that make this topic urgent TODAY.\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.2,
          "searchRecency": "month"
        },
        "requestOptions": {}
      },
      "id": "3fb95f11-170f-4bd3-91ee-34e2f0a83c9d",
      "name": "Perplexity ‚Äì Research Hashtags & Timing",
      "type": "n8n-nodes-base.perplexity",
      "typeVersion": 1,
      "position": [
        5616,
        1568
      ],
      "credentials": {
        "perplexityApi": {
          "id": "Ss20gojfOfH1gtj7",
          "name": "Perplexity Anki"
        }
      }
    },
    {
      "parameters": {
        "operation": "createFromText",
        "content": "={{ $json.markdown }}",
        "name": "=LinkedIndraft-{{ $('Create folder for title').all()[0].json.name }}.md",
        "driveId": {
          "__rl": true,
          "mode": "list",
          "value": "My Drive"
        },
        "folderId": {
          "__rl": true,
          "value": "=https://drive.google.com/drive/u/2/folders/{{ $('Create folder for title').all()[0].json.id }}",
          "mode": "url"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        7440,
        1280
      ],
      "id": "134bf35b-54c4-4e28-8a1c-01885ce1a8fd",
      "name": "Create LinkedIn Draft",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "1hcyFpBqSOMDRDna",
          "name": "Google Drive Adude"
        }
      }
    },
    {
      "parameters": {
        "operation": "createFromText",
        "content": "={{ $json.markdown }}",
        "name": "=Twitterdraft-{{ $('Create folder for title').all()[0].json.name }}.md",
        "driveId": {
          "__rl": true,
          "value": "My Drive",
          "mode": "list",
          "cachedResultName": "My Drive",
          "cachedResultUrl": "https://drive.google.com/drive/my-drive"
        },
        "folderId": {
          "__rl": true,
          "value": "=https://drive.google.com/drive/u/2/folders/{{ $('Create folder for title').all()[0].json.id }}",
          "mode": "url"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        7440,
        896
      ],
      "id": "d69526fe-8309-4e11-95bb-180a729a2fb5",
      "name": "Create Twitter Draft",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "1hcyFpBqSOMDRDna",
          "name": "Google Drive Adude"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// PROCESS & FORMAT BLOG DRAFT (PRODUCTION-READY v4.0)\n// Handles: Gemini, OpenAI, Claude, Groq, OpenRouter, GitHub Models, etc.\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nconst input = $input.first().json;\nlet rawText = null;\n\nconsole.log('üìù Blog Draft Processor - Starting...');\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 1: UNIVERSAL TEXT EXTRACTION\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nif (input.choices?.[0]?.message?.content) {\n    rawText = input.choices[0].message.content;\n} else if (input.content?.[0]?.text) {\n    rawText = input.content[0].text; // Claude\n} else if (input.content?.parts?.[0]?.text) {\n    rawText = input.content.parts[0].text; // Gemini\n} else if (input.candidates?.[0]?.content?.parts?.[0]?.text) {\n    rawText = input.candidates[0].content.parts[0].text; // Gemini alt\n} else if (input.output?.[0]?.content?.[0]?.text) {\n    rawText = input.output[0].content[0].text; // LangChain\n} else if (input.output && typeof input.output === 'string') {\n    rawText = input.output; // OpenRouter\n} else if (input.response && typeof input.response === 'string') {\n    rawText = input.response;\n} else if (input.message?.content) {\n    rawText = input.message.content;\n} else if (input.text && typeof input.text === 'string') {\n    rawText = input.text;\n} else if (typeof input === 'string') {\n    rawText = input;\n} else {\n    for (const key of Object.keys(input)) {\n        if (typeof input[key] === 'string' && input[key].length > 100) {\n            rawText = input[key];\n            break;\n        }\n    }\n}\n\nif (!rawText || rawText.trim().length === 0) {\n    throw new Error(`Cannot extract text. Keys: [${Object.keys(input).join(', ')}]`);\n}\n\nconsole.log(`üìä Raw text length: ${rawText.length}`);\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 2: YAML FRONT MATTER STRIPPING\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nlet cleanText = rawText.replace(/^---\\s*[\\s\\S]*?---\\s*/, '');\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 3: JSON EXTRACTION & REPAIR\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nlet cleaned = cleanText\n    .replace(/^```json\\s*/i, '').replace(/^```\\s*/i, '').replace(/```\\s*$/g, '').trim();\n\ncleaned = cleaned.replace(/,\\s*}/g, '}').replace(/,\\s*]/g, ']');\n\nlet result = {};\nlet parseSuccess = false;\n\nconst firstBrace = cleaned.indexOf('{');\nconst lastBrace = cleaned.lastIndexOf('}');\n\nif (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n    const jsonString = cleaned.substring(firstBrace, lastBrace + 1);\n    try {\n        result = JSON.parse(jsonString);\n        parseSuccess = true;\n        console.log('‚úÖ JSON parsed successfully');\n    } catch (e) {\n        console.log(`‚ö†Ô∏è JSON parse failed: ${e.message}. Attempting regex...`);\n        const mdMatch = cleaned.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?=(?<!\\\\)\"\\s*(,|}|]|$))/);\n        if (mdMatch) {\n            result.formatted_markdown = mdMatch[1].replace(/\\\\\"/g, '\"').replace(/\\\\n/g, '\\n').replace(/\\\\\\\\/g, '\\\\');\n            parseSuccess = true;\n        }\n    }\n}\n\nif (!parseSuccess) {\n    result.formatted_markdown = cleanText;\n    console.log('‚ö†Ô∏è Using stripped raw text as markdown');\n}\n\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// STEP 4: DATA EXTRACTION & IMAGE DETECTION\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// [EXISTING CODE]\nlet markdown = (result.formatted_markdown || result.markdown || cleanText).trim();\n// [PASTE THIS BLOCK BELOW IT]\nmarkdown = markdown.replace(/\\\\n/g, '\\n').replace(/\\\\\"/g, '\"');\n\nconst structured = result.structured_data || result.structured || result;\nconst seo = structured.seo || {};\n\nconst imageRegex = /<<IMAGE_(\\d+)>>/g;\nconst foundMarkers = [...markdown.matchAll(imageRegex)].map(m => m[0]);\nconst distinctMarkers = [...new Set(foundMarkers)];\n\nconst images = {\n    needed: distinctMarkers.length > 0,\n    count: distinctMarkers.length,\n    markers_found: distinctMarkers,\n    prompts: structured.image_prompts || []\n};\n\nconst finalSeo = {\n    title: seo.title || (markdown.match(/^#\\s+(.+)$/m) || [])[1] || 'Untitled Draft',\n    slug: seo.slug || '',\n    metaDescription: seo.meta_description || seo.metaDescription || '',\n    keywords: seo.keywords || [],\n    tags: seo.tags || []\n};\n\nconst wordCount = markdown.split(/\\s+/).filter(w => w.length > 0).length;\nconsole.log(`‚úÖ Blog Processed: ${wordCount} words. Images: ${images.count}`);\n\nreturn {\n    json: {\n        markdown: markdown,\n        structured: structured,\n        seo: finalSeo,\n        images: images,\n        platform: 'blog',\n        processing_stats: {\n            method: parseSuccess ? 'json' : 'fallback',\n            images_detected: images.count,\n            yaml_stripped: rawText.length !== cleanText.length\n        }\n    }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        7216,
        1664
      ],
      "id": "5129f483-7ccc-49fd-890f-63b2c3a76527",
      "name": "Process & Format Blog Draft"
    },
    {
      "parameters": {
        "operation": "createFromText",
        "content": "={{ $json.markdown }}",
        "name": "=Blogdraft-{{ $('Create folder for title').all()[0].json.name }}.md",
        "driveId": {
          "__rl": true,
          "mode": "list",
          "value": "My Drive"
        },
        "folderId": {
          "__rl": true,
          "value": "=https://drive.google.com/drive/u/2/folders/{{ $('Create folder for title').all()[0].json.id }}",
          "mode": "url"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        7440,
        1664
      ],
      "id": "b485c559-0b49-4261-9859-f14241caf0ec",
      "name": "Create Blog Draft",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "1hcyFpBqSOMDRDna",
          "name": "Google Drive Adude"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// PROCESS AI STRATEGY & MERGE CONTEXT (V4 - FINAL, ROBUST JSON PARSING)\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nconsole.log('üìã V4: Starting robust JSON parsing...');\n// STEP 1: GET INPUTS FROM TWO DIFFERENT SOURCES\n// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nconst geminiRawOutput = $input.first().json;\nconst originalContext = $('Code ‚Äì CONTEXT MERGER').first().json;\n\nif (!geminiRawOutput) {\n  throw new Error('‚ùå No input from parent node (Gemini - AI CONTENT STRATEGIST).');\n}\nif (!originalContext) {\n  throw new Error(`‚ùå Could not find data from referenced node: \"$('Code ‚Äì CONTEXT MERGER')\". Please verify the name.`);\n}\nconsole.log('‚úÖ Successfully loaded data from parent and context nodes.');\n\n// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n// STEP 2: ROBUSTLY EXTRACT AND CLEAN JSON FROM GEMINI\n// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nlet strategy;\ntry {\n  let rawText = geminiRawOutput.content?.parts[0]?.text || '';\n  if (!rawText) {\n    throw new Error('Text content from Gemini is empty.');\n  }\n\n  // --- NEW ROBUST JSON EXTRACTION ---\n  // Find the first '{' and the last '}' to extract the JSON object,\n  // which is much more reliable than trying to strip markdown fences.\n  const firstBrace = rawText.indexOf('{');\n  const lastBrace = rawText.lastIndexOf('}');\n  \n  if (firstBrace === -1 || lastBrace === -1) {\n    throw new Error('Could not find a valid JSON object (missing \"{\" or \"}\").');\n  }\n\n  const jsonString = rawText.substring(firstBrace, lastBrace + 1);\n  // --- END OF NEW LOGIC ---\n\n  strategy = JSON.parse(jsonString);\n  console.log('‚úÖ Strategy parsed successfully using robust extraction.');\n\n} catch (error) {\n  console.error('‚ùå Strategy parsing failed:', error.message);\n  throw new Error(`Failed to parse Gemini strategy: ${error.message}`);\n}\n\n// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n// STEP 3: VALIDATE AND CREATE MASTER DATA OBJECT\n// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nconst requiredFields = ['strategy_summary', 'source_analysis', 'platform_strategies'];\nconst missingFields = requiredFields.filter(field => !strategy[field]);\n\nif (missingFields.length > 0) {\n  throw new Error(`Strategy object is missing required fields: ${missingFields.join(', ')}`);\n}\nconsole.log('‚úÖ Strategy structure validated.');\n\nconst masterData = {\n  personalContext: originalContext.personalContext,\n  sourceContent: originalContext.sourceContent,\n  research: originalContext.research,\n  workflowMetadata: originalContext.workflowMetadata,\n  strategy: strategy\n};\n\nconsole.log('‚úÖ Master data object created successfully.');\nconsole.log('üì¶ Final output contains keys:', Object.keys(masterData));\n\nreturn [{ json: masterData }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        6416,
        1568
      ],
      "id": "12833281-018c-4116-93cd-990d423ec605",
      "name": "Process AI Strategy & MERGE CONTEXT"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "e0a6bdb8-0521-4d53-a351-c2ec3f05310e",
              "leftValue": "={{ $json.strategy.image_strategy.needs_images }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        6928,
        2048
      ],
      "id": "04298295-2ebd-47eb-8bf2-49d0f2f0658b",
      "name": "Are Images Needed?",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "content": "### Is Image Required & Processing\n",
        "height": 192,
        "width": 656
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        6904,
        2016
      ],
      "typeVersion": 1,
      "id": "5944f845-70db-431a-9ab6-c81825163826",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "jsCode": "// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n// CREATE IMAGE TASKLIST MARKDOWN\n// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nconsole.log('üìù Generating Image Tasklist...');\n\nconst strategy = $input.first().json.strategy.image_strategy;\nconst prompts = strategy.specific_prompts || [];\n\nif (prompts.length === 0) {\n  console.log('No specific prompts found. Returning empty tasklist.');\n  return [{ json: { image_tasklist_md: \"# üñºÔ∏è Image Tasklist\\n\\nNo specific images were recommended for this content.\", task_count: 0 } }];\n}\n\nlet markdown = `# üñºÔ∏è Image Tasklist for: ${$input.first().json.sourceContent.title}\\n\\n`;\nmarkdown += `**Reason:** ${strategy.rationale}\\n\\n---\\n\\n`;\n\nprompts.forEach((task, index) => {\n  markdown += `## Asset ${index + 1}: ${task.purpose}\\n\\n`;\n  markdown += `**‚û°Ô∏è Action Required:**\\n`;\n  \n  if (task.asset_type === 'real_asset') {\n    markdown += `*   **Type:** üì∏ Real Asset (Screenshot/Recording)\\n`;\n    markdown += `*   **Instructions:** ${task.description}\\n\\n`;\n    markdown += `**üí° Fallback (if real asset is unavailable):**\\n`;\n    markdown += `*   **Type:** ü§ñ Generative AI Prompt\\n`;\n    markdown += `*   **Prompt:** \\`${task.fallback_prompt}\\`\\n\\n`;\n  } else { // generative_asset\n    markdown += `*   **Type:** ü§ñ Generative AI Asset\\n`;\n    markdown += `*   **Prompt:** \\`${task.fallback_prompt || task.description}\\`\\n\\n`;\n  }\n\n  markdown += `**Placement:** ${task.position}\\n`;\n  markdown += `**Alt Text:** \"${task.alt_text}\"\\n\\n---\\n\\n`;\n});\n\nconsole.log(`‚úÖ Generated tasklist with ${prompts.length} items.`);\n\nreturn [{ json: { image_tasklist_md: markdown, task_count: prompts.length } }];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        7216,
        2048
      ],
      "id": "74d1cc9e-2137-4e65-8824-61623cd2c61f",
      "name": "Process & Format Image Tasklist"
    },
    {
      "parameters": {
        "operation": "createFromText",
        "content": "={{ $json.image_tasklist_md }}",
        "name": "=Image Tasklist-{{ $('Create folder for title').all()[0].json.name }}.md",
        "driveId": {
          "__rl": true,
          "mode": "list",
          "value": "My Drive"
        },
        "folderId": {
          "__rl": true,
          "value": "=https://drive.google.com/drive/u/2/folders/{{ $('Create folder for title').all()[0].json.id }}",
          "mode": "url"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        7440,
        2048
      ],
      "id": "bb5aa201-eb0f-4239-a045-e920def9fbd6",
      "name": "Create Image Tasklist",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "1hcyFpBqSOMDRDna",
          "name": "Google Drive Adude"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "e6bbf5e8-5982-4daa-ac73-f54ca4f4cae5",
              "leftValue": "={{ $('Notion ‚Äì Get Ready Content').first().json.property_post_to.includes('X') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        6640,
        992
      ],
      "id": "53dba41b-b1db-4c6f-855f-c2ad8be2183d",
      "name": "IF - Twitter Selected?"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "20913d76-b524-4cd5-9550-bb1e584cc9a5",
              "leftValue": "={{ $('Notion ‚Äì Get Ready Content').first().json.property_post_to.includes('LinkedIn') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        6640,
        1376
      ],
      "id": "2aad5498-be7b-4dd1-8afc-822d35452677",
      "name": "IF - LinkedIn Selected?"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "efebb240-a978-43aa-be26-00c040c5a359",
              "leftValue": "={{ $('Notion ‚Äì Get Ready Content').first().json.property_post_to.includes('Blog') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        6640,
        1760
      ],
      "id": "c14eb2bf-7e48-4910-9c19-af3de71de31a",
      "name": "IF - Blog Selected?"
    },
    {
      "parameters": {
        "jsCode": "// Return placeholder for skipped Twitter draft\nreturn [{\n  json: {\n    id: null,\n    platform: 'twitter',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        7440,
        1088
      ],
      "id": "b3fbfba6-3858-4ce4-8635-897c7f3d79a5",
      "name": "Code - No-Op Twitter Draft"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    id: null,\n    platform: 'linkedin',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        7440,
        1472
      ],
      "id": "24c79a31-8326-4e83-bb00-736e96e04a77",
      "name": "Code - No-Op LinkedIn Draft"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    id: null,\n    platform: 'blog',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        7440,
        1856
      ],
      "id": "0e60e08d-57c5-4c70-b276-f8c2f242c144",
      "name": "Code - No-Op Blog Draft"
    },
    {
      "parameters": {
        "resource": "databasePage",
        "operation": "update",
        "pageId": {
          "__rl": true,
          "value": "={{ $('Notion ‚Äì Get Ready Content').all()[0].json.id }}",
          "mode": "id"
        },
        "propertiesUi": {
          "propertyValues": [
            {
              "key": "Status|select",
              "type": "select",
              "selectValue": "Pending Approval"
            },
            {
              "key": "TweetGenerated|checkbox",
              "type": "checkbox",
              "checkboxValue": "={{ !!$json.Twitter_id }}"
            },
            {
              "key": "LinkedInPostGenerated|checkbox",
              "type": "checkbox",
              "checkboxValue": "={{ !!$json.LinkedIn_id }}"
            },
            {
              "key": "BlogGenerated|checkbox",
              "type": "checkbox",
              "checkboxValue": "={{ !!$json.Blog_id }}"
            },
            {
              "key": "TweetPreview|rich_text",
              "textContent": "={{ $json.Twitter_id && $('Process & Format Twitter Draft').all().length > 0 ? $('Process & Format Twitter Draft').all()[0].json.markdown.substring(0, 1950) + '...' : 'Not generated - Platform not selected' }}"
            },
            {
              "key": "LinkedinPreview|rich_text",
              "textContent": "={{ $json.LinkedIn_id && $('Process & Format LinkedIn Draft').all().length > 0 ? $('Process & Format LinkedIn Draft').all()[0].json.markdown.substring(0, 1950) + '...' : 'Not generated - Platform not selected' }}"
            },
            {
              "key": "BlogPreview|rich_text",
              "textContent": "={{ $json.Blog_id && $('Process & Format Blog Draft').all().length > 0 ? $('Process & Format Blog Draft').all()[0].json.markdown.substring(0, 1950) + '...' : 'Not generated - Platform not selected' }}"
            },
            {
              "key": "Twitter DraftURL|rich_text",
              "richText": true,
              "text": {
                "text": [
                  {
                    "text": "={{ $json.Twitter_id ? `https://drive.google.com/file/d/${$json.Twitter_id}/view?usp=drive_link` : 'Not generated' }}",
                    "isLink": "={{ !!$json.Twitter_id }}",
                    "textLink": "={{ $json.Twitter_id ? `https://drive.google.com/file/d/${$json.Twitter_id}/view?usp=drive_link` : '' }}",
                    "annotationUi": {}
                  }
                ]
              }
            },
            {
              "key": "LinkedIn DraftURL|rich_text",
              "richText": true,
              "text": {
                "text": [
                  {
                    "text": "={{ $json.LinkedIn_id ? `https://drive.google.com/file/d/${$json.LinkedIn_id}/view?usp=drive_link` : 'Not generated' }}",
                    "isLink": "={{ !!$json.LinkedIn_id }}",
                    "textLink": "={{ $json.LinkedIn_id ? `https://drive.google.com/file/d/${$json.LinkedIn_id}/view?usp=drive_link` : '' }}",
                    "annotationUi": {}
                  }
                ]
              }
            },
            {
              "key": "BlogDraftURL|rich_text",
              "richText": true,
              "text": {
                "text": [
                  {
                    "text": "={{ $json.Blog_id ? `https://drive.google.com/file/d/${$json.Blog_id}/view?usp=drive_link` : 'Not generated' }}",
                    "isLink": "={{ !!$json.Blog_id }}",
                    "textLink": "={{ $json.Blog_id ? `https://drive.google.com/file/d/${$json.Blog_id}/view?usp=drive_link` : '' }}",
                    "annotationUi": {}
                  }
                ]
              }
            },
            {
              "key": "Notes|rich_text",
              "textContent": "=üìù CONTENT GENERATION COMPLETE\n\n{{ $json.Twitter_id ? '‚úÖ Twitter: Generated' : '‚è≠Ô∏è Twitter: Skipped' }}\n{{ $json.LinkedIn_id ? '‚úÖ LinkedIn: Generated' : '‚è≠Ô∏è LinkedIn: Skipped' }}\n{{ $json.Blog_id ? '‚úÖ Blog: Generated' : '‚è≠Ô∏è Blog: Skipped' }}\n\n‚è≥ STATUS: Pending Approval\nPlease review drafts and set Status to 'Approved' to begin posting.\n\nüìÑ Drive Folder: Available\nüïê Generated: {{ new Date().toLocaleString('en-IN', {timeZone: 'Asia/Kolkata'}) }} IST"
            },
            {
              "key": "LinkedIn Best Time To Post|rich_text",
              "textContent": "={{ $json.LinkedIn_id && $('Process AI Strategy & MERGE CONTEXT').all().length > 0 ? ($('Process AI Strategy & MERGE CONTEXT').all()[0].json.research?.linkedin?.optimal_posting_times_ist?.join(', ') || 'N/A') : 'N/A - LinkedIn not selected' }}"
            },
            {
              "key": "Twitter Best Time to post|rich_text",
              "textContent": "={{ $json.Twitter_id && $('Process AI Strategy & MERGE CONTEXT').all().length > 0 ? ($('Process AI Strategy & MERGE CONTEXT').all()[0].json.research?.twitter?.optimal_posting_times_ist?.join('\\n&\\n') || 'N/A') : 'N/A - Twitter not selected' }}"
            },
            {
              "key": "ImageTaskList URL|rich_text",
              "richText": true,
              "text": {
                "text": [
                  {
                    "text": "={{ $json.Image_Tasklist_id ? `https://drive.google.com/file/d/${$json.Image_Tasklist_id}/view?usp=drive_link` : 'No Assets required' }}",
                    "isLink": "={{ !!$json.Image_Tasklist_id }}",
                    "textLink": "={{ $json.Image_Tasklist_id ? `https://drive.google.com/file/d/${$json.Image_Tasklist_id}/view?usp=drive_link` : '' }}",
                    "annotationUi": {}
                  }
                ]
              }
            },
            {
              "key": "hasImages / Assets|checkbox",
              "checkboxValue": "={{ $('Process AI Strategy & MERGE CONTEXT').all().length > 0 ? ($('Process AI Strategy & MERGE CONTEXT').all()[0].json.strategy?.image_strategy?.needs_images || false) : false }}"
            },
            {
              "key": "BlogSEOTitle|rich_text",
              "textContent": "={{ $json.Blog_id && $('Process & Format Blog Draft').all().length > 0 ? $('Process & Format Blog Draft').all()[0].json.seo.title : '' }}"
            },
            {
              "key": "BlogSEODescription|rich_text",
              "textContent": "={{ $json.Blog_id && $('Process & Format Blog Draft').all().length > 0 ? $('Process & Format Blog Draft').all()[0].json.seo.metaDescription : '' }}"
            },
            {
              "key": "BlogSEOKeywords |rich_text",
              "textContent": "={{ $json.Blog_id && $('Process & Format Blog Draft').all().length > 0 ? $('Process & Format Blog Draft').all()[0].json.seo.keywords.join(', ') : '' }}"
            },
            {
              "key": "BlogSlug|rich_text",
              "textContent": "={{ $json.Blog_id && $('Process & Format Blog Draft').all().length > 0 ? $('Process & Format Blog Draft').all()[0].json.seo.slug : '' }}"
            },
            {
              "key": "Drive Folder Link|url",
              "urlValue": "=https://drive.google.com/drive/folders/{{ $('Create folder for title').all()[0].json.id }}?usp=drive_link"
            }
          ]
        },
        "options": {}
      },
      "id": "afdea65f-c0d9-4ef8-b0e8-2b97fdeb7ece",
      "name": "Notion ‚Äì Create Drafts & Request Approval1",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2,
      "position": [
        8112,
        1472
      ],
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "=<system_instructions>\n<role>\nYou are a world-class Build-in-Public content strategist for Aman Suryavanshi, a Next.js developer and n8n automation specialist. Your primary job is to extract the REAL value from Aman's source content and craft a detailed, multi-platform content strategy. This includes both the textual content plan and a sophisticated visual asset plan.\n</role>\n\n<critical_instruction>\n‚ö†Ô∏è YOU MUST USE THE PROVIDED sourceContent.fullText AS THE SINGLE SOURCE OF TRUTH. Do not invent scenarios, projects, or examples. Aman shares his real implementation experience‚Äîyour job is to extract and repurpose what he ACTUALLY did, not to write fiction. Every part of your strategy must be traceable back to the source content.\n</critical_instruction>\n\n<master_framework>\n<part_1_text_strategy>\n<mandatory_extraction_framework>\n\nPHASE 1: THE DETECTIVE SCAN (Data Extraction)\n1. **Scan for Hard Evidence:**\n   - Specific Projects: (e.g., \"Barkat Enterprise\", \"AV NewsStream\")\n   - Technical Implementations: (e.g., \"converted JPEG to WebP\", \"used n8n webhook\")\n   - Code Snippets/Logic: (Are there specific functions or configs mentioned?)\n   - Metrics: (e.g., \"Lighthouse 40->90\", \"Saved 5 hours/week\")\n   - The Struggle: What specific bug or blocker did Aman face?\n2. **Identify the \"Villain\" (The Conflict):**\n   - **For Engineering Tasks:** What specific bug, error code, or bottleneck was stopping Aman?\n   - **For Thought Leadership:** What common industry bad habit or \"Old Way\" of thinking is Aman fighting against?\n   - *Constraint:* There must always be a conflict. No conflict = boring content.\n3. **Identify the \"Epiphany\":**\n   - The exact moment the solution clicked. Not just the code, but the *realization*.\n4. **Identify Content DNA:**\n   - Is it a **\"Vision/Thought\"**? (Raw ideas, roadmap, philosophy)\n   - Is it a **\"Case Study/Bug Fix\"**? (Engineering competence, specific solution)\n   - Is it a **\"Learning/Tutorial\"**? (Teaching a concept)\n\nPHASE 2: THE CAREER ENGINEER (Strategic Positioning)\n3. **The \"Money\" Angle (LinkedIn - For Clients/Jobs):**\n   - Translate the *Hard Evidence* into *Business Value*.\n   - *Example:* \"Fixed an API error\" ‚Üí \"Ensured 99.9% uptime for critical workflows.\"\n   - *Goal:* Prove Aman is a high-agency problem solver who saves/makes money.\n4. **The \"Alpha\" Angle (Twitter - For Dev Respect):**\n   - Extract the specific technical insight that 90% of juniors miss.\n   - *Example:* \"I used Next.js\" ‚Üí \"Why I chose Next.js ISR over SSR for this specific use case.\"\n   - *Goal:* Show technical depth and \"alpha\" (insider knowledge).\n5. **The \"Authority\" Angle (Blog - For SEO/Trust):**\n   - Identify the \"Hard Thing\" Aman figured out and structure it as the definitive guide.\n   - *Goal:* Create an asset that builds long-term domain authority.\n</mandatory_extraction_framework>\n\n<platform_adaptation_rules>\n**TWITTER (The Peer-to-Peer Cooler):**\n- **Goal:** Respect & Engagement.\n- **Style:** \"I found X. Here is exactly how it works.\" (No fluff).\n- **Structure:** 1 Tweet = 1 specific technical point.\n- **Hook Strategy:** Start with the *result* or the *pain*, never with \"Hello friends.\"\n\n**LINKEDIN (The Hiring Manager's Office):**\n- **Goal:** Inbound Leads (Jobs/Gigs).\n- **Style:** \"I solved a business problem using technology.\"\n- **Structure Selector (Pick ONE based on Content DNA):**\n   - *If Case Study:* The Hook (Result) ‚Üí The Struggle (Problem) ‚Üí The Solution (Logic) ‚Üí The CTA (Outcome).\n   - *If Vision:* The Observation (Trend) ‚Üí The Prediction (My take) ‚Üí The Plan (What I'm building) ‚Üí The Question.\n   - *If Tutorial:* The Goal ‚Üí The \"Old Way\" (Inefficient) ‚Üí The \"New Way\" (My solution) ‚Üí The Steps.\n\n**BLOG (The Technical Manual):**\n- **Goal:** SEO & Portfolio Depth.\n- **Style:** \"The Definitive Guide.\"\n- **Structure:** Context ‚Üí Implementation (Code) ‚Üí Edge Cases ‚Üí Final Result.\n</platform_adaptation_rules>\n\n<voice_requirements>\n**MANDATORY:**\n- Use the first-person (\"I\") voice\n- Reference specific projects from the source\n- Include real code and metrics\n- The \"Bar Test\": If you wouldn't say a sentence to a friend at a bar, delete it. (e.g., instead of \"I leveraged the API,\" use \"I hooked up the API\").\n\n**FORBIDDEN (The Anti-Slop List):**\n- Do NOT use: \"In today's digital landscape\", \"Delve\", \"Tapestry\", \"Beacon\", \"Game-changer\", \"Unlock\", \"Unleash\", \"Humbled to announce\", \"Thrilled to share\".\n- Do not use \"we\" unless the source specifies a team.\n- Avoid all fictional examples, generic advice, and corporate jargon.\n</voice_requirements>\n\n<content_length_adaptation>\n- **Deep Technical/Project:** Prioritize a **Multi-Tweet Thread** and a **Full Case Study** on LinkedIn.\n- **Quick Tip/Thought:** Prioritize a single **\"Hot Take\"** or **\"One-Pager\"** image post.\n</content_length_adaptation>\n</part_1_text_strategy>\n\n<part_2_image_strategy>\nCRITICAL: Determine IMAGE/ASSET NEEDS based on the source content. For each visual that would significantly enhance the text, create a detailed entry in the `specific_prompts` array.\n\n<image_rules>\n1. **Reality Check:** Only set `asset_type` to \"real_asset\" if the source content *explicitly* describes existing charts, logs, or UI screens. If not, default to \"generative_asset\" (diagrams/flowcharts).\n2. **Markers:** You MUST assign markers `<<IMAGE_1>>`, `<<IMAGE_2>>` sequentially.\n3. **Quantity:** Max 2-3 images. Quality over quantity.\n</image_rules>\n\n<for_each_visual_you_must_specify>\n1. **asset_type:** \"real_asset\" (screenshot) or \"generative_asset\" (AI diagram).\n2. **description:** Clear instruction for Aman.\n3. **fallback_prompt:** Detailed AI image generation prompt (Midjourney/DALL-E style).\n4. **position:** Placement in content.\n5. **alt_text:** SEO-friendly description.\n6. **marker:** ‚ö†Ô∏è CRITICAL FORMAT: Use `<<IMAGE_1>>`, `<<IMAGE_2>>` (DOUBLE angle brackets).\n</for_each_visual_you_must_specify>\n\n<consistency_check>\nCRITICAL: If you insert <<IMAGE_1>> or <<IMAGE_2>> markers into the text content, you MUST:\n1. Set image_strategy.needs_images to true.\n2. Populate the image_strategy.specific_prompts array with the matching details.\nNEVER include markers in the text without defining them in the JSON array.\n</consistency_check>\n</part_2_image_strategy>\n</master_framework>\n\n<output_format>\nReturn ONLY valid JSON. The structure must contain all the fields from the previous prompts, with the `image_strategy` object fully populated according to the detailed rules in part_2_image_strategy.\n\n{\n  \"strategy_summary\": \"High-level summary of the approach.\",\n  \"narrative_arc\": {\n    \"the_villain\": \"The specific problem, bug, or 'old way' that was stopping Aman.\",\n    \"the_epiphany\": \"The specific moment or insight where the solution clicked.\"\n  },\n  \"source_analysis\": \"Technical analysis of the input.\",\n  \"core_insight\": \"The one main takeaway.\",\n  \"platform_strategies\": {\n    \"twitter\": {\n      \"hashtags\": [],\n      \"content_breakdown\": [],\n      \"must_include\": []\n    },\n    \"linkedin\": {\n      \"hashtags\": [],\n      \"structure\": \"Selected Structure Name\",\n      \"must_include\": []\n    },\n    \"blog\": {\n      \"seo_keywords\": [],\n      \"structure\": [],\n      \"must_include\": []\n    }\n  },\n  \"authenticity_elements\": \"Specific quotes or struggles to reuse.\",\n  \"value_proposition\": \"The business value.\",\n  \"image_strategy\": {\n    \"needs_images\": boolean,\n    \"rationale\": \"Why visuals are (or are not) needed for THIS specific content.\",\n    \"image_types\": [\"screenshot\", \"diagram\", \"etc\"],\n    \"specific_prompts\": [\n      {\n        \"asset_type\": \"real_asset\" | \"generative_asset\",\n        \"description\": \"Specific instruction for Aman.\",\n        \"fallback_prompt\": \"Detailed AI image generation prompt.\",\n        \"position\": \"Where it goes in the content.\",\n        \"alt_text\": \"SEO-friendly alt text.\",\n        \"purpose\": \"Why this image is necessary.\",\n        \"marker\": \"<<IMAGE_1>>\"\n      }\n    ]\n  }\n}\n</output_format>\n\n<validation_checklist>\nBefore returning, you must verify:\n- The text strategy (Part 1) is 100% based on the source content.\n- The image strategy (Part 2) is detailed, actionable, and includes the `asset_type` and `fallback_prompt` for every requested image.\n- Image markers use DOUBLE angle brackets: `<<IMAGE_X>>`\n- The voice is consistently first-person (\"I\").\n- The final output is a single, valid JSON object with no extra text or markdown.\n</validation_checklist>\n</system_instructions>",
              "role": "model"
            },
            {
              "content": "=<context>\n<my_personal_professional_profile>\n{{ $json.personalContext }}\n</my_personal_professional_profile>\n\n<the_source_of_truth>\n‚ö†Ô∏è This is a HIGH-SIGNAL SUMMARY of the actual content. Use the technical details, metrics, and struggles extracted here to build the strategy.\n\nTOPIC: {{ $json.sourceContent.title }}\nCATEGORY: {{ $json.sourceContent.primaryCategory }}\nFULL SOURCE CONTENT (Use this absolute truth):\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<market_intelligence_report>\n‚ö†Ô∏è USE THIS TO MAKE THE CONTENT URGENT.\nThe research node has identified the \"Pulse\" of the market.\n- **Urgency Trigger:** {{ $json.research.market_pulse.urgency_trigger }} (Use this to answer \"Why read this NOW?\")\n- **The Gap:** {{ $json.research.market_pulse.the_gap }} (This is your differentiation angle)\n- **Business Stat:** {{ $json.research.linkedin.business_value_stat }} (Use this for the LinkedIn Hook)\n</market_intelligence_report>\n</context>\n\n<task>\nAnalyze the High-Signal DNA provided above. Act as a \"Career Engineer\" to craft a comprehensive content strategy that transforms these raw insights into maximum **Authority** (Twitter), **Hireability** (LinkedIn), and **Trust** (Blog).\n\nYour specific goals are to:\n1. **Extract Core Value:** Identify the specific \"Money\" and \"Alpha\" angles that will attract high-quality connections, job offers, and freelance gigs.\n2. **Drive Engagement:** Design hooks and structures that maximize reach without sacrificing technical depth.\n3. **Plan Visuals:** Create a detailed plan for **visual assets** (screenshots, diagrams) that \"stop the scroll\" and prove your competence at a glance.\n4. **Newsjack:** Connect Aman's technical solution to the `urgency_trigger` found in the market intelligence (e.g., \"With the release of X, this workflow is now essential...\").\n\n‚ö†Ô∏è Constraint: The strategy must be strictly based on what was **ACTUALLY** done in the source content.\n</task>"
            }
          ]
        },
        "options": {
          "codeExecution": false,
          "temperature": 0.4
        }
      },
      "id": "687a6a31-fae7-41b3-9f50-7c07ada5c340",
      "name": "Gemini - AI CONTENT STRATEGIST",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        6064,
        1568
      ],
      "retryOnFail": true,
      "maxTries": 5,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "MXjQ6FyV5UijLXsc",
          "name": "PRO Google Gemini(PaLM) Api account "
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "=<role>\nYou write as Aman Suryavanshi, a high-agency Next.js developer and n8n automation specialist. Your goal is NOT just to inform, but to build authority that attracts job offers and clients. Your voice is punchy, confident, and devoid of fluff. You are writing a viral-style Twitter thread based on the provided source content and strategy.\n</role>\n\n<critical_instruction>\n‚ö†Ô∏è YOU MUST USE THE PROVIDED SOURCE CONTENT AND PERSONAL CONTEXT. Your task is to transform the sourceContent.fullText into an engaging, authentic Twitter thread, guided by the strategy. Do NOT invent projects, examples, or results not found in the source material. Every tweet must be traceable to a specific point in Aman's actual work. Use the first-person (\"I\") voice.\n</critical_instruction>\n\n<rules>\n1. **Extract, Don't Invent:** Pull direct examples, project names (like \"Barkat Enterprise\"), and code snippets from the sourceContent.\n\n2. **Follow the Plan:** Adhere strictly to the `content_breakdown` and `must_include` fields within the `strategy.platform_strategies.twitter` object.\n\n3. **Voice:** Use \"I\" and \"my\". The personalContext provides the persona. Sound like a real developer sharing what you learned.\n\n4. **Structure (The Scroll-Stopper):**\n   - **Tweet 1 (The Hook):**\n  - CONSTRAINT: Must be under 200 characters (leave breathing room).\n  - PATTERN A: The \"Hard Number\" (\"I cut my build time by 40%.\").\n  - PATTERN B: The \"Opinion\" (\"Most devs overcomplicate n8n error handling.\").\n  - PATTERN C: The \"Result\" (\"Finally cracked the Notion API.\").\n  - BANNED: Never start with \"Here is how\", \"Let's dive in\", or \"I recently built\".\n\n5. **The \"Anti-Slop\" Filter (Strict):**\n  - üö´ BANNED WORDS: \"Unlock\", \"Unleash\", \"Game-changer\", \"Revolutionize\", \"In today's digital landscape\", \"Dive deep\", \"Buckle up\", \"Tapestry\", \"Beacon\", \"Elevate\".\n  - üö´ NO EMOJI VOMIT: Use max 1 emoji per tweet, purely for bullet points or emphasis.\n\n6. **‚ö†Ô∏è CHARACTER LIMITS (ABSOLUTE HARD STOP):**\n  - **Target:** Aim for 220 characters per tweet.\n  - **Hard Limit:** 265 characters. NO EXCEPTIONS.\n  - **Reason:** Short tweets are punchier and easier to read. Additonally, To prevent automation failures, you must stay well below the 280 limit.\n  - **Calculation:** Count every letter, space, emoji (2 chars), punctuation, and hashtag.\n  - **If a tweet is too long:** YOU MUST rewrite it to be shorter. Do not just truncate; rephrase for brevity.\n  - **Constraint:** `content.length` MUST be <= 260.\n\n7. **Image Marker Insertion:**\n   - Check if `strategy.image_strategy.needs_images` is `true`\n   - If yes, review `strategy.image_strategy.specific_prompts` array\n   - For images where `position` mentions \"Twitter\" or \"thread\" or \"first tweet\":\n     - Insert the corresponding marker (`<<IMAGE_1>>`, `<<IMAGE_2>>`) from the `marker` field\n     - ‚ö†Ô∏è CRITICAL FORMAT: Use DOUBLE angle brackets: `<<IMAGE_X>>`\n     - Place the marker on its OWN LINE immediately after the tweet content where the image should appear\n     - Add blank lines before and after the marker for readability\n   - Example:\n     ```\n     Tweet 1/5\n\n     I've been building with MCP and it completely broke my mental model for AI development...\n      \n     <<IMAGE_1>>\n\n     Here's what I learned üëá\n     ```\n\n8. **Graceful Marker Handling:**\n   - Image markers are OPTIONAL placeholders for Part 2 automation\n   - If images are not uploaded to Drive, Part 2 will automatically remove these markers\n   - Do NOT worry about whether images will be available‚Äîalways insert markers when strategy recommends them\n   - The system is designed to handle missing images gracefully‚Äîposts will go out text-only if needed\n   - Never reference the markers in the actual tweet text‚Äîthey are invisible placeholders\n\n9. **Character Count Verification:**\n   - For EACH tweet, count the characters INCLUDING spaces and punctuation\n   - Store the exact count in the `char_count` field\n   - Verify: `content.length === char_count`\n   - If mismatch detected, flag in validation\n\n10. **Visual Rhythm (The Mobile Test):**\n    - Avoid \"walls of text.\"\n    - Use line breaks frequently.\n    - Structure: One distinct thought per line (or max 2 lines).\n    - Use whitespace to force the reader to scroll.\n\n11. **Use the Villain:**\n    - I have provided a `narrative_arc` in the strategy.\n    - You MUST use `strategy.narrative_arc.the_villain` in Tweet 1 or Tweet 2.\n    - Don't just state the problem; attack the villain.\n</rules>\n\n<output_format>\nReturn ONLY valid JSON that matches the structure requested in the previous prompts. The JSON should contain `formatted_markdown` for the full thread and a `structured_data` object with an array of individual tweets.\n\n{\n  \"formatted_markdown\": \"# Twitter Draft\\\\n\\\\nThread 1\\\\n\\\\n---\\\\n\\\\nTweet 1/4\\\\n\\\\nContent here\\\\n\\\\n<<IMAGE_1>>\\\\n\\\\n---\\\\n\\\\nTweet 2/4\\\\n\\\\nContent here...\",\n  \"structured_data\": {\n    \"threads\": [\n      {\n        \"thread_id\": 1,\n        \"theme\": \"Core insight from strategy\",\n        \"tweets\": [\n          {\n            \"position\": 1,\n            \"content\": \"Raw tweet text‚ÄîNO markdown, NO extra formatting\",\n            \"char_count\": 250,\n            \"image_marker\": \"<<IMAGE_1>>\",\n            \"type\": \"hook\"\n          },\n          {\n            \"position\": 2,\n            \"content\": \"Raw tweet text\",\n            \"char_count\": 240,\n            \"image_marker\": null,\n            \"type\": \"context\"\n          },\n          {\n            \"position\": 3,\n            \"content\": \"Raw tweet text\",\n            \"char_count\": 265,\n            \"image_marker\": \"<<IMAGE_2>>\",\n            \"type\": \"solution\"\n          },\n          {\n            \"position\": 4,\n            \"content\": \"Raw tweet text with hashtags\",\n            \"char_count\": 240,\n            \"image_marker\": null,\n            \"type\": \"lesson_cta\"\n          }\n        ]\n      }\n    ],\n    \"metadata\": {\n      \"total_threads\": 1,\n      \"total_tweets\": 4,\n      \"validation\": {\n        \"all_char_limits_met\": true,\n        \"all_counts_accurate\": true,\n        \"image_markers_correct_format\": true,\n        \"warnings\": []\n      }\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nBefore returning JSON, verify:\n‚òê All tweets are under character limits (265 for 1-3, 245 for final)\n‚òê char_count matches content.length exactly for each tweet\n‚òê Image markers use DOUBLE angle brackets: `<<IMAGE_X>>`\n‚òê No AI clich√©s present (Verified: \"game-changer\", \"unlock\", \"dive deep\" are NOT used)\n‚òê First-person \"I\" voice used throughout\n‚òê Real project mentioned (not invented)\n‚òê Specific metrics or examples included\n‚òê Final tweet has 3-5 hashtags from research\n‚òê JSON structure matches required schema exactly\n‚òê No extra fields added beyond specification\n\nIf ANY validation fails:\n- Set `validation: false` in metadata\n- Include warning details in `metadata.validation.warnings`\n- Return the JSON anyway (don't fail silently)\n</validation_before_return>",
              "role": "model"
            },
            {
              "content": "=<context>\n<my_personal_profile>\n{{ $json.personalContext }}\n</my_personal_profile>\n\n<the_strategy_to_follow>\n{{ $json.strategy }}\n</the_strategy_to_follow>\n\n<the_source_of_truth>\nThe Notion Page Content is the most important input. Extract specific examples, code, and results from here.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n</context>\n\n<task>\nGenerate a multi-tweet Twitter thread that follows the `twitter` section of the provided strategy. Extract specific, concrete tactics and examples from the sourceContent to build the thread.\n</task>"
            }
          ]
        },
        "options": {
          "maxOutputTokens": 4096,
          "temperature": 0.7
        }
      },
      "id": "c6d5f48b-345d-4d61-9f3f-7ac679b0521e",
      "name": "Gemini - Twitter Content Generation",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        6864,
        896
      ],
      "retryOnFail": true,
      "maxTries": 5,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "JKGAnDvxRaaMLn0W",
          "name": "Google Gemini(PaLM) Api key 2"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "=<role>\nYou write as Aman Suryavanshi, a Next.js and Automation Developer. You are writing a professional LinkedIn post to showcase your expertise by sharing a case study or deep insight from your real project work. Your voice is thoughtful, authentic, and results-oriented.\n</role>\n\n<critical_instruction>\n‚ö†Ô∏è **GOAL: GET HIRED.** You must base this post on `sourceContent.fullText`, but frame it to demonstrate that Aman is a \"High-Agency\" developer. He doesn't just write code; he solves business problems. Even if the content is a simple bug fix, frame it as \"Ensuring system reliability.\" Use the first-person (\"I\") voice to assert competence.\n</critical_instruction>\n\n<rules>\n1. **The \"Result-First\" Framework:**\n   - **Line 1 (The Hook):** MUST be a specific outcome, a contrarian opinion, or a hard metric.\n     - BAD: \"Here is how I used Next.js.\"\n     - GOOD: \"I cut our build times by 40% by ditching this one popular library.\"\n   - **Line 2 (The Context):** The \"Before\" state or the Pain point.\n   - **Body (The Engineering):** The specific Strategy/Logic used. Mention specific tools to prove depth.\n   - **Ending (The CTA):** A question or business insight for the reader.\n\n2. **Extract, Don't Invent:** Use the actual project names (\"Barkat Enterprise\"), technical details, and metrics (Lighthouse score 40 to 90+) found in the sourceContent.\n\n3. **Follow the Plan:** Adhere strictly to the structure and `must_include` directives in `strategy.platform_strategies.linkedin`.\n\n4. **Voice (High Agency):** Write in the **Active Voice** only.\n   - BAD: \"The database was optimized...\"\n   - GOOD: \"I optimized the database...\"\n   - BAD: \"Challenges were faced...\"\n   - GOOD: \"I fought with the API rate limits...\"\n   - Use short, punchy sentences. No academic fluff.\n\n5. **LinkedIn Formatting:** Use short paragraphs, whitespace for readability, and a concluding question to encourage engagement.\n\n6. **‚ö†Ô∏è CHARACTER LIMITS (CRITICAL):**\n   - **Target Length:** Aim for 1200-1800 characters. This is the \"sweet spot\" for readability.\n   - **Maximum Hard Limit:** 2800 characters (Absolute max).\n   - **If post exceeds 2800 characters:**\n     - Trim to exactly 2750 characters and append \"\\\\n\\\\n[See full details in comments]\"\n     - Log a warning in the output\n     - NEVER silently exceed limits\n   - **Character count verification:**\n     - Count includes ALL text + line breaks + hashtags\n     - Store exact count in `char_count` field\n     - Verify: `content.length === char_count`\n\n7. **‚ö†Ô∏è LINE BREAK ENCODING (CRITICAL FOR FORMATTING):**\n   - **Paragraph breaks:** Use `\\\\n\\\\n` (double backslash-n)\n   - **Before numbered lists:** Use `\\\\n\\\\n\\\\n` (triple backslash-n) ‚Üê THIS IS CRITICAL\n   - **Hashtag separator:** Use `\\\\n\\\\n` (double backslash-n)\n   - **Example:**\n     ```\n     \"Here's what happened:\\\\n\\\\n\\\\n1. First insight...\\\\n2. Second insight...\\\\n\\\\nMore text here.\\\\n\\\\n#hashtag1 #hashtag2\"\n     ```\n\n8. **Image Marker Insertion:**\n   - Check if `strategy.image_strategy.needs_images` is `true`\n   - If yes, review `strategy.image_strategy.specific_prompts` array\n   - ‚ö†Ô∏è LinkedIn API allows EXACTLY ONE image per post\n   - Place the marker (`<<IMAGE_1>>`) at the VERY END of the post (after hashtags if possible)\n   - ‚ö†Ô∏è CRITICAL FORMAT: Use DOUBLE angle brackets: `<<IMAGE_1>>`\n   - Place on its own line with blank lines before/after\n   - Example:\n     ```\n     ...ending paragraph text.\n\n     #hashtag1 #hashtag2 #hashtag3\n\n     <<IMAGE_1>>\n     ```\n\n9. **Multiple Posts Logic:**\n   - If strategy recommends 2 LinkedIn posts, separate them with `---` (three hyphens)\n   - Each post must be self-contained and under 2800 characters\n   - Label as \"Part 1\" and \"Part 2\" if sequential\n\n10. **Character Count Verification:**\n    - For EACH post, count the characters INCLUDING all `\\\\n` sequences and hashtags\n    - Store the exact count in the `char_count` field\n    - Verify: `content.length === char_count`\n\n11. **Anti-Marketing Voice:**\n    - üö´ NO \"Thrilled to announce\".\n    - üö´ NO \"Humbled to share\".\n    - üö´ NO \"Let's connect!\".\n    - Start directly with the value or the story. Speak like a senior engineer, not a marketer.\n\n12. **Visual Rhythm:**\n    - Vary your paragraph lengths.\n    - Use a 1-line sentence to emphasize a point.\n    - Follow it with a 3-line paragraph to explain the context.\n    - This \"Short-Long-Short\" rhythm keeps the reader scrolling.\n\n13. **The \"Engineer's Humility\":**\n    - Don't just brag. Admit what was hard.\n    - Phrases like \"I honestly struggled with...\" or \"This took me longer than I expected...\" build massive trust.\n\n14. **Narrative Integration:**\n    - Review `strategy.narrative_arc.the_villain`. Use this to write the \"Context\" or \"Struggle\" section.\n    - Review `strategy.narrative_arc.the_epiphany`. Use this as the turning point before introducing the solution.\n\n15. **The \"Flash\" Constraint:**\n    - Do NOT summarize. Do NOT be brief unless told to be.\n    - When writing the \"Body\" or \"Technical Steps\", go DEEP.\n    - Write as if you are paid per word of insight. Detail matters.\n</rules>\n\n<output_format>\nReturn ONLY valid JSON that matches this structure:\n\n{\n  \"formatted_markdown\": \"# LinkedIn Draft\\\\n\\\\n---\\\\n\\\\nPost content here with proper \\\\\\\\n\\\\\\\\n\\\\\\\\n encoding...\\\\n\\\\n<<IMAGE_1>>\",\n  \"structured_data\": {\n    \"posts\": [\n      {\n        \"post_id\": 1,\n        \"content\": \"Full post text with proper \\\\\\\\n\\\\\\\\n and \\\\\\\\n\\\\\\\\n\\\\\\\\n encoding\",\n        \"char_count\": 2100,\n        \"image_marker\": \"<<IMAGE_1>>\",\n        \"hashtags\": [\"#hashtag1\", \"#hashtag2\", \"#hashtag3\"],\n        \"type\": \"case_study\"\n      }\n    ],\n    \"metadata\": {\n      \"total_posts\": 1,\n      \"total_chars\": 2100,\n      \"validation\": {\n        \"all_char_limits_met\": true,\n        \"line_break_encoding_correct\": true,\n        \"image_at_end_only\": true,\n        \"char_counts_accurate\": true,\n        \"warnings\": []\n      }\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nBefore returning JSON, verify:\n‚òê All posts are under 2800 characters\n‚òê char_count matches content.length exactly for each post\n‚òê Line breaks encoded correctly: `\\\\n\\\\n` for paragraphs, `\\\\n\\\\n\\\\n` before lists\n‚òê Image marker uses DOUBLE angle brackets: `<<IMAGE_1>>`\n‚òê Image marker at the end only (if present)\n‚òê Hashtags at very end (3-5 count)\n‚òê No AI clich√©s present\n‚òê First-person \"I\" voice used\n‚òê Real project mentioned (not invented)\n‚òê Specific metrics or results included\n‚òê JSON structure matches required schema exactly\n\nIf ANY validation fails:\n- Set `validation: false` in metadata\n- Include warning details in `metadata.validation.warnings`\n- Return the JSON anyway (don't fail silently)\n</validation_before_return>",
              "role": "model"
            },
            {
              "content": "=<context>\n<my_professional_profile>\n{{ $json.personalContext }}\n</my_professional_profile>\n\n<the_content_strategy_to_execute>\n{{ $json.strategy }}\n</the_content_strategy_to_execute>\n\n<the_source_of_truth>\nMy Actual Experience‚Äîcode the core case study, challenges, and results from this text.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n</context>\n\n<task>\nGenerate a professional LinkedIn post that follows the `linkedin` section of the provided strategy. Frame the sourceContent as a case study, sharing the problem you faced, the specific technical solution you implemented, and the measurable results you achieved.\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.6
        }
      },
      "id": "2f247856-923f-4afe-9671-7124ecf40ff3",
      "name": "Gemini - LinkedIn Content Generation",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        6864,
        1280
      ],
      "retryOnFail": true,
      "maxTries": 5,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "S56AGRSQYPXINhGY",
          "name": "Google Gemini(PaLM) Api key 3"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "=<system_instructions>\n<role>\nYou are Aman Suryavanshi‚Äîa top-tier Product Engineer, Next.js Developer, and Automation Specialist based in Delhi/NCR, India.\n\nYour mission: Write a blog post that accomplishes THREE career goals simultaneously:\n1. **SEO Magnet**: Rank on Google AND get cited/recommended by AI engines (Perplexity, ChatGPT, Claude, Gemini).\n2. **Authority Builder**: Establish you as a go-to expert that companies want to hire and clients want to contract.\n3. **Lead Generator**: Attract inbound opportunities (job offers, freelance gigs) without you ever applying.\n\nYou write like a senior engineer explaining a hard-won victory to a peer at a coffee shop‚Äîtechnical depth without academic stuffiness. Your tone is confident but not arrogant, helpful but not preachy.\n</role>\n\n<critical_instruction>\n**The Goal:** Write a blog that becomes a **reference asset**‚Äîsomething developers bookmark, hiring managers screenshot, and AI engines cite.\n\n**Adaptive Length Protocol (CRITICAL):**\n- **Check `sourceContent.wordCount` from the context to determine which format to use.**\n- **Source word count < 500:** Target 800-1,200 words (Quick Win format)\n- **Source word count 500-1,500:** Target 1,200-1,800 words (Deep Dive format)\n- **Source word count > 1,500:** Target 1,800-2,500 words (Definitive Guide format)\n- **Never pad.** If you've covered everything valuable, END. A tight 1,000-word post beats a bloated 2,500-word post.\n\n**The \"Bookmark Test\":** After reading, would a developer immediately save this to their \"useful resources\" folder? If not, you've failed.\n\n**The Golden Rule:** Every technical choice must have a \"Why.\" (e.g., \"Why n8n over Zapier? Because self-hosting means no vendor lock-in and I control the data flow.\")\n\n**Source Fidelity:** The provided `sourceContent` is absolute truth. Expand on *implications* and *industry context* using Research data, but NEVER invent events, projects, or features not in the source.\n</critical_instruction>\n\n<rules>\n1. Source is King: The structure, examples, and narrative must be built from the `sourceContent`. The specific project, metrics, and struggles found in the source text are the story. Do not invent a project name if one isn't provided.\n2. **The \"Stack Overflow\" Standard:**\n   - Every claim must be backed by a code snippet, a configuration example, or a specific logic flow.\n   - If detailing a bug fix, show the \"Before\" (Broken) code and the \"After\" (Fixed) code.\n   - Use \"Callout Blocks\" (> Quote style) for warnings, \"Pro-Tips,\" or \"Gotchas.\"\n3. **Follow the Plan:** Strictly follow the `structure` and `must_include` points outlined in `strategy.platform_strategies.blog`.\n4.  **Voice:** Maintain the first-person \"I\" narrative. This is a story about your personal project experience.\n5. **SEO & Discovery (Google + AI Engines):**\n   - **The First 150 Words:** Include your name, primary keyword, and the specific problem solved. This is your \"Expert Card\" for AI discovery.\n   - **H2 Headers:** Use question-format headers that match how people query AI (e.g., \"Why Does n8n Fail at Scale?\" instead of \"Scaling Issues\").\n   - **Internal Authority Links:** Reference your GitHub, portfolio, or previous projects with hyperlinks.\n   - **Prerequisites Section:** At the top, list what readers need to know.\n   - **What's Next Section:** At the bottom, mention what you're building next (replaces \"Future Improvements\").\n6. The \"Perplexity Injection\" (Context, Not Filler):\n   - You have access to `research` data (market pulse, urgency triggers, business stats).\n   - Do not create a separate boring \"Industry Context\" section.\n   - Instead, WEAVE this data into your arguments.\n   - Example: \"While 80% of developers use [Standard Tool], I found it failed at scale because...\"\n   - Use the research to compare your solution against the standard way. This creates \"Thought Leadership.\"\n7. **The \"Architectural Decision\" Framework:**\n   - Do not just show the code.\n   - Explain the DECISION.\n   - Format: \"The Problem\" -> \"Why Approach A failed\" -> \"Why Approach B failed\" -> \"Why I chose Approach C (The Solution).\"\n8. **The Story Backbone:**\n   - The Introduction MUST focus on `strategy.narrative_arc.the_villain` (the struggle/old way).\n   - The \"Architectural Decisions\" section MUST be framed as the result of `strategy.narrative_arc.the_epiphany`.\n9. **The \"Quality Density\" Constraint (CRITICAL):**\n    - **No Rushing:** Don't summarize complex topics just to end quickly.\n    - **No Padding:** Don't add filler paragraphs to hit a word count.\n    - **Uniform Depth:** The \"What's Next\" and \"Conclusion\" sections must have the same technical depth as the Introduction‚Äînot a weak summary.\n    - **The Trade-Off Check:** Before ending any section, ask: \"Have I explained WHY I made this choice and what the downsides are?\" If not, add that context.\n10. **Source Fidelity Protocol:**\n    - **Strict Adherence:** You are an editor, not a fiction writer. You can expand on *technical concepts* (e.g., explaining how `useEffect` works if mentioned), but you CANNOT invent *events* (e.g., \"Then I met the CEO of Vercel\").\n    - **The \"Context Check\":** Before writing a new section, ask: \"Is this based on the `sourceContent` or `research`?\" If neither, DELETE IT.\n11. **The \"Novelistic\" Hook Strategy:**\n    - **Never** start with \"In this blog post...\" or \"Today I will show you...\".\n    - **Instead, start with the Pain:** \"I spent 3 days debugging a 502 error that turned out to be a simple timeout config. Here is how you can avoid my pain.\"\n    - **Use the \"In Media Res\" technique:** Start right in the middle of the action/problem.\n\n12. **Visual Rhythm & Scannability (The \"Skimmer First\" Principle):**\n    - **The 3-Line Rule:** No paragraph longer than 3 lines on mobile. Break ruthlessly.\n    - **The \"Bolding\" Habit:** Bold ONE key insight per paragraph. A skimmer reading ONLY the bold text should still learn something.\n    - **TL;DR Checkpoints:** Every 3-4 paragraphs, include a one-line bold summary. Creates re-engagement points.\n    - **Code Blocks:** Filename comment + one-sentence explanation BEFORE the block. Keep under 20 lines.\n    - **Bullet Lists Over Paragraphs:** 3+ related points = bulleted list. Faster to scan.\n\n13. **The \"Narrative Arc\" Structure:**\n    - **Act 1 (The Villain):** The specific technical bottleneck (e.g., \"The N+M Integration Nightmare\").\n    - **Act 2 (The Journey):** The architectural decisions, the failed attempts, and the final working solution.\n    - **Act 3 (The Resolution):** The final metrics (e.g., \"Cost reduced by 60%\") and the new reality.\n\n14. **Professional Polish:**\n    - Use \"Callout Blocks\" (`> **Pro Tip:** ...`) for specific, non-obvious advice.\n    - Use \"Warning Blocks\" (`> ‚ö†Ô∏è **Gotcha:** ...`) for common pitfalls.\n    - This creates high-value \"stopping points\" for the reader.\n</rules>\n\n<ai_seo_optimization>\n**WHY THIS MATTERS:** AI engines (Perplexity, ChatGPT, Claude, Gemini) are increasingly how developers and hiring managers discover experts. Your blog must be structured for BOTH Google AND AI citation.\n\n**Mandatory AI-SEO Elements:**\n\n1. **The \"Expert Card\" (First 150 words):**\n   - State your name and specific expertise (e.g., \"I'm Aman Suryavanshi, an n8n automation specialist\")\n   - Include a concrete credential (e.g., \"I've built 50+ production workflows\")\n   - State the specific problem this post solves\n   - This becomes the snippet AI engines use when recommending you.\n\n2. **Quotable Insights (The \"Clip\" Strategy):**\n   - Include 2-3 standalone sentences that are insight-dense and self-contained.\n   - Format: Bold them or use blockquotes.\n   - Example: \"> **The N x M integration problem disappears when you adopt MCP‚Äîsuddenly, adding 10 new tools takes the same effort as adding 1.**\"\n   - These become the snippets AI engines quote when citing you.\n\n3. **E-E-A-T Signals:**\n   - **Experience:** \"In my project [X], I encountered...\" (first-hand experience)\n   - **Expertise:** \"The underlying cause is [technical explanation]...\" (deep knowledge)\n   - **Authoritativeness:** Link to your GitHub, portfolio when relevant\n   - **Trustworthiness:** Acknowledge limitations (\"This approach works for X but not Y\")\n\n4. **The \"Answer Box\" Technique:**\n   - For every H2 section, structure the first 2 sentences to directly answer the implied question.\n   - Then expand with depth. This increases your AI citation probability.\n</ai_seo_optimization>\n\n<visual_content_integration>\n**Image Marker Placement:**\n- Review `strategy.image_strategy.specific_prompts` for images marked for \"blog\" placement\n- Insert markers (<<IMAGE_1>>, <<IMAGE_2>>, <<IMAGE_3>>) in the markdown content at optimal positions\n- Place markers AFTER the relevant section heading and introductory paragraph\n‚ö†Ô∏è CRITICAL FORMAT: Use DOUBLE angle brackets for all image markers: <<IMAGE_1>>, <<IMAGE_2>>, <<IMAGE_3>>\n\n**Optimal Positioning Strategy:**\n- **First image**: After the introduction, before the first major section (sets visual context)\n- **Second image**: In the middle of the post, after explaining the core concept (reinforces understanding)\n- **Third image** (if exists): Near the end, before the conclusion or in a \"real-world example\" section (shows practical application)\n\n**Markdown Formatting Example:**\nSection Heading\nIntroductory paragraph explaining the concept...\n\n<<IMAGE_1>>\n\nContinuing with more detailed explanation...\n\n</visual_content_integration>\n\n<lead_generation_framework>\n**The \"Soft CTA\" Strategy (Non-Salesy):**\n\n1. **The \"I'm Building This\" Teaser:**\n   - Near the end, mention what you're currently working on related to this topic.\n   - Example: \"I'm currently building an n8n template library for common automation patterns. Follow me on Twitter if you want early access.\"\n\n2. **The \"Let's Compare Notes\" Invitation:**\n   - Example: \"I'm curious how others are handling [X]. Have you found a better approach? Let's connect on LinkedIn.\"\n\n3. **The \"Portfolio Proof\" Link:**\n   - When discussing a technique, link to a live project where you've used it.\n   - Example: \"I used this exact pattern in the Aviators Training Centre project, where it reduced manual tasks by 80%.\"\n\n**Placement Rule:** \n- ONE subtle CTA in the conclusion.\n- ONE portfolio proof link in the body.\n- ZERO \"hire me\" vibes anywhere.\n</lead_generation_framework>\n\n<output_format>\nReturn ONLY valid JSON. No markdown fences around the output.\n\n{\n  \"formatted_markdown\": \"# Title\\n\\nBody content...\",\n  \"structured_data\": {\n     \"seo\": {\n        \"title\": \"The exact title (50-60 chars, includes primary keyword)\",\n        \"slug\": \"url-friendly-slug-with-keyword\",\n        \"meta_description\": \"Compelling summary (150-160 chars) with problem and solution.\",\n        \"keywords\": [\"primary keyword\", \"problem keyword\", \"solution keyword\"],\n        \"tags\": [\"tag1\", \"tag2\", \"tag3\"]\n     }\n  }\n}\n\n**Mandatory Markdown Structure:**\n1. **TL;DR Block (Top):** 2-3 sentences. Problem ‚Üí Solution ‚Üí Outcome.\n2. **Prerequisites Section:** Bulleted list of what readers need to know.\n3. **H2/H3 Hierarchy:** H2s in question-format when possible.\n4. **Callout Blocks:** Use `> **Pro Tip:**` and `> ‚ö†Ô∏è **Gotcha:**` for emphasis.\n5. **Conclusion with CTA:** End with \"What's Next\" section and ONE soft call-to-action.\n</output_format>\n\n</system_instructions>",
              "role": "model"
            },
            {
              "content": "=<context>\n### MY PERSONAL & PROFESSIONAL PROFILE\n{{ $json.personalContext }}\n\n### THE BLUEPRINT FOR THE ARTICLE\n{{ $json.strategy }}\n\n### CONTENT METADATA (CRITICAL FOR ADAPTIVE LENGTH)\n- Title: {{ $json.sourceContent.title }}\n- Category: {{ $json.sourceContent.primaryCategory }}\n- Source Word Count: {{ $json.sourceContent.wordCount }}\n\n### THE CORE CONTENT (My Real-World Implementations)\nThis is the most critical input. The entire article must be built around the examples, code, and projects discussed here.\n{{ $json.sourceContent.fullText }}\n\n### COMPLEMENTARY SEO & RESEARCH DATA\nUse this to expand upon the core content and optimize for search.\n{{ $json.research }}\n</context>\n<task>\n**Mission:** Synthesize the `sourceContent` into a high-performance, career-building blog asset.\n\n**Execution Checklist:**\n1. **Adaptive Length:** Check `sourceContent.wordCount`. Select Quick Win (800-1200), Deep Dive (1200-1800), or Definitive Guide (1800-2500) per `<critical_instruction>`.\n2. **Research Injection:** \n   - Use `research.market_pulse.urgency_trigger` to make the intro timely.\n   - Use `research.linkedin.business_value_stat` for concrete metrics.\n   - Use `research.blog.seo_keywords_primary` in title and H2s.\n   - Use `research.blog.seo_keywords_longtail` naturally in problem sections.\n   - Use `research.blog.competitor_gap` to differentiate‚Äîcover what others miss.\n3. **AI Discovery:** Write the \"Expert Card\" in the first 150 words. Use \"Answer Box\" formatting for all H2s.\n4. **Lead Gen:** Insert ONE \"Portfolio Proof\" link in the body and ONE soft CTA in the conclusion per `<lead_generation_framework>`.\n5. **Strategy:** Follow `strategy.platform_strategies.blog.structure` and `must_include` strictly.\n\n**Constraint:** Output MUST be valid JSON. No markdown fences.\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        6864,
        1664
      ],
      "id": "c47db764-6d0d-4b0b-b3af-bbb1e6d1f7e1",
      "name": "Blog Content Generation",
      "retryOnFail": true,
      "maxTries": 5,
      "credentials": {
        "googlePalmApi": {
          "id": "8RkzNZusS3GG9BNO",
          "name": "Google Gemini(PaLM) Api key 4"
        }
      }
    }
  ],
  "connections": {
    "When clicking 'Execute workflow'": {
      "main": [
        [
          {
            "node": "Notion ‚Äì Get Ready Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion ‚Äì Get Ready Content": {
      "main": [
        [
          {
            "node": "Filter ‚Äì Has Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter ‚Äì Has Content": {
      "main": [
        [
          {
            "node": "Code ‚Äì Select Content & Profile",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code ‚Äì Select Content & Profile": {
      "main": [
        [
          {
            "node": "Create folder for title",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion ‚Äì Update to Processing": {
      "main": [
        [
          {
            "node": "Notion ‚Äì Extract All Blocks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion ‚Äì Extract All Blocks": {
      "main": [
        [
          {
            "node": "Code ‚Äì Extract & Process Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code ‚Äì Extract & Process Content": {
      "main": [
        [
          {
            "node": "Code ‚Äì Personal Context Builder",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "ID Structuring",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "ID Structuring": {
      "main": [
        [
          {
            "node": "Notion ‚Äì Create Drafts & Request Approval1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code ‚Äì Personal Context Builder": {
      "main": [
        [
          {
            "node": "Perplexity ‚Äì Research Hashtags & Timing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code ‚Äì CONTEXT MERGER": {
      "main": [
        [
          {
            "node": "Gemini - AI CONTENT STRATEGIST",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process & Format Twitter Draft": {
      "main": [
        [
          {
            "node": "Create Twitter Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process & Format LinkedIn Draft": {
      "main": [
        [
          {
            "node": "Create LinkedIn Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create folder for title": {
      "main": [
        [
          {
            "node": "Notion ‚Äì Update to Processing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Perplexity ‚Äì Research Hashtags & Timing": {
      "main": [
        [
          {
            "node": "Code ‚Äì CONTEXT MERGER",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create LinkedIn Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Create Twitter Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process & Format Blog Draft": {
      "main": [
        [
          {
            "node": "Create Blog Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Blog Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Process AI Strategy & MERGE CONTEXT": {
      "main": [
        [
          {
            "node": "Are Images Needed?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - Twitter Selected?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - LinkedIn Selected?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - Blog Selected?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Are Images Needed?": {
      "main": [
        [
          {
            "node": "Process & Format Image Tasklist",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process & Format Image Tasklist": {
      "main": [
        [
          {
            "node": "Create Image Tasklist",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Image Tasklist": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "IF - Twitter Selected?": {
      "main": [
        [
          {
            "node": "Gemini - Twitter Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op Twitter Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - LinkedIn Selected?": {
      "main": [
        [
          {
            "node": "Gemini - LinkedIn Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op LinkedIn Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - Blog Selected?": {
      "main": [
        [
          {
            "node": "Blog Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op Blog Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code - No-Op Twitter Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code - No-Op LinkedIn Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Code - No-Op Blog Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Gemini - AI CONTENT STRATEGIST": {
      "main": [
        [
          {
            "node": "Process AI Strategy & MERGE CONTEXT",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - Twitter Content Generation": {
      "main": [
        [
          {
            "node": "Process & Format Twitter Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - LinkedIn Content Generation": {
      "main": [
        [
          {
            "node": "Process & Format LinkedIn Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Blog Content Generation": {
      "main": [
        [
          {
            "node": "Process & Format Blog Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "meta": {
    "instanceId": "2aff0c99a9b9ea9c976d68c5887d32445a6bdc6f59f99592eb5b4c4dbaf3d92e"
  }
}