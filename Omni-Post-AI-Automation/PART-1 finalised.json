{
    "nodes": [
        {
            "parameters": {},
            "type": "n8n-nodes-base.manualTrigger",
            "typeVersion": 1,
            "position": [
                1776,
                2400
            ],
            "id": "57b96b2a-02d9-4bd0-a8fb-fc493d9cd8b2",
            "name": "When clicking 'Execute workflow'"
        },
        {
            "parameters": {
                "resource": "databasePage",
                "operation": "getAll",
                "databaseId": {
                    "__rl": true,
                    "value": "21a34bf1-f7e5-8035-b16f-d5ebf63a86a9",
                    "mode": "list"
                },
                "returnAll": true,
                "filterType": "manual",
                "filters": {
                    "conditions": [
                        {
                            "key": "Status|select",
                            "condition": "equals",
                            "selectValue": "Ready to Generate"
                        }
                    ]
                },
                "options": {
                    "sort": {
                        "sortValue": [
                            {
                                "key": "ManualOrder|number",
                                "direction": "ascending"
                            },
                            {
                                "key": "Priority|select",
                                "direction": "ascending"
                            },
                            {
                                "timestamp": true,
                                "key": "created_time",
                                "direction": "ascending"
                            }
                        ]
                    }
                }
            },
            "id": "ac78d29e-6134-4cf8-8ff3-bdc57d5baeb2",
            "name": "Notion â€“ Get Ready Content",
            "type": "n8n-nodes-base.notion",
            "typeVersion": 2,
            "position": [
                2000,
                2352
            ],
            "retryOnFail": true,
            "waitBetweenTries": 2000,
            "credentials": {
                "notionApi": {
                    "id": "je8hKPK6RzYSk4JA",
                    "name": "Notion account 2"
                }
            }
        },
        {
            "parameters": {
                "conditions": {
                    "options": {
                        "caseSensitive": true,
                        "leftValue": "",
                        "typeValidation": "strict",
                        "version": 1
                    },
                    "conditions": [
                        {
                            "leftValue": "={{ $input.all().length > 0 }}",
                            "rightValue": true,
                            "operator": {
                                "type": "boolean",
                                "operation": "equals"
                            },
                            "id": "6855ced2-6ef0-4ea1-acd1-a9326c4b67f9"
                        }
                    ],
                    "combinator": "and"
                },
                "options": {}
            },
            "id": "1a58c3cf-7f2d-4cc8-a888-427b634cf439",
            "name": "Filter â€“ Has Content",
            "type": "n8n-nodes-base.if",
            "typeVersion": 2,
            "position": [
                2224,
                2352
            ]
        },
        {
            "parameters": {
                "jsCode": "// CONTENT SELECTION & PROFILE SETUP\nconst items = $input.all();\n\nif (!items || items.length === 0) {\nÂ  console.log('âŒ No content ready for processing');\nÂ  return [];\n}\n\n// Get first item (priority + FIFO)\nconst item = items[0].json;\nconsole.log('ðŸŽ¯ Processing item:', item.id);\n\n// Enhanced property extraction with fallbacks\nconst getProperty = (obj, path, defaultValue = '') => {\nÂ  const keys = path.split('.');\nÂ  let result = obj;\nÂ  for (const key of keys) {\nÂ  Â  if (result && typeof result === 'object' && key in result) {\nÂ  Â  Â  result = result[key];\nÂ  Â  } else {\nÂ  Â  Â  return defaultValue;\nÂ  Â  }\nÂ  }\nÂ  return result || defaultValue;\n};\n\nconst title = getProperty(item, 'properties.Content Pages.title.0.plain_text') || \nÂ  Â  Â  Â  Â  Â  Â  getProperty(item, 'properties.title.title.0.plain_text') ||\nÂ  Â  Â  Â  Â  Â  Â  getProperty(item, 'properties.Name.title.0.plain_text') ||\nÂ  Â  Â  Â  Â  Â  Â  getProperty(item, 'name') || \nÂ  Â  Â  Â  Â  Â  Â  'Untitled Content';\n\nconst category = getProperty(item, 'properties.Category.select.name') || \nÂ  Â  Â  Â  Â  Â  Â  Â  Â 'Learning';\n\nconst priority = getProperty(item, 'properties.Priority.select.name') || \nÂ  Â  Â  Â  Â  Â  Â  Â  Â 'normal';\n\n// Complete user profile for authentic content\nconst userProfile = {\nÂ  name: 'Aman Surya',\nÂ  role: 'Fresh CS Graduate & AI/ML Enthusiast',\nÂ  focus: 'Building with Next.js/React/n8n, seeking AI PM roles',\nÂ  personality: 'Authentic, curious, growth-minded, detail-oriented',\nÂ  expertise: ['JavaScript', 'React', 'Next.js', 'n8n', 'AI/ML', 'Automation', 'Product Management'],\nÂ  audience: 'Tech community, AI enthusiasts, developers, PM aspirants',\nÂ  timezone: 'Asia/Kolkata',\nÂ  writing_style: {\nÂ  Â  twitter: 'Casual, engaging, thread-friendly, question-driven, community-focused',\nÂ  Â  linkedin: 'Professional, detailed, story-driven, insight-rich, career-focused'\nÂ  },\nÂ  content_goals: {\nÂ  Â  primary: 'Build technical credibility for AI PM roles',\nÂ  Â  secondary: 'Help fellow developers learn and grow',\nÂ  Â  engagement: 'Create genuine discussions and valuable connections'\nÂ  }\n};\n\nconst sessionId = `session_${Date.now()}_${(item.id || '').toString().substring(0, 8)}`;\n\nreturn [{\nÂ  json: {\nÂ  Â  id: item.id,\nÂ  Â  title: title,\nÂ  Â  category: category,\nÂ  Â  priority: priority,\nÂ  Â  sessionId: sessionId,\nÂ  Â  userProfile: userProfile,\nÂ  Â  processingStartTime: new Date().toISOString(),\nÂ  Â  remainingItems: items.length - 1,\nÂ  Â  originalId: item.id\nÂ  }\n}];"
            },
            "id": "b52c9b71-f0b5-4aa2-8d61-a3d8eb5b50bf",
            "name": "Code â€“ Select Content & Profile",
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                2448,
                2352
            ]
        },
        {
            "parameters": {
                "resource": "databasePage",
                "operation": "update",
                "pageId": {
                    "__rl": true,
                    "value": "={{ $('Code â€“ Select Content & Profile').item.json.id }}",
                    "mode": "id"
                },
                "propertiesUi": {
                    "propertyValues": [
                        {
                            "key": "Status|select",
                            "type": "select",
                            "selectValue": "Generating"
                        },
                        {
                            "key": "SessionID|rich_text",
                            "richText": true,
                            "text": {
                                "text": [
                                    {
                                        "text": "={{ $('Code â€“ Select Content & Profile').item.json.sessionId }}",
                                        "annotationUi": {}
                                    }
                                ]
                            }
                        },
                        {
                            "key": "Processing Started|date",
                            "type": "date",
                            "date": "={{ $('Code â€“ Select Content & Profile').item.json.processingStartTime }}"
                        },
                        {
                            "key": "Notes|rich_text",
                            "richText": true,
                            "text": {
                                "text": [
                                    {
                                        "text": "=ðŸ”„ Processing started\\nSession: {{ $('Code â€“ Select Content & Profile').item.json.sessionId }}\\nPriority: {{ $('Code â€“ Select Content & Profile').item.json.priority }}\\nCategory: {{ $('Code â€“ Select Content & Profile').item.json.category }}\\nStarted: {{ new Date().toLocaleString('en-IN', {timeZone: 'Asia/Kolkata'}) }} IST",
                                        "annotationUi": {}
                                    }
                                ]
                            }
                        }
                    ]
                },
                "options": {}
            },
            "id": "0a7e4f9d-d0e1-4f4d-a4e1-fa85fb6ff7be",
            "name": "Notion â€“ Update to Processing",
            "type": "n8n-nodes-base.notion",
            "typeVersion": 2,
            "position": [
                2896,
                2352
            ],
            "credentials": {
                "notionApi": {
                    "id": "je8hKPK6RzYSk4JA",
                    "name": "Notion account 2"
                }
            }
        },
        {
            "parameters": {
                "resource": "block",
                "operation": "getAll",
                "blockId": {
                    "__rl": true,
                    "value": "={{ $json.id }}",
                    "mode": "id"
                },
                "returnAll": true,
                "fetchNestedBlocks": true,
                "simplifyOutput": false
            },
            "id": "f681036d-756a-4506-af73-d94cb4fdd884",
            "name": "Notion â€“ Extract All Blocks",
            "type": "n8n-nodes-base.notion",
            "typeVersion": 2.2,
            "position": [
                3120,
                2352
            ],
            "credentials": {
                "notionApi": {
                    "id": "je8hKPK6RzYSk4JA",
                    "name": "Notion account 2"
                }
            }
        },
        {
            "parameters": {
                "jsCode": "// PRODUCTION-READY NOTION CONTENT EXTRACTION (V2 - FIXED OUTPUT)\n\ntry {\n  console.log('ðŸ” Starting comprehensive content extraction...');\n  \n  const extractItems = $items('Notion â€“ Extract All Blocks');\n  if (!extractItems?.length) {\n    throw new Error('No blocks from Notion â€“ Extract All Blocks');\n  }\n  console.log(`ðŸ“¥ Processing ${extractItems.length} block items`);\n  \n  const allBlocks = extractItems.map(item => item.json);\n  const blockMap = new Map();\n  const topLevelBlocks = [];\n  \n  // Build hierarchical tree\n  allBlocks.forEach(block => {\n    blockMap.set(block.id, { ...block, children: [] });\n  });\n  \n  allBlocks.forEach(block => {\n    if (block.parent?.type === 'page_id') {\n      topLevelBlocks.push(blockMap.get(block.id));\n    } else if (block.parent?.type === 'block_id') {\n      const parent = blockMap.get(block.parent.block_id);\n      if (parent) {\n        parent.children.push(blockMap.get(block.id));\n      }\n    }\n  });\n  \n  console.log(`ðŸŒ³ Built tree with ${topLevelBlocks.length} top-level blocks`);\n  \n  // Text extraction helper\n  const extractText = (richTextArray) => {\n    if (!Array.isArray(richTextArray)) return '';\n    return richTextArray\n      .map(item => item.plain_text || item.text?.content || '')\n      .join('')\n      .trim();\n  };\n  \n  // Image processing helper\n  const processImage = (url, caption = '') => {\n    if (!url) return null;\n    try {\n      return {\n        url: url,\n        caption: caption,\n        alt_text: caption || 'Content image',\n        processing_needed: true\n      };\n    } catch {\n      return null;\n    }\n  };\n  \n  // Recursive block renderer\n  function renderBlock(block, level = 0) {\n    if (!block?.type) return { text: '', sections: [], images: [] };\n    \n    const indent = '  '.repeat(level);\n    const blockData = block[block.type] || {};\n    let content = '';\n    let sections = [];\n    let images = [];\n    let text = extractText(blockData?.rich_text || blockData?.text || []);\n    \n    switch (block.type) {\n      case 'heading_1':\n        content = `\\\\n# ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 1, title: text, content: '', id: block.id });\n        break;\n      case 'heading_2':\n        content = `\\\\n## ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 2, title: text, content: '', id: block.id });\n        break;\n      case 'heading_3':\n        content = `\\\\n### ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 3, title: text, content: '', id: block.id });\n        break;\n      case 'paragraph':\n        if (text) content = `${text}\\\\n\\\\n`;\n        break;\n      case 'bulleted_list_item':\n        if (text) content = `${indent}- ${text}\\\\n`;\n        break;\n      case 'numbered_list_item':\n        if (text) content = `${indent}1. ${text}\\\\n`;\n        break;\n      case 'toggle':\n        if (text) {\n          content = `\\\\nâ–¶ï¸ ${text}\\\\n`;\n          sections.push({ level: 4, title: text, content: '', id: block.id, type: 'toggle' });\n        }\n        break;\n      case 'callout':\n        const icon = blockData?.icon?.emoji || 'ðŸ’¡';\n        if (text) content = `\\\\n${icon} **${text}**\\\\n\\\\n`;\n        break;\n      case 'quote':\n        if (text) content = `\\\\n> ${text}\\\\n\\\\n`;\n        break;\n      case 'code':\n        const language = blockData?.language || 'text';\n        if (text) {\n          content = `\\\\n\\`\\`\\`${language}\\\\n${text}\\\\n\\`\\`\\`\\\\n\\\\n`;\n          sections.push({ level: 5, title: `Code: ${language}`, content: text, id: block.id, type: 'code' });\n        }\n        break;\n      case 'divider':\n        content = '\\\\n---\\\\n\\\\n';\n        break;\n      case 'image':\n        const imageUrl = blockData?.file?.url || blockData?.external?.url;\n        if (imageUrl) {\n          const processedImage = processImage(imageUrl, text);\n          if (processedImage) {\n            images.push(processedImage);\n            content = `\\\\n[ðŸ“¸ Image: ${text || 'Visual content'}]\\\\n\\\\n`;\n          }\n        }\n        break;\n      case 'video':\n        content = `\\\\n[ðŸŽ¥ Video: ${text || 'Video content'}]\\\\n\\\\n`;\n        break;\n      case 'bookmark':\n        const bookmarkUrl = blockData?.url || '';\n        if (bookmarkUrl) content = `\\\\n[ðŸ”— ${text || bookmarkUrl}](${bookmarkUrl})\\\\n\\\\n`;\n        break;\n      default:\n        if (text) content = `${indent}${text}\\\\n\\\\n`;\n        break;\n    }\n    \n    // Process children recursively\n    if (block.children?.length) {\n      const childrenResult = block.children\n        .map(child => renderBlock(child, level + 1))\n        .reduce((acc, result) => {\n          acc.text += result.text;\n          acc.sections = acc.sections.concat(result.sections);\n          acc.images = acc.images.concat(result.images);\n          return acc;\n        }, { text: '', sections: [], images: [] });\n      \n      content += childrenResult.text;\n      sections = sections.concat(childrenResult.sections);\n      images = images.concat(childrenResult.images);\n    }\n    \n    return { text: content, sections: sections, images: images };\n  }\n  \n  // Process all blocks\n  const result = topLevelBlocks\n    .map(block => renderBlock(block))\n    .reduce((acc, blockResult) => {\n      acc.text += blockResult.text;\n      acc.sections = acc.sections.concat(blockResult.sections);\n      acc.images = acc.images.concat(blockResult.images);\n      return acc;\n    }, { text: '', sections: [], images: [] });\n  \n  // Clean up text\n  let fullText = result.text\n    .replace(/\\n{3,}/g, '\\n\\n')\n    .replace(/\\s+$/gm, '')\n    .trim();\n  \n  const stats = {\n    totalBlocks: allBlocks.length,\n    processedBlocks: topLevelBlocks.length,\n    characterCount: fullText.length,\n    wordCount: fullText.split(/\\s+/).filter(w => w.length > 0).length,\n    sections: result.sections.length,\n    images: result.images.length,\n    toggleSections: result.sections.filter(s => s.type === 'toggle').length,\n    codeSections: result.sections.filter(s => s.type === 'code').length\n  };\n  \n  console.log('âœ… Content extraction complete:', stats);\n  \n  // â­ KEY FIX: Wrap everything in 'sourceContent'\n  return [{\n    json: {\n      sourceContent: {\n        name: $('Notion â€“ Update to Processing').first().json.name,\n        categories: $('Notion â€“ Update to Processing').first().json.property_category,\n        fullText: fullText,\n        sections: result.sections,\n        images: result.images,\n        extractionStats: stats,\n        contentMetadata: {\n          totalSections: result.sections.length,\n          hasImages: result.images.length > 0,\n          hasCode: result.sections.some(s => s.type === 'code'),\n          hasToggles: result.sections.some(s => s.type === 'toggle'),\n          hasLists: fullText.includes('- ') || /^\\d+\\.\\s/m.test(fullText),\n          complexity: stats.wordCount > 800 ? 'high' : stats.wordCount > 400 ? 'medium' : 'low'\n        }\n      }\n    }\n  }];\n  \n} catch (error) {\n  console.error('âŒ Content extraction failed:', error.message);\n  return [{\n    json: {\n      sourceContent: {\n        fullText: `Content extraction error: ${error.message}`,\n        sections: [],\n        images: [],\n        extractionStats: { error: true },\n        contentMetadata: { error: error.message }\n      }\n    }\n  }];\n}\n"
            },
            "id": "cfc2ddab-2cbc-4871-9c03-5861082459da",
            "name": "Code â€“ Extract & Process Content",
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                3344,
                2352
            ]
        },
        {
            "parameters": {
                "numberInputs": 6
            },
            "type": "n8n-nodes-base.merge",
            "typeVersion": 3.2,
            "position": [
                4752,
                2480
            ],
            "id": "8741abe3-69fa-435d-b53f-fbfa9389d9c4",
            "name": "Merge2"
        },
        {
            "parameters": {
                "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// CONTEXT ADAPTER v3 (Production-Ready)\n// Purpose: Merge Portfolio API data + Notion Content + Strategic Context\n// \n// Architecture:\n//   Portfolio API â†’ Facts & Proof (skills, projects, metrics)\n//   personalContext â†’ Strategy & Voice (goals, hooks, forbidden phrases)\n//   Notion Content â†’ Raw source material for repurposing\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst contentNode = $('Code â€“ Extract & Process Content').first().json;\nconst contextRaw = $('Context - Standardize & Filter').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 1: STATIC STRATEGIC CONTEXT (Never from API - Your \"ContentDNA\")\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nconst strategicContext = {\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.1 POSITIONING & CAREER STRATEGY\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  positioning: {\n    headline: \"Full-Stack Agentic Developer | AI Automation Engineer + Next.js Developer\",\n    experienceLevel: \"Early Career (0-2 years) | Senior-level output in n8n, SEO/GEO, workflow automation\",\n    location: \"Delhi/NCR + Remote (India & Global)\",\n    availability: \"Open to full-time, contract, freelance\",\n    \n    // The T-Shaped Stack (Your Unfair Advantage)\n    tStack: {\n      depth: {\n        area: \"Multi-Agent Orchestration\",\n        skills: [\"LangGraph\", \"CrewAI\", \"n8n AI Agents\"],\n        proof: \"74-node production workflows with 99.7% reliability\"\n      },\n      breadth: [\n        { area: \"Frontend Excellence\", detail: \"Next.js 15, 95+ Lighthouse scores\" },\n        { area: \"Workflow Automation\", detail: \"15+ production workflows deployed\" },\n        { area: \"Technical SEO/GEO\", detail: \"#1 Google rankings, AI Search visibility\" }\n      ],\n      pitch: \"Most AI developers build the brain but not the body. I do both.\"\n    }\n  },\n  \n  targetRoles: [\n    \"Technical Solutions Engineer (TSE)\",\n    \"Associate Product Manager (APM)\",\n    \"Developer Relations (DevRel)\",\n    \"Growth Engineer\",\n    \"Founder's Office (Technical)\",\n    \"AI Automation Engineer\",\n    \"Agentic AI Developer\",\n    \"Full-Stack AI Developer\"\n  ],\n  \n  hiddenGoals: {\n    primary: \"Get inbound TSE/APM/DevRel offers from target companies\",\n    secondary: \"Attract â‚¹75K-3L freelance automation projects organically\",\n    tertiary: \"Build reputation as Agentic AI + n8n expert in India\",\n    longTerm: \"Transition to robotics/edge AI within 2-3 years\"\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.2 CONTENT VOICE (How to Sound Like Aman)\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  voice: {\n    attributes: [\n      \"Authentic & transparent - share real struggles + wins\",\n      \"Detail-oriented with technical depth\",\n      \"Growth-minded - always learning, never pretending to know it all\",\n      \"Practical over theoretical - show real code, real metrics\",\n      \"Builds in public - document the journey, not just the destination\",\n      \"Helpful & community-focused - teach what you learn\"\n    ],\n    \n    toneGuidelines: [\n      \"Use 'I' statements, not 'we' (you're a solo builder)\",\n      \"Short paragraphs (2-3 sentences max for social)\",\n      \"Lead with the insight, not the backstory\",\n      \"Be opinionated on tech choices - strong views, loosely held\",\n      \"Admit mistakes openly - it builds trust\"\n    ],\n    \n    forbiddenPhrases: [\n      \"In today's digital landscape\",\n      \"Delve\", \"Unlock\", \"Unleash\", \"Leverage\",\n      \"Game-changer\", \"Revolutionary\", \"Cutting-edge\", \"Synergy\",\n      \"Humbled to announce\", \"Thrilled to share\", \"Excited to announce\",\n      \"Let's dive in\", \"Without further ado\", \"Honored to\",\n      \"At the end of the day\", \"It goes without saying\",\n      \"Take it to the next level\", \"Circle back\"\n    ]\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.3 CONTENT PILLARS (What to Post About)\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  contentPillars: [\n    {\n      pillar: \"Build-in-Public\",\n      weight: 0.35,\n      hashtags: [\"#buildinpublic\", \"#indiedev\", \"#solofounder\"],\n      topics: [\"Project updates\", \"Revenue milestones\", \"Failures & pivots\", \"Tool reveals\"]\n    },\n    {\n      pillar: \"n8n & Automation Deep Dives\",\n      weight: 0.30,\n      hashtags: [\"#n8n\", \"#automation\", \"#nocode\", \"#lowcode\", \"#workflowautomation\"],\n      topics: [\"Workflow breakdowns\", \"Error handling patterns\", \"Self-healing architecture\", \"API integration tips\"]\n    },\n    {\n      pillar: \"AI/Agentic Systems\",\n      weight: 0.25,\n      hashtags: [\"#AgenticAI\", \"#LangChain\", \"#LangGraph\", \"#AI\", \"#LLM\"],\n      topics: [\"RAG implementations\", \"Multi-agent patterns\", \"LLM orchestration\", \"AI in production\"]\n    },\n    {\n      pillar: \"Career & Freelance\",\n      weight: 0.10,\n      hashtags: [\"#freelance\", \"#remotework\", \"#techcareers\", \"#developerlife\"],\n      topics: [\"Client acquisition\", \"Portfolio strategy\", \"Pricing lessons\", \"Work-life integration\"]\n    }\n  ],\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.4 PROJECT HOOKS (Story Starters - The \"Content Seeds\")\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  projectHooks: {\n    \"aviators-training-centre\": {\n      hooks: [\n        \"I turned a flight school's website into their #1 sales channel. Here's the system:\",\n        \"From 0 to â‚¹3L revenue with just SEO + n8n automation. Thread ðŸ§µ\",\n        \"My client was losing leads to a contact form nobody checked. I built a 14-node solution.\",\n        \"How I achieved 95+ Lighthouse scores on a Next.js 15 production site:\",\n        \"80% reduction in manual tasks. Here's the n8n workflow that made it happen:\"\n      ],\n      theStruggle: \"Spent 2 days debugging Firebase webhook triggers that fired twice. Turns out I needed idempotency keys.\",\n      theBreakthrough: \"Realized n8n + Airtable + Resend could replace their entire CRM workflow.\",\n      lessonLearned: \"SEO compounds. The â‚¹3L didn't come from one postâ€”it came from 6 months of #1 rankings.\",\n      hotTakes: [\n        \"WordPress is dead for client projects. Next.js + Sanity is the 2025 stack.\"\n      ]\n    },\n    \"n8n-automation-suite\": {\n      hooks: [\n        \"I post to LinkedIn and Twitter/X with one click. Here's my 74-node system:\",\n        \"Stop copy-pasting content across platforms. Automate it.\",\n        \"Built-in-public content flywheel: Notion draft â†’ viral post in 60 seconds.\",\n        \"The architecture behind my self-healing content automation:\",\n        \"Why I moved from Zapier to self-hosted n8n (and saved â‚¹15K/month):\"\n      ],\n      theStruggle: \"Twitter API rate limits almost killed this project at 3 AM. OAuth 1.0a is pain.\",\n      theBreakthrough: \"Dead-letter queues changed everything. No more silent failures.\",\n      lessonLearned: \"Build for failure first. Happy path is the easy part.\",\n      hotTakes: [\n        \"Zapier is for prototypes. n8n is for production.\",\n        \"If your automation can't self-heal, it's just a scheduled script.\"\n      ]\n    },\n    \"n8n-github-backup\": {\n      hooks: [\n        \"My n8n instance crashed on a Friday. No backups. Never again.\",\n        \"99.9% recovery rate with self-healing retry logic. Here's the architecture:\",\n        \"How I built a dual-stream backup system that handles 1000+ workflows:\",\n        \"The credential scrubbing pattern that makes your n8n repos public-safe:\",\n        \"GitHub's 30 req/min limit forced me to redesign everything. Best decision ever.\"\n      ],\n      theStruggle: \"First version hit rate limits constantly. Had to completely rethink the architecture.\",\n      theBreakthrough: \"Loop-to-Webhook pattern: Orchestration and execution in separate streams.\",\n      lessonLearned: \"Rate limits aren't bugsâ€”they're design constraints. Embrace them.\",\n      hotTakes: [\n        \"If you're not backing up your n8n workflows to git, you're one crash away from losing everything.\"\n      ]\n    },\n    \"barkat-enterprise\": {\n      hooks: [\n        \"3,000+ viewers for a tiles distributor website. Here's how React won:\",\n        \"PDF catalogues in-browser with PDFJS. No downloads, no friction.\",\n        \"My first B2B freelance project: lessons from building for a traditional business.\"\n      ],\n      theStruggle: \"Client had no digital presence. Had to explain every tech decision in simple terms.\",\n      theBreakthrough: \"PDF viewer eliminated their biggest pain pointâ€”printing and distributing catalogues.\",\n      lessonLearned: \"Simple features that remove friction > complex features that impress developers.\"\n    },\n    \"av-newsstream\": {\n      hooks: [\n        \"9 API keys. 10-minute cache. 90% reduction in API calls. Here's the system:\",\n        \"How I solved the free-tier API limit problem with intelligent key rotation:\",\n        \"Text-to-speech in a news app? Here's why I added it and what I learned.\"\n      ],\n      theStruggle: \"NewsAPI's 100 req/day limit seemed impossible to work around.\",\n      theBreakthrough: \"ApiKeyManager.js with health tracking and automatic failover.\",\n      lessonLearned: \"Caching is the most underrated optimization. 10 minutes saved 90% of API calls.\"\n    },\n    \"foodah\": {\n      hooks: [\n        \"14,000+ lines of JSON. 60fps scrolling. Here's how I built Foodah:\",\n        \"Custom React hooks for everything: useOnlineStatus, useFallbackImage, useRestaurantMenu.\",\n        \"Shimmer UI and lazy loading: The performance patterns that matter.\"\n      ],\n      theStruggle: \"Swiggy API returns deeply nested, inconsistent data. Optional chaining saved my sanity.\",\n      theBreakthrough: \"useFallbackImage hook that replaces broken images with random alternatives seamlessly.\",\n      lessonLearned: \"Never trust external APIs to be consistent. Always have fallbacks.\"\n    },\n    \"portfolio-website\": {\n      hooks: [\n        \"6,000+ project views. 95+ Lighthouse. Here's my portfolio stack:\",\n        \"Why I chose Sanity CMS over Contentful for my developer portfolio:\",\n        \"The Omni-Post workflow that auto-distributes every blog post I write.\"\n      ],\n      theStruggle: \"Redesigned 3 times before landing on the current system.\",\n      theBreakthrough: \"Integrating n8n webhooks with Sanity CMS for automated social distribution.\",\n      lessonLearned: \"Your portfolio is never done. Treat it like a product, not a project.\"\n    }\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.5 PLATFORM-SPECIFIC RULES\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  platformRules: {\n    linkedin: {\n      maxLength: 3000,\n      optimalLength: \"800-1200 chars for engagement\",\n      style: \"Professional but not corporate. Use line breaks aggressively. Hook in first 2 lines.\",\n      cta: \"Follow for daily AI automation breakdowns.\",\n      formatting: [\n        \"Use emoji bullets sparingly (â†’, âœ…, ðŸ”¥)\",\n        \"One idea per paragraph\",\n        \"End with a question to drive comments\"\n      ],\n      emojiUsage: \"Minimal. 2-3 max. No emoji spam.\",\n      hashtagCount: \"3-5 at the end, never inline\"\n    },\n    twitter: {\n      maxLength: 280,\n      style: \"Punchy. Opinionated. Thread-friendly. No fluff.\",\n      cta: \"Follow @_AmanSurya for more.\",\n      formatting: [\n        \"Front-load the value\",\n        \"Use numbers and specifics\",\n        \"Thread opener should stand alone\"\n      ],\n      emojiUsage: \"Match tech twitter energy. More acceptable here.\",\n      hashtagCount: \"1-2 max, only if organic\"\n    }\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.6 FUTURE ROADMAP (For relevant content positioning)\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  futureRoadmap: {\n    currentFocus: \"Agentic Systems Era - LangGraph + CrewAI + n8n AI Agents\",\n    learning: [\n      \"Advanced LangGraph patterns\",\n      \"Multi-agent orchestration at scale\",\n      \"WebSockets & real-time communication\",\n      \"Docker & containerization for edge deployment\"\n    ],\n    yearEnd2026: \"Launch Personal RAG assistant + production LangGraph agents\",\n    longTermVision: \"Transition to robotics/edge AIâ€”bringing agentic intelligence to physical systems\",\n    philosophyNote: \"The T-Stack: deep in orchestration, broad across the stack. That's the unfair advantage.\"\n  }\n};\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 2: SAFE PARSE OF INCOMING API/GEMINI DATA\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nlet portfolioData = {};\ntry {\n  // Handle both stringified JSON and direct object from Gemini/API\n  const text = contextRaw.content?.parts?.[0]?.text || JSON.stringify(contextRaw);\n  const cleanJson = text.replace(/```json/g, '').replace(/```/g, '').trim();\n  portfolioData = JSON.parse(cleanJson);\n} catch (e) {\n  console.log('Portfolio Data Parse Warning:', e.message);\n  // Fallback with essential identity\n  portfolioData = {\n    core: {\n      name: \"Aman Suryavanshi\",\n      role: \"AI Workflow Architect & Systems Builder\",\n      tagline: \"I Build Self-Healing AI Systems That Drive Revenue\"\n    }\n  };\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 3: INTELLIGENT CONTENT SUMMARIZATION (Cost-Optimized)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nfunction intelligentSummarize(sourceContent) {\n  if (!sourceContent) {\n    return {\n      summary: \"No content available\",\n      structure: \"empty\",\n      wordCount: 0,\n      complexity: \"unknown\",\n      keyTopics: []\n    };\n  }\n\n  const { fullText, sections, extractionStats, summary } = sourceContent;\n  let outputSummary = \"\";\n\n  // Priority 1: Use pre-extracted summary if available\n  if (summary && summary.length > 100) {\n    outputSummary = summary.substring(0, 1500);\n  } else {\n    // Priority 2: Section headings (highest signal-to-noise)\n    const sectionTitles = (sections || [])\n      .filter(s => s.title && s.title.length > 3)\n      .map(s => `â€¢ ${s.title}`)\n      .slice(0, 10)\n      .join('\\n');\n\n    if (sectionTitles) {\n      outputSummary += \"**Key Sections:**\\n\" + sectionTitles + \"\\n\\n\";\n    }\n\n    // Priority 3: First substantive content block\n    if (sections && sections.length > 0) {\n      const contentSection = sections.find(s => s.content && s.content.length > 50);\n      if (contentSection) {\n        outputSummary += \"**Core Content:**\\n\" +\n          contentSection.content.substring(0, 600).replace(/\\n+/g, ' ') + \"...\\n\";\n      }\n    }\n\n    // Priority 4: Fallback to fullText\n    if (!outputSummary && fullText) {\n      outputSummary = \"**Content Preview:**\\n\" + fullText.substring(0, 1200) + \"...\";\n    }\n  }\n\n  // Extract key topics for content matching (simple keyword extraction)\n  const topicKeywords = [\n    'n8n', 'automation', 'Next.js', 'React', 'AI', 'LLM', 'SEO', 'workflow',\n    'API', 'Firebase', 'Supabase', 'TypeScript', 'production', 'revenue'\n  ];\n  const textLower = (fullText || outputSummary).toLowerCase();\n  const keyTopics = topicKeywords.filter(kw => textLower.includes(kw.toLowerCase()));\n\n  return {\n    summary: outputSummary.substring(0, 2000),\n    structure: extractionStats?.hasToggles ? \"hierarchical\" : \"linear\",\n    wordCount: extractionStats?.wordCount || (fullText?.split(/\\s+/).length || 0),\n    complexity: extractionStats?.complexity || \"medium\",\n    sectionCount: sections?.length || 0,\n    hasCode: extractionStats?.codeSections > 0,\n    hasToggles: extractionStats?.toggleSections > 0,\n    keyTopics: keyTopics\n  };\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 4: CONTEXT MATCHING - Find relevant project hooks for the content\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nfunction findRelevantProjectHooks(contentSummary, projectHooks) {\n  const topics = contentSummary.keyTopics || [];\n  const contentText = (contentSummary.summary || '').toLowerCase();\n  \n  // Score each project by keyword matches\n  const projectScores = Object.entries(projectHooks).map(([projectId, hooks]) => {\n    let score = 0;\n    \n    // Check if project name is mentioned\n    if (contentText.includes(projectId.replace(/-/g, ' '))) score += 10;\n    \n    // Check topic overlaps\n    const projectKeywords = {\n      \"aviators-training-centre\": [\"next.js\", \"seo\", \"revenue\", \"firebase\", \"freelance\"],\n      \"n8n-automation-suite\": [\"n8n\", \"automation\", \"content\", \"linkedin\", \"twitter\", \"workflow\"],\n      \"n8n-github-backup\": [\"backup\", \"github\", \"n8n\", \"self-healing\", \"production\"],\n      \"barkat-enterprise\": [\"react\", \"pdf\", \"b2b\", \"freelance\"],\n      \"av-newsstream\": [\"api\", \"news\", \"caching\", \"react\"],\n      \"foodah\": [\"react\", \"api\", \"performance\", \"swiggy\"],\n      \"portfolio-website\": [\"portfolio\", \"sanity\", \"blog\", \"seo\"]\n    };\n    \n    (projectKeywords[projectId] || []).forEach(kw => {\n      if (contentText.includes(kw)) score += 2;\n    });\n    \n    return { projectId, hooks, score };\n  });\n  \n  // Return top 2 relevant projects\n  return projectScores\n    .filter(p => p.score > 0)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, 2)\n    .map(p => ({\n      projectId: p.projectId,\n      suggestedHooks: p.hooks.hooks?.slice(0, 2) || [],\n      theStruggle: p.hooks.theStruggle,\n      lessonLearned: p.hooks.lessonLearned\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 5: BUILD FINAL MERGED OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nconst sourceContent = contentNode.sourceContent || {};\nconst contentSummary = intelligentSummarize(sourceContent);\nconst relevantHooks = findRelevantProjectHooks(contentSummary, strategicContext.projectHooks);\n\n// Merge everything\nconst mergedContext = {\n  // From Portfolio API (facts, proof, metrics)\n  ...portfolioData,\n  \n  // Strategic layer (voice, goals, positioning)\n  strategic: strategicContext,\n  \n  // Matched content hooks for this specific post\n  matchedHooks: relevantHooks\n};\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 6: FINAL OUTPUT (Matching \"Part 1\" Schema)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nreturn [{\n  json: {\n    // The full merged context for AI nodes\n    personalContext: mergedContext,\n    \n    // Convenience: Quick access to key strategic elements for prompts\n    voiceGuide: {\n      attributes: strategicContext.voice.attributes,\n      forbidden: strategicContext.voice.forbiddenPhrases,\n      toneGuidelines: strategicContext.voice.toneGuidelines\n    },\n    \n    // Platform rules for the Distribution node\n    platformRules: strategicContext.platformRules,\n    \n    // Content pillars with weights for topic selection\n    contentPillars: strategicContext.contentPillars,\n    \n    // The T-Stack pitch (use in bios, intros)\n    tStackPitch: strategicContext.positioning.tStack.pitch,\n    \n    // Processed source content\n    sourceContent: sourceContent,\n    \n    // Optimized summary for LLM prompts (cost control)\n    contentSummary: contentSummary,\n    \n    // Matched hooks for this content\n    suggestedHooks: relevantHooks,\n    \n    // Keep full source for reference if needed\n    _fullSourceContent: sourceContent,\n    \n    // Metadata for debugging\n    _meta: {\n      version: \"v3.0\",\n      generatedAt: new Date().toISOString(),\n      portfolioDataKeys: Object.keys(portfolioData),\n      matchedProjects: relevantHooks.map(h => h.projectId)\n    }\n  }\n}];"
            },
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                2336,
                2640
            ],
            "id": "8875bd0d-d663-408c-8c2b-08187c2b107d",
            "name": "Code â€“ Personal Context Builder"
        },
        {
            "parameters": {
                "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// CONTEXT MERGER (fetches from previous node, merges with Perplexity)\n// Place after Perplexity node, queries previous (Personal Context Builder) node\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconsole.log('ðŸ”— Starting final context merger...');\n\n// 1. Fetch JSON data from the previous Personal Context Builder node\n// const previous = $('Code â€“ Personal Context Builder').first().json || {};\nconst previous = $('Code â€“ Personal Context Builder').first().json;\n\n// 2. Get Perplexity output directly â€“ comes as $json in this node\n// const perplexity = $json || {};\nconst perplexity = $json;\n\n// 3. Merge key blocks: always prefer Perplexity for \"research\", but get everything else from previous\n// const personalContext = previous.personalContext || {};\nconst personalContext = previous.personalContext;\nconst sourceContent = previous.sourceContent || {};\nconst contentSummary = previous.contentSummary || {};\nconst perplexityChoices = perplexity.choices;\n\n// Use fallback/default for every key field!\nconst name = personalContext.name || 'Unknown User';\nconst title = sourceContent.name || 'Untitled Content';\nconst categories = Array.isArray(sourceContent.categories) ? sourceContent.categories : ['General'];\nconst primaryCategory = categories[0] || 'General';\nconst summary = contentSummary.summary || '';\nconst wordCount = contentSummary.wordCount || 0;\nconst structure = contentSummary.structure || 'linear';\nconst complexity = contentSummary.complexity || 'unknown';\nconst fullText = sourceContent.fullText || '';\n\n// Perplexity research blockâ€”parse its result\nlet research = {};\ntry {\n  if (\n    Array.isArray(perplexityChoices) &&\n    perplexityChoices.length > 0 &&\n    typeof perplexityChoices[0] === 'object'\n  ) {\n    let rawContent = perplexityChoices[0].message?.content ?? '';\n    rawContent = rawContent.replace(/``````/g, '').trim();\n    if (rawContent) {\n      research = JSON.parse(rawContent);\n      console.log('âœ… Parsed Perplexity JSON.');\n    } else {\n      throw new Error('Empty content in Perplexity choices.');\n    }\n  } else {\n    throw new Error('Perplexity choices incomplete.');\n  }\n} catch (err) {\n  console.warn(`âš ï¸ Perplexity parsing failed: ${err.message}. Using fallback research.`);\n  research = {\n    authenticHashtags: {\n      twitter: ['#BuildInPublic', `#${primaryCategory}`, '#Automation', '#NoCode', '#n8n'],\n      linkedin: ['#ProcessAutomation', `#${primaryCategory}`, '#SystemsThinking', '#AI'],\n    },\n    optimalTimesIST: {\n      twitter_primary_ist: \"9:00-11:00 am IST\",\n      twitter_secondary_ist: \"8:30-9:30 pm IST (US/EU overlap)\",\n      linkedin_ist: \"10:00-12:00 am IST (Tue-Thu)\"\n    },\n    authenticHooks: {\n      twitter_example: \"Solving a weird API quirk in n8n todayâ€”here's the step that finally worked. Anyone else get stuck on webhook reliability?\",\n      linkedin_example: \"Client automated 50% manual onboarding steps using n8n, saving 10 hours/week. Why did we choose modular flows?\"\n    },\n    developerPainPoints: [\n      \"Lack of reliable content scheduling tools for Indian time zones\",\n      \"Complicated OAuth flows between LinkedIn, X and custom APIs\"\n    ]\n  };\n}\n\n// Optional IDs/session info\nconst originalId = previous.originalId ?? null;\nconst sessionId = previous.sessionId ?? null;\nconst notionPageId = sourceContent.id ?? null;\nconst extractionStats = sourceContent.extractionStats ?? {};\nconst hasImages = Array.isArray(sourceContent.images) && sourceContent.images.length > 0;\nconst processingTime = new Date().toISOString();\n\n// Master context object (robust, merged)\nconst masterContext = {\n  personalContext: {\n    ...personalContext,\n    name\n  },\n  sourceContent: {\n    title,\n    categories,\n    primaryCategory,\n    summary,\n    wordCount,\n    structure,\n    complexity,\n    fullText\n  },\n  contentSummary: {\n    summary,\n    wordCount,\n    structure,\n    complexity\n  },\n  research,\n  originalId,\n  sessionId,\n  workflowMetadata: {\n    notionPageId,\n    extractionStats,\n    hasImages,\n    processingTime\n  }\n};\n\nconsole.log('âœ… Master context object created successfully!');\nreturn [{ json: masterContext }];\n"
            },
            "id": "451f93a8-4726-4d59-ab08-9407377db809",
            "name": "Code â€“ CONTEXT MERGER",
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                2784,
                2640
            ]
        },
        {
            "parameters": {
                "resource": "folder",
                "name": "={{ $('Notion â€“ Get Ready Content').item.json.name }}-SocialDrafts-{{ $json.sessionId }}",
                "driveId": {
                    "__rl": true,
                    "mode": "list",
                    "value": "My Drive"
                },
                "folderId": {
                    "__rl": true,
                    "value": "1F25H1IcOyYzJa41LwbD-r31_Ogs6ASZd",
                    "mode": "list",
                    "cachedResultName": "N8N Build in public Drafts - LinkedIn & X",
                    "cachedResultUrl": "https://drive.google.com/drive/folders/1F25H1IcOyYzJa41LwbD-r31_Ogs6ASZd"
                },
                "options": {}
            },
            "type": "n8n-nodes-base.googleDrive",
            "typeVersion": 3,
            "position": [
                2672,
                2352
            ],
            "id": "1d33175b-011f-450a-b647-11d3f1be50ae",
            "name": "Create folder for title",
            "credentials": {
                "googleDriveOAuth2Api": {
                    "id": "1hcyFpBqSOMDRDna",
                    "name": "Google Drive Adude"
                }
            }
        },
        {
            "parameters": {
                "content": "Creating a separate folder in Drive to store all the assets & generated drafts",
                "height": 240,
                "width": 224
            },
            "type": "n8n-nodes-base.stickyNote",
            "position": [
                2608,
                2272
            ],
            "typeVersion": 1,
            "id": "6876bda7-0a9f-4421-b0ed-c4f2a7406334",
            "name": "Sticky Note3"
        },
        {
            "parameters": {
                "model": "sonar-pro",
                "messages": {
                    "message": [
                        {
                            "content": "=<role>\nYou are a Senior Technical Market Intelligence Analyst. Your job is NOT to write content, but to find the \"Heat\" in the market. You act as the eyes and ears for Aman Suryavanshi, a Build-in-Public founder (Next.js/n8n/AI/no-code/low-code).\n</role>\n\n<instructions>\n1. **The \"Newsjack\" (Urgency)**\n   - Search for recent software updates (e.g., \"Next.js 15\", \"n8n v1.0\", \"Claude 3.5\") or industry news related to this topic.\n   - *Goal:* Find ONE specific event that makes this content timely. (e.g., \"This is relevant because Vercel just changed their caching policy\").\n\n2. **The \"Gap Analysis\" (The Void)**\n   - Search Reddit (r/webdev, r/selfhosted) and HackerNews.\n   - What question is everyone asking but getting bad answers for?\n   - Identify \"Contrarian Angles\": What is the common advice that is actually wrong/inefficient?\n\n3. **Technical Vibe Check**\n   - Find 2-3 specific technical keywords that are trending in this niche RIGHT NOW (e.g., don't just say \"AI\", say \"Agentic Loops\" or \"MCP Servers\").\n\n4. **Platform Intelligence**\n   - **Twitter:** Find a \"Village\" (group of devs) discussing this. What is their sentiment? (Excited? Angry? Confused?)\n   - **LinkedIn:** Find a \"Business Stat\" or \"Cost Argument\". (e.g., \"Manual API integrations cost devs 10hrs/week\").\n   - **Blog:** Find \"Zero-Volume, High-Intent\" keywords (e.g., \"fix n8n webhook timeout 502\").\n\n5. **Timing**\n   - Provide optimal posting times for Asia/Kolkata (IST).\n</instructions>\n\n<outputformat>\nReturn ONLY valid JSON with this EXACT structure (no markdown fences):\n\n{\n  \"market_pulse\": {\n    \"urgency_trigger\": \"The recent event/update that makes this relevant NOW.\",\n    \"community_sentiment\": \"What are devs feeling? (e.g., 'Frustrated with complex setups').\",\n    \"the_gap\": \"The specific unanswered question or bad advice you found.\"\n  },\n  \"twitter\": {\n    \"hashtags\": [\"#SpecificTag1\", \"#SpecificTag2\"],\n    \"optimal_posting_times_ist\": [\"09:00 AM\", \"06:00 PM\"],\n    \"hook_inspiration\": \"A specific angle based on the urgency_trigger.\"\n  },\n  \"linkedin\": {\n    \"hashtags\": [\"#SpecificTag1\", \"#SpecificTag2\"],\n    \"optimal_posting_times_ist\": [\"10:00 AM\", \"02:00 PM\"],\n    \"business_value_stat\": \"A specific data point or cost argument found in research.\"\n  },\n  \"blog\": {\n    \"seo_keywords_primary\": [\n      {\"keyword\": \"main topic\", \"volume\": \"high\"}\n    ],\n    \"seo_keywords_longtail\": [\n      {\"keyword\": \"very specific problem fix\", \"volume\": \"low\"}\n    ],\n    \"competitor_gap\": \"What technical detail is missing in current top articles?\"\n  }\n}\n</outputformat>\n\n<constraints>\n- Research MUST be from the last 14 days.\n- Do NOT return generic advice. If no specific news is found, focus on a specific \"Eternal Struggle\" (e.g., \"Dependency Hell\").\n- Output must be strict JSON.\n</constraints>\n",
                            "role": "system"
                        },
                        {
                            "content": "=<context>\n<profile>\n- primary_focus: {{ $json.personalContext.strategic.futureRoadmap.currentFocus }}\n- target_roles: {{ $json.personalContext.strategic.targetRoles }}\n</profile>\n\n<topic>\n<name>{{$json.sourceContent.name}}</name>\n<categories>{{$json.sourceContent.categories}}</categories>\n<summary>{{$json.contentSummary.summary}}</summary>\n<date>{{ $now }}</date>\n</topic>\n</context>\n\n<task>\nConduct deep real-time research (last 14 days) to validate this topic. Find specific discussions, news, and technical arguments that make this topic urgent TODAY.\n</task>"
                        }
                    ]
                },
                "options": {
                    "temperature": 0.2,
                    "searchRecency": "month"
                },
                "requestOptions": {}
            },
            "id": "47ac0211-2d59-46bf-bb2e-f5ce7d6b1c2f",
            "name": "Perplexity â€“ Research Hashtags & Timing",
            "type": "n8n-nodes-base.perplexity",
            "typeVersion": 1,
            "position": [
                2560,
                2640
            ],
            "retryOnFail": true,
            "waitBetweenTries": 2000,
            "credentials": {
                "perplexityApi": {
                    "id": "Ss20gojfOfH1gtj7",
                    "name": "Perplexity Anki"
                }
            }
        },
        {
            "parameters": {
                "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// PROCESS AI STRATEGY (V5 - PRODUCTION HARDENED)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n// 1. SAFE INPUT EXTRACTION\n// We use optional chaining and fallback objects to prevent \"Cannot read property of undefined\" errors\nconst geminiRawOutput = $input.first()?.json || {};\nconst contextNode = $('Code â€“ CONTEXT MERGER').first();\nconst originalContext = contextNode ? contextNode.json : {};\n\n// Validate Critical Inputs\nif (Object.keys(geminiRawOutput).length === 0) {\n  throw new Error('âŒ CRITICAL: No input received from Gemini AI Node.');\n}\nif (Object.keys(originalContext).length === 0) {\n  // Warn but don't crash hard if context is missing (useful for isolated testing)\n  console.log('âš ï¸ WARNING: Original Context is empty. Merging might be incomplete.');\n}\n\n// 2. ROBUST JSON PARSING (The \"Fence Stripper\")\n// AI often wraps output in markdown or adds conversational filler. We strip it all.\nlet rawText = geminiRawOutput.text || \n              geminiRawOutput.content?.parts?.[0]?.text || \n              geminiRawOutput.result || // Some Gemini node versions use .result\n              \"\";\n\n// Handle edge case where the input itself is just the string\nif (typeof geminiRawOutput === 'string') rawText = geminiRawOutput;\n\nconst firstBrace = rawText.indexOf('{');\nconst lastBrace = rawText.lastIndexOf('}');\n\nif (firstBrace === -1 || lastBrace === -1) {\n  // Output the raw text to the error log so you can debug *what* the AI actually said\n  throw new Error(`CRITICAL: Valid JSON not found in AI output. Raw Output Preview: ${rawText.substring(0, 100)}...`);\n}\n\nconst jsonString = rawText.substring(firstBrace, lastBrace + 1);\nlet strategy;\ntry {\n  strategy = JSON.parse(jsonString);\n} catch (e) {\n  // Common AI error: trailing commas. We fail strictly here to ensure data integrity.\n  throw new Error(`CRITICAL: JSON Syntax Error. The extracted block was not valid JSON. Error: ${e.message}`);\n}\n\n// 3. DEEP VALIDATION & SANITIZATION (The Checkpoints)\nfunction validateAndSanitize(data) {\n  const issues = [];\n  \n  // A. Top-Level Integrity\n  if (!data?.strategy_summary) issues.push(\"Missing 'strategy_summary'\");\n  if (!data?.platform_strategies) issues.push(\"Missing 'platform_strategies'\");\n  \n  const platforms = data.platform_strategies || {};\n  \n  // B. Twitter/X Sanitization\n  if (!platforms.twitter) {\n     // Auto-fix: Create a minimal valid object so downstream nodes don't crash\n     platforms.twitter = { \n         hashtags: [], \n         content_breakdown: [\"General Strategy Update\"] \n     };\n  } else {\n     // Enforce array types for iterables\n     if (!Array.isArray(platforms.twitter.hashtags)) platforms.twitter.hashtags = [];\n  }\n\n  // C. LinkedIn Validation (We treat this as critical)\n  if (!platforms.linkedin) {\n      issues.push(\"Missing 'platform_strategies.linkedin'\");\n  }\n\n  // D. Image Strategy Safety (Crucial for branching nodes)\n  if (!data.image_strategy) {\n      // Safe default: No images needed\n      data.image_strategy = { \n          needs_images: false, \n          rationale: \"Default fallback (AI strategy missing)\", \n          specific_prompts: [] \n      };\n  } else {\n      // Ensure specific_prompts is always an array\n      if (!Array.isArray(data.image_strategy.specific_prompts)) {\n          data.image_strategy.specific_prompts = [];\n      }\n      // Boolean enforcement\n      data.image_strategy.needs_images = !!data.image_strategy.needs_images;\n  }\n\n  // If critical fields are missing, fail the workflow so you are alerted\n  if (issues.length > 0) {\n    throw new Error(`VALIDATION FAILED: ${issues.join(', ')}`);\n  }\n  \n  return data;\n}\n\n// Run the validator\nconst cleanStrategy = validateAndSanitize(strategy);\n\n// 4. MASTER MERGE\n// Combine everything into one guaranteed object for the next nodes\nconst masterData = {\n  // Use optional chaining to safely access deep properties from context\n  personalContext: originalContext?.personalContext || {}, \n  sourceContent: originalContext?.sourceContent || {},\n  research: originalContext?.research || {},\n  workflowMetadata: originalContext?.workflowMetadata || {},\n  strategy: cleanStrategy,\n  _meta: {\n    parsedAt: new Date().toISOString(),\n    validatorVersion: \"5.1-Hardened\"\n  }\n};\n\nreturn [{ json: masterData }];"
            },
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                3360,
                2640
            ],
            "id": "427a9a98-3fbb-4313-b6fd-1982731dcce5",
            "name": "Process AI Strategy & MERGE CONTEXT"
        },
        {
            "parameters": {
                "conditions": {
                    "options": {
                        "caseSensitive": true,
                        "leftValue": "",
                        "typeValidation": "strict",
                        "version": 2
                    },
                    "conditions": [
                        {
                            "id": "e0a6bdb8-0521-4d53-a351-c2ec3f05310e",
                            "leftValue": "={{ $json.strategy.image_strategy.needs_images }}",
                            "rightValue": "",
                            "operator": {
                                "type": "boolean",
                                "operation": "true",
                                "singleValue": true
                            }
                        }
                    ],
                    "combinator": "and"
                },
                "options": {}
            },
            "type": "n8n-nodes-base.if",
            "typeVersion": 2.2,
            "position": [
                4016,
                3504
            ],
            "id": "74a8a462-0b2f-42e5-9c56-9af09c55bd4c",
            "name": "Are Images Needed?",
            "onError": "continueRegularOutput"
        },
        {
            "parameters": {
                "conditions": {
                    "options": {
                        "caseSensitive": true,
                        "leftValue": "",
                        "typeValidation": "strict",
                        "version": 2
                    },
                    "conditions": [
                        {
                            "id": "e6bbf5e8-5982-4daa-ac73-f54ca4f4cae5",
                            "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('X') }}",
                            "rightValue": "",
                            "operator": {
                                "type": "boolean",
                                "operation": "true",
                                "singleValue": true
                            }
                        }
                    ],
                    "combinator": "and"
                },
                "options": {}
            },
            "type": "n8n-nodes-base.if",
            "typeVersion": 2.2,
            "position": [
                3728,
                1680
            ],
            "id": "a5cafb72-4554-4163-87d9-efa483ce40dd",
            "name": "IF - Twitter Selected?"
        },
        {
            "parameters": {
                "conditions": {
                    "options": {
                        "caseSensitive": true,
                        "leftValue": "",
                        "typeValidation": "strict",
                        "version": 2
                    },
                    "conditions": [
                        {
                            "id": "20913d76-b524-4cd5-9550-bb1e584cc9a5",
                            "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('LinkedIn') }}",
                            "rightValue": "",
                            "operator": {
                                "type": "boolean",
                                "operation": "true",
                                "singleValue": true
                            }
                        }
                    ],
                    "combinator": "and"
                },
                "options": {}
            },
            "type": "n8n-nodes-base.if",
            "typeVersion": 2.2,
            "position": [
                3728,
                2064
            ],
            "id": "bc43212b-c620-421e-b97f-086c22679384",
            "name": "IF - LinkedIn Selected?"
        },
        {
            "parameters": {
                "conditions": {
                    "options": {
                        "caseSensitive": true,
                        "leftValue": "",
                        "typeValidation": "strict",
                        "version": 2
                    },
                    "conditions": [
                        {
                            "id": "efebb240-a978-43aa-be26-00c040c5a359",
                            "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('Blog') }}",
                            "rightValue": "",
                            "operator": {
                                "type": "boolean",
                                "operation": "true",
                                "singleValue": true
                            }
                        }
                    ],
                    "combinator": "and"
                },
                "options": {}
            },
            "type": "n8n-nodes-base.if",
            "typeVersion": 2.2,
            "position": [
                3728,
                2448
            ],
            "id": "0790741c-8d96-47af-ba36-d5e0b4024e45",
            "name": "IF - Blog Selected?"
        },
        {
            "parameters": {
                "jsCode": "// Return placeholder for skipped Twitter draft\nreturn [{\n  json: {\n    id: null,\n    platform: 'twitter',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
            },
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4528,
                1776
            ],
            "id": "3f646da1-48ec-4610-97b2-ce744c6528dc",
            "name": "Code - No-Op Twitter Draft"
        },
        {
            "parameters": {
                "jsCode": "return [{\n  json: {\n    id: null,\n    platform: 'linkedin',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
            },
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4528,
                2160
            ],
            "id": "4441de05-3b0c-4a73-aaa9-33c5787562e9",
            "name": "Code - No-Op LinkedIn Draft"
        },
        {
            "parameters": {
                "jsCode": "return [{\n  json: {\n    id: null,\n    platform: 'blog',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
            },
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4528,
                2544
            ],
            "id": "4a33f768-9e4c-46a0-a568-c495f96b4031",
            "name": "Code - No-Op Blog Draft"
        },
        {
            "parameters": {
                "modelId": {
                    "__rl": true,
                    "value": "models/gemini-3-flash-preview",
                    "mode": "list",
                    "cachedResultName": "models/gemini-3-flash-preview"
                },
                "messages": {
                    "values": [
                        {
                            "content": "=<system_instructions>\n<role>\nYou are a world-class Build-in-Public content strategist for Aman Suryavanshi, a Next.js developer and n8n automation specialist. Your primary job is to extract the REAL value from Aman's source content and craft a detailed, multi-platform content strategy. This includes both the textual content plan and a sophisticated visual asset plan.\n</role>\n\n<critical_instruction>\nâš ï¸ YOU MUST USE THE PROVIDED sourceContent.fullText AS THE SINGLE SOURCE OF TRUTH. Do not invent scenarios, projects, or examples. Aman shares his real implementation experienceâ€”your job is to extract and repurpose what he ACTUALLY did, not to write fiction. Every part of your strategy must be traceable back to the source content.\n</critical_instruction>\n\n<master_framework>\n<part_1_text_strategy>\n<mandatory_extraction_framework>\n\nPHASE 1: THE DETECTIVE SCAN (Data Extraction)\n1. **Scan for Hard Evidence:**\n   - Specific Projects: (e.g., \"Barkat Enterprise\", \"AV NewsStream\")\n   - Technical Implementations: (e.g., \"converted JPEG to WebP\", \"used n8n webhook\")\n   - Code Snippets/Logic: (Are there specific functions or configs mentioned?)\n   - Metrics: (e.g., \"Lighthouse 40->90\", \"Saved 5 hours/week\")\n   - The Struggle: What specific bug or blocker did Aman face?\n2. **Identify the \"Villain\" (The Conflict):**\n   - **For Engineering Tasks:** What specific bug, error code, or bottleneck was stopping Aman?\n   - **For Thought Leadership:** What common industry bad habit or \"Old Way\" of thinking is Aman fighting against?\n   - *Constraint:* There must always be a conflict. No conflict = boring content.\n3. **Identify the \"Epiphany\":**\n   - The exact moment the solution clicked. Not just the code, but the *realization*.\n4. **Identify Content DNA:**\n   - Is it a **\"Vision/Thought\"**? (Raw ideas, roadmap, philosophy)\n   - Is it a **\"Case Study/Bug Fix\"**? (Engineering competence, specific solution)\n   - Is it a **\"Learning/Tutorial\"**? (Teaching a concept)\n\nPHASE 2: THE CAREER ENGINEER (Strategic Positioning)\n3. **The \"Money\" Angle (LinkedIn - For Clients/Jobs):**\n   - Translate the *Hard Evidence* into *Business Value*.\n   - *Example:* \"Fixed an API error\" â†’ \"Ensured 99.9% uptime for critical workflows.\"\n   - *Goal:* Prove Aman is a high-agency problem solver who saves/makes money.\n4. **The \"Alpha\" Angle (Twitter - For Dev Respect):**\n   - Extract the specific technical insight that 90% of juniors miss.\n   - *Example:* \"I used Next.js\" â†’ \"Why I chose Next.js ISR over SSR for this specific use case.\"\n   - *Goal:* Show technical depth and \"alpha\" (insider knowledge).\n5. **The \"Authority\" Angle (Blog - For SEO/Trust):**\n   - Identify the \"Hard Thing\" Aman figured out and structure it as the definitive guide.\n   - *Goal:* Create an asset that builds long-term domain authority.\n</mandatory_extraction_framework>\n\n<platform_adaptation_rules>\n**TWITTER (The Peer-to-Peer Cooler):**\n- **Goal:** Respect & Engagement.\n- **Style:** \"I found X. Here is exactly how it works.\" (No fluff).\n- **Structure:** 1 Tweet = 1 specific technical point.\n- **Hook Strategy:** Start with the *result* or the *pain*, never with \"Hello friends.\"\n\n**LINKEDIN (The Hiring Manager's Office):**\n- **Goal:** Inbound Leads (Jobs/Gigs).\n- **Style:** \"I solved a business problem using technology.\"\n- **Structure Selector (Pick ONE based on Content DNA):**\n   - *If Case Study:* The Hook (Result) â†’ The Struggle (Problem) â†’ The Solution (Logic) â†’ The CTA (Outcome).\n   - *If Vision:* The Observation (Trend) â†’ The Prediction (My take) â†’ The Plan (What I'm building) â†’ The Question.\n   - *If Tutorial:* The Goal â†’ The \"Old Way\" (Inefficient) â†’ The \"New Way\" (My solution) â†’ The Steps.\n\n**BLOG (The Technical Manual):**\n- **Goal:** SEO & Portfolio Depth.\n- **Style:** \"The Definitive Guide.\"\n- **Structure:** Context â†’ Implementation (Code) â†’ Edge Cases â†’ Final Result.\n</platform_adaptation_rules>\n\n<voice_requirements>\n**MANDATORY:**\n- Use the first-person (\"I\") voice\n- Reference specific projects from the source\n- Include real code and metrics\n- The \"Bar Test\": If you wouldn't say a sentence to a friend at a bar, delete it. (e.g., instead of \"I leveraged the API,\" use \"I hooked up the API\").\n\n**FORBIDDEN (The Anti-Slop List):**\n- Do NOT use: \"In today's digital landscape\", \"Delve\", \"Tapestry\", \"Beacon\", \"Game-changer\", \"Unlock\", \"Unleash\", \"Humbled to announce\", \"Thrilled to share\".\n- Do not use \"we\" unless the source specifies a team.\n- Avoid all fictional examples, generic advice, and corporate jargon.\n</voice_requirements>\n\n<content_length_adaptation>\n- **Deep Technical/Project:** Prioritize a **Multi-Tweet Thread** and a **Full Case Study** on LinkedIn.\n- **Quick Tip/Thought:** Prioritize a single **\"Hot Take\"** or **\"One-Pager\"** image post.\n</content_length_adaptation>\n</part_1_text_strategy>\n\n<part_2_image_strategy>\nCRITICAL: Determine IMAGE/ASSET NEEDS based on the source content. For each visual that would significantly enhance the text, create a detailed entry in the `specific_prompts` array.\n\n<image_rules>\n1. **Reality Check:** Only set `asset_type` to \"real_asset\" if the source content *explicitly* describes existing charts, logs, or UI screens. If not, default to \"generative_asset\" (diagrams/flowcharts).\n2. **Markers:** You MUST assign markers `<<IMAGE_1>>`, `<<IMAGE_2>>` sequentially.\n3. **Quantity:** Max 2-3 images. Quality over quantity.\n</image_rules>\n\n<for_each_visual_you_must_specify>\n1. **asset_type:** \"real_asset\" (screenshot) or \"generative_asset\" (AI diagram).\n2. **description:** Clear instruction for Aman.\n3. **fallback_prompt:** Detailed AI image generation prompt (Midjourney/DALL-E style).\n4. **position:** Placement in content.\n5. **alt_text:** SEO-friendly description.\n6. **marker:** âš ï¸ CRITICAL FORMAT: Use `<<IMAGE_1>>`, `<<IMAGE_2>>` (DOUBLE angle brackets).\n</for_each_visual_you_must_specify>\n\n<consistency_check>\nCRITICAL: If you insert <<IMAGE_1>> or <<IMAGE_2>> markers into the text content, you MUST:\n1. Set image_strategy.needs_images to true.\n2. Populate the image_strategy.specific_prompts array with the matching details.\nNEVER include markers in the text without defining them in the JSON array.\n</consistency_check>\n</part_2_image_strategy>\n</master_framework>\n\n<output_format>\nReturn ONLY valid JSON. The structure must contain all the fields from the previous prompts, with the `image_strategy` object fully populated according to the detailed rules in part_2_image_strategy.\n\n{\n  \"strategy_summary\": \"High-level summary of the approach.\",\n  \"narrative_arc\": {\n    \"the_villain\": \"The specific problem, bug, or 'old way' that was stopping Aman.\",\n    \"the_epiphany\": \"The specific moment or insight where the solution clicked.\"\n  },\n  \"source_analysis\": \"Technical analysis of the input.\",\n  \"core_insight\": \"The one main takeaway.\",\n  \"platform_strategies\": {\n    \"twitter\": {\n      \"hashtags\": [],\n      \"content_breakdown\": [],\n      \"must_include\": []\n    },\n    \"linkedin\": {\n      \"hashtags\": [],\n      \"structure\": \"Selected Structure Name\",\n      \"must_include\": []\n    },\n    \"blog\": {\n      \"seo_keywords\": [],\n      \"structure\": [],\n      \"must_include\": []\n    }\n  },\n  \"authenticity_elements\": \"Specific quotes or struggles to reuse.\",\n  \"value_proposition\": \"The business value.\",\n  \"image_strategy\": {\n    \"needs_images\": boolean,\n    \"rationale\": \"Why visuals are (or are not) needed for THIS specific content.\",\n    \"image_types\": [\"screenshot\", \"diagram\", \"etc\"],\n    \"specific_prompts\": [\n      {\n        \"asset_type\": \"real_asset\" | \"generative_asset\",\n        \"description\": \"Specific instruction for Aman.\",\n        \"fallback_prompt\": \"Detailed AI image generation prompt.\",\n        \"position\": \"Where it goes in the content.\",\n        \"alt_text\": \"SEO-friendly alt text.\",\n        \"purpose\": \"Why this image is necessary.\",\n        \"marker\": \"<<IMAGE_1>>\"\n      }\n    ]\n  }\n}\n</output_format>\n\n<validation_checklist>\nBefore returning, you must verify:\n- The text strategy (Part 1) is 100% based on the source content.\n- The image strategy (Part 2) is detailed, actionable, and includes the `asset_type` and `fallback_prompt` for every requested image.\n- Image markers use DOUBLE angle brackets: `<<IMAGE_X>>`\n- The voice is consistently first-person (\"I\").\n- The final output is a single, valid JSON object with no extra text or markdown.\n</validation_checklist>\n</system_instructions>",
                            "role": "model"
                        },
                        {
                            "content": "=<context>\n<my_personal_professional_profile>\n{{ $json.personalContext }}\n</my_personal_professional_profile>\n\n<the_source_of_truth>\nâš ï¸ This is a HIGH-SIGNAL SUMMARY of the actual content. Use the technical details, metrics, and struggles extracted here to build the strategy.\n\nTOPIC: {{ $json.sourceContent.title }}\nCATEGORY: {{ $json.sourceContent.primaryCategory }}\nFULL SOURCE CONTENT (Use this absolute truth):\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<market_intelligence_report>\nâš ï¸ USE THIS TO MAKE THE CONTENT URGENT.\nThe research node has identified the \"Pulse\" of the market.\n- **Urgency Trigger:** {{ $json.research.market_pulse.urgency_trigger }} (Use this to answer \"Why read this NOW?\")\n- **The Gap:** {{ $json.research.market_pulse.the_gap }} (This is your differentiation angle)\n- **Business Stat:** {{ $json.research.linkedin.business_value_stat }} (Use this for the LinkedIn Hook)\n</market_intelligence_report>\n</context>\n\n<task>\nAnalyze the High-Signal DNA provided above. Act as a \"Career Engineer\" to craft a comprehensive content strategy that transforms these raw insights into maximum **Authority** (Twitter), **Hireability** (LinkedIn), and **Trust** (Blog).\n\nYour specific goals are to:\n1. **Extract Core Value:** Identify the specific \"Money\" and \"Alpha\" angles that will attract high-quality connections, job offers, and freelance gigs.\n2. **Drive Engagement:** Design hooks and structures that maximize reach without sacrificing technical depth.\n3. **Plan Visuals:** Create a detailed plan for **visual assets** (screenshots, diagrams) that \"stop the scroll\" and prove your competence at a glance.\n4. **Newsjack:** Connect Aman's technical solution to the `urgency_trigger` found in the market intelligence (e.g., \"With the release of X, this workflow is now essential...\").\n\nâš ï¸ Constraint: The strategy must be strictly based on what was **ACTUALLY** done in the source content.\n</task>"
                        }
                    ]
                },
                "options": {
                    "codeExecution": false,
                    "temperature": 0.4
                }
            },
            "id": "5a369058-165d-421b-9612-e97c3c9a4dbc",
            "name": "Gemini - AI CONTENT STRATEGIST",
            "type": "@n8n/n8n-nodes-langchain.googleGemini",
            "typeVersion": 1,
            "position": [
                3008,
                2640
            ],
            "retryOnFail": true,
            "maxTries": 3,
            "waitBetweenTries": 2000,
            "credentials": {
                "googlePalmApi": {
                    "id": "MXjQ6FyV5UijLXsc",
                    "name": "PRO Google Gemini(PaLM) Api account "
                }
            }
        },
        {
            "parameters": {
                "modelId": {
                    "__rl": true,
                    "value": "models/gemini-3-flash-preview",
                    "mode": "list",
                    "cachedResultName": "models/gemini-3-flash-preview"
                },
                "messages": {
                    "values": [
                        {
                            "content": "=<role>\nYou write as Aman Suryavanshi, a high-agency Next.js developer and n8n automation specialist. Your goal is NOT just to inform, but to build authority that attracts job offers and clients. Your voice is punchy, confident, and devoid of fluff. You are writing a viral-style Twitter thread based on the provided source content and strategy.\n</role>\n\n<critical_instruction>\nâš ï¸ YOU MUST USE THE PROVIDED SOURCE CONTENT AND PERSONAL CONTEXT. Your task is to transform the sourceContent.fullText into an engaging, authentic Twitter thread, guided by the strategy. Do NOT invent projects, examples, or results not found in the source material. Every tweet must be traceable to a specific point in Aman's actual work. Use the first-person (\"I\") voice.\n</critical_instruction>\n\n<rules>\n1. **Extract, Don't Invent:** Pull direct examples, project names (like \"Barkat Enterprise\"), and code snippets from the sourceContent.\n\n2. **Follow the Plan:** Adhere strictly to the `content_breakdown` and `must_include` fields within the `strategy.platform_strategies.twitter` object.\n\n3. **Voice:** Use \"I\" and \"my\". The personalContext provides the persona. Sound like a real developer sharing what you learned.\n\n4. **Structure (The Scroll-Stopper):**\n   - **Tweet 1 (The Hook):**\n  - CONSTRAINT: Must be under 200 characters (leave breathing room).\n  - PATTERN A: The \"Hard Number\" (\"I cut my build time by 40%.\").\n  - PATTERN B: The \"Opinion\" (\"Most devs overcomplicate n8n error handling.\").\n  - PATTERN C: The \"Result\" (\"Finally cracked the Notion API.\").\n  - BANNED: Never start with \"Here is how\", \"Let's dive in\", or \"I recently built\".\n\n5. **The \"Anti-Slop\" Filter (Strict):**\n  - ðŸš« BANNED WORDS: \"Unlock\", \"Unleash\", \"Game-changer\", \"Revolutionize\", \"In today's digital landscape\", \"Dive deep\", \"Buckle up\", \"Tapestry\", \"Beacon\", \"Elevate\".\n  - ðŸš« NO EMOJI VOMIT: Use max 1 emoji per tweet, purely for bullet points or emphasis.\n\n6. **âš ï¸ CHARACTER LIMITS (ABSOLUTE HARD STOP):**\n  - **Target:** Aim for 220 characters per tweet.\n  - **Hard Limit:** 265 characters. NO EXCEPTIONS.\n  - **Reason:** Short tweets are punchier and easier to read. Additonally, To prevent automation failures, you must stay well below the 280 limit.\n  - **Calculation:** Count every letter, space, emoji (2 chars), punctuation, and hashtag.\n  - **If a tweet is too long:** YOU MUST rewrite it to be shorter. Do not just truncate; rephrase for brevity.\n  - **Constraint:** `content.length` MUST be <= 260.\n\n7. **Image Marker Insertion:**\n   - Check if `strategy.image_strategy.needs_images` is `true`\n   - If yes, review `strategy.image_strategy.specific_prompts` array\n   - For images where `position` mentions \"Twitter\" or \"thread\" or \"first tweet\":\n     - Insert the corresponding marker (`<<IMAGE_1>>`, `<<IMAGE_2>>`) from the `marker` field\n     - âš ï¸ CRITICAL FORMAT: Use DOUBLE angle brackets: `<<IMAGE_X>>`\n     - Place the marker on its OWN LINE immediately after the tweet content where the image should appear\n     - Add blank lines before and after the marker for readability\n   - Example:\n     ```\n     Tweet 1/5\n\n     I've been building with MCP and it completely broke my mental model for AI development...\n      \n     <<IMAGE_1>>\n\n     Here's what I learned ðŸ‘‡\n     ```\n\n8. **Graceful Marker Handling:**\n   - Image markers are OPTIONAL placeholders for Part 2 automation\n   - If images are not uploaded to Drive, Part 2 will automatically remove these markers\n   - Do NOT worry about whether images will be availableâ€”always insert markers when strategy recommends them\n   - The system is designed to handle missing images gracefullyâ€”posts will go out text-only if needed\n   - Never reference the markers in the actual tweet textâ€”they are invisible placeholders\n\n9. **Character Count Verification:**\n   - For EACH tweet, count the characters INCLUDING spaces and punctuation\n   - Store the exact count in the `char_count` field\n   - Verify: `content.length === char_count`\n   - If mismatch detected, flag in validation\n\n10. **Visual Rhythm (The Mobile Test):**\n    - Avoid \"walls of text.\"\n    - Use line breaks frequently.\n    - Structure: One distinct thought per line (or max 2 lines).\n    - Use whitespace to force the reader to scroll.\n\n11. **Use the Villain:**\n    - I have provided a `narrative_arc` in the strategy.\n    - You MUST use `strategy.narrative_arc.the_villain` in Tweet 1 or Tweet 2.\n    - Don't just state the problem; attack the villain.\n</rules>\n\n<output_format>\nReturn ONLY valid JSON that matches the structure requested in the previous prompts. The JSON should contain `formatted_markdown` for the full thread and a `structured_data` object with an array of individual tweets.\n\n{\n  \"formatted_markdown\": \"# Twitter Draft\\\\n\\\\nThread 1\\\\n\\\\n---\\\\n\\\\nTweet 1/4\\\\n\\\\nContent here\\\\n\\\\n<<IMAGE_1>>\\\\n\\\\n---\\\\n\\\\nTweet 2/4\\\\n\\\\nContent here...\",\n  \"structured_data\": {\n    \"threads\": [\n      {\n        \"thread_id\": 1,\n        \"theme\": \"Core insight from strategy\",\n        \"tweets\": [\n          {\n            \"position\": 1,\n            \"content\": \"Raw tweet textâ€”NO markdown, NO extra formatting\",\n            \"char_count\": 250,\n            \"image_marker\": \"<<IMAGE_1>>\",\n            \"type\": \"hook\"\n          },\n          {\n            \"position\": 2,\n            \"content\": \"Raw tweet text\",\n            \"char_count\": 240,\n            \"image_marker\": null,\n            \"type\": \"context\"\n          },\n          {\n            \"position\": 3,\n            \"content\": \"Raw tweet text\",\n            \"char_count\": 265,\n            \"image_marker\": \"<<IMAGE_2>>\",\n            \"type\": \"solution\"\n          },\n          {\n            \"position\": 4,\n            \"content\": \"Raw tweet text with hashtags\",\n            \"char_count\": 240,\n            \"image_marker\": null,\n            \"type\": \"lesson_cta\"\n          }\n        ]\n      }\n    ],\n    \"metadata\": {\n      \"total_threads\": 1,\n      \"total_tweets\": 4,\n      \"validation\": {\n        \"all_char_limits_met\": true,\n        \"all_counts_accurate\": true,\n        \"image_markers_correct_format\": true,\n        \"warnings\": []\n      }\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nBefore returning JSON, verify:\nâ˜ All tweets are under character limits (265 for 1-3, 245 for final)\nâ˜ char_count matches content.length exactly for each tweet\nâ˜ Image markers use DOUBLE angle brackets: `<<IMAGE_X>>`\nâ˜ No AI clichÃ©s present (Verified: \"game-changer\", \"unlock\", \"dive deep\" are NOT used)\nâ˜ First-person \"I\" voice used throughout\nâ˜ Real project mentioned (not invented)\nâ˜ Specific metrics or examples included\nâ˜ Final tweet has 3-5 hashtags from research\nâ˜ JSON structure matches required schema exactly\nâ˜ No extra fields added beyond specification\n\nIf ANY validation fails:\n- Set `validation: false` in metadata\n- Include warning details in `metadata.validation.warnings`\n- Return the JSON anyway (don't fail silently)\n</validation_before_return>",
                            "role": "model"
                        },
                        {
                            "content": "=<context>\n<my_personal_profile>\n{{ $json.personalContext }}\n</my_personal_profile>\n\n<the_strategy_to_follow>\n{{ $json.strategy }}\n</the_strategy_to_follow>\n\n<the_source_of_truth>\nThe Notion Page Content is the most important input. Extract specific examples, code, and results from here.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<market_intelligence>\n{{ $json.research }}\n</market_intelligence>\n\n</context>\n\n<task>\nGenerate a multi-tweet Twitter thread that follows the `twitter` section of the provided strategy. Extract specific, concrete tactics and examples from the sourceContent to build the thread.\n</task>"
                        }
                    ]
                },
                "options": {
                    "maxOutputTokens": 4096,
                    "temperature": 0.7
                }
            },
            "id": "9549ac14-11e1-451c-91cc-a68bb7387f89",
            "name": "Gemini - Twitter Content Generation",
            "type": "@n8n/n8n-nodes-langchain.googleGemini",
            "typeVersion": 1,
            "position": [
                3952,
                1584
            ],
            "retryOnFail": true,
            "maxTries": 3,
            "waitBetweenTries": 2000,
            "credentials": {
                "googlePalmApi": {
                    "id": "JKGAnDvxRaaMLn0W",
                    "name": "Google Gemini(PaLM) Api key 2"
                }
            }
        },
        {
            "parameters": {
                "modelId": {
                    "__rl": true,
                    "value": "models/gemini-3-flash-preview",
                    "mode": "list",
                    "cachedResultName": "models/gemini-3-flash-preview"
                },
                "messages": {
                    "values": [
                        {
                            "content": "=<role>\nYou write as Aman Suryavanshi, a Next.js and Automation Developer. You are writing a professional LinkedIn post to showcase your expertise by sharing a case study or deep insight from your real project work. Your voice is thoughtful, authentic, and results-oriented.\n</role>\n\n<critical_instruction>\nâš ï¸ **GOAL: GET HIRED.** You must base this post on `sourceContent.fullText`, but frame it to demonstrate that Aman is a \"High-Agency\" developer. He doesn't just write code; he solves business problems. Even if the content is a simple bug fix, frame it as \"Ensuring system reliability.\" Use the first-person (\"I\") voice to assert competence.\n</critical_instruction>\n\n<rules>\n1. **The \"Result-First\" Framework:**\n   - **Line 1 (The Hook):** MUST be a specific outcome, a contrarian opinion, or a hard metric.\n     - BAD: \"Here is how I used Next.js.\"\n     - GOOD: \"I cut our build times by 40% by ditching this one popular library.\"\n   - **Line 2 (The Context):** The \"Before\" state or the Pain point.\n   - **Body (The Engineering):** The specific Strategy/Logic used. Mention specific tools to prove depth.\n   - **Ending (The CTA):** A question or business insight for the reader.\n\n2. **Extract, Don't Invent:** Use the actual project names (\"Barkat Enterprise\"), technical details, and metrics (Lighthouse score 40 to 90+) found in the sourceContent.\n\n3. **Follow the Plan:** Adhere strictly to the structure and `must_include` directives in `strategy.platform_strategies.linkedin`.\n\n4. **Voice (High Agency):** Write in the **Active Voice** only.\n   - BAD: \"The database was optimized...\"\n   - GOOD: \"I optimized the database...\"\n   - BAD: \"Challenges were faced...\"\n   - GOOD: \"I fought with the API rate limits...\"\n   - Use short, punchy sentences. No academic fluff.\n\n5. **LinkedIn Formatting:** Use short paragraphs, whitespace for readability, and a concluding question to encourage engagement.\n\n6. **âš ï¸ CHARACTER LIMITS (CRITICAL):**\n   - **Target Length:** Aim for 1200-1800 characters. This is the \"sweet spot\" for readability.\n   - **Maximum Hard Limit:** 2800 characters (Absolute max).\n   - **If post exceeds 2800 characters:**\n     - Trim to exactly 2750 characters and append \"\\\\n\\\\n[See full details in comments]\"\n     - Log a warning in the output\n     - NEVER silently exceed limits\n   - **Character count verification:**\n     - Count includes ALL text + line breaks + hashtags\n     - Store exact count in `char_count` field\n     - Verify: `content.length === char_count`\n\n7. **âš ï¸ LINE BREAK ENCODING (CRITICAL FOR FORMATTING):**\n   - **Paragraph breaks:** Use `\\\\n\\\\n` (double backslash-n)\n   - **Before numbered lists:** Use `\\\\n\\\\n\\\\n` (triple backslash-n) â† THIS IS CRITICAL\n   - **Hashtag separator:** Use `\\\\n\\\\n` (double backslash-n)\n   - **Example:**\n     ```\n     \"Here's what happened:\\\\n\\\\n\\\\n1. First insight...\\\\n2. Second insight...\\\\n\\\\nMore text here.\\\\n\\\\n#hashtag1 #hashtag2\"\n     ```\n\n8. **Image Marker Insertion:**\n   - Check if `strategy.image_strategy.needs_images` is `true`\n   - If yes, review `strategy.image_strategy.specific_prompts` array\n   - âš ï¸ LinkedIn API allows EXACTLY ONE image per post\n   - Place the marker (`<<IMAGE_1>>`) at the VERY END of the post (after hashtags if possible)\n   - âš ï¸ CRITICAL FORMAT: Use DOUBLE angle brackets: `<<IMAGE_1>>`\n   - Place on its own line with blank lines before/after\n   - Example:\n     ```\n     ...ending paragraph text.\n\n     #hashtag1 #hashtag2 #hashtag3\n\n     <<IMAGE_1>>\n     ```\n\n9. **Multiple Posts Logic:**\n   - If strategy recommends 2 LinkedIn posts, separate them with `---` (three hyphens)\n   - Each post must be self-contained and under 2800 characters\n   - Label as \"Part 1\" and \"Part 2\" if sequential\n\n10. **Character Count Verification:**\n    - For EACH post, count the characters INCLUDING all `\\\\n` sequences and hashtags\n    - Store the exact count in the `char_count` field\n    - Verify: `content.length === char_count`\n\n11. **Anti-Marketing Voice:**\n    - ðŸš« NO \"Thrilled to announce\".\n    - ðŸš« NO \"Humbled to share\".\n    - ðŸš« NO \"Let's connect!\".\n    - Start directly with the value or the story. Speak like a senior engineer, not a marketer.\n\n12. **Visual Rhythm:**\n    - Vary your paragraph lengths.\n    - Use a 1-line sentence to emphasize a point.\n    - Follow it with a 3-line paragraph to explain the context.\n    - This \"Short-Long-Short\" rhythm keeps the reader scrolling.\n\n13. **The \"Engineer's Humility\":**\n    - Don't just brag. Admit what was hard.\n    - Phrases like \"I honestly struggled with...\" or \"This took me longer than I expected...\" build massive trust.\n\n14. **Narrative Integration:**\n    - Review `strategy.narrative_arc.the_villain`. Use this to write the \"Context\" or \"Struggle\" section.\n    - Review `strategy.narrative_arc.the_epiphany`. Use this as the turning point before introducing the solution.\n\n15. **The \"Flash\" Constraint:**\n    - Do NOT summarize. Do NOT be brief unless told to be.\n    - When writing the \"Body\" or \"Technical Steps\", go DEEP.\n    - Write as if you are paid per word of insight. Detail matters.\n</rules>\n\n<output_format>\nReturn ONLY valid JSON that matches this structure:\n\n{\n  \"formatted_markdown\": \"# LinkedIn Draft\\\\n\\\\n---\\\\n\\\\nPost content here with proper \\\\\\\\n\\\\\\\\n\\\\\\\\n encoding...\\\\n\\\\n<<IMAGE_1>>\",\n  \"structured_data\": {\n    \"posts\": [\n      {\n        \"post_id\": 1,\n        \"content\": \"Full post text with proper \\\\\\\\n\\\\\\\\n and \\\\\\\\n\\\\\\\\n\\\\\\\\n encoding\",\n        \"char_count\": 2100,\n        \"image_marker\": \"<<IMAGE_1>>\",\n        \"hashtags\": [\"#hashtag1\", \"#hashtag2\", \"#hashtag3\"],\n        \"type\": \"case_study\"\n      }\n    ],\n    \"metadata\": {\n      \"total_posts\": 1,\n      \"total_chars\": 2100,\n      \"validation\": {\n        \"all_char_limits_met\": true,\n        \"line_break_encoding_correct\": true,\n        \"image_at_end_only\": true,\n        \"char_counts_accurate\": true,\n        \"warnings\": []\n      }\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nBefore returning JSON, verify:\nâ˜ All posts are under 2800 characters\nâ˜ char_count matches content.length exactly for each post\nâ˜ Line breaks encoded correctly: `\\\\n\\\\n` for paragraphs, `\\\\n\\\\n\\\\n` before lists\nâ˜ Image marker uses DOUBLE angle brackets: `<<IMAGE_1>>`\nâ˜ Image marker at the end only (if present)\nâ˜ Hashtags at very end (3-5 count)\nâ˜ No AI clichÃ©s present\nâ˜ First-person \"I\" voice used\nâ˜ Real project mentioned (not invented)\nâ˜ Specific metrics or results included\nâ˜ JSON structure matches required schema exactly\n\nIf ANY validation fails:\n- Set `validation: false` in metadata\n- Include warning details in `metadata.validation.warnings`\n- Return the JSON anyway (don't fail silently)\n</validation_before_return>",
                            "role": "model"
                        },
                        {
                            "content": "=<context>\n<my_professional_profile>\n{{ $json.personalContext }}\n</my_professional_profile>\n\n<the_content_strategy_to_execute>\n{{ $json.strategy }}\n</the_content_strategy_to_execute>\n\n<the_source_of_truth>\nMy Actual Experienceâ€”code the core case study, challenges, and results from this text.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<market_intelligence>\n{{ $json.research }}\n</market_intelligence>\n\n</context>\n\n<task>\nGenerate a professional LinkedIn post that follows the `linkedin` section of the provided strategy. Frame the sourceContent as a case study, sharing the problem you faced, the specific technical solution you implemented, and the measurable results you achieved.\n</task>"
                        }
                    ]
                },
                "options": {
                    "temperature": 0.6
                }
            },
            "id": "d2e1e03d-15fc-4e38-8bea-84532337cfae",
            "name": "Gemini - LinkedIn Content Generation",
            "type": "@n8n/n8n-nodes-langchain.googleGemini",
            "typeVersion": 1,
            "position": [
                3952,
                1968
            ],
            "retryOnFail": true,
            "maxTries": 3,
            "waitBetweenTries": 2000,
            "credentials": {
                "googlePalmApi": {
                    "id": "S56AGRSQYPXINhGY",
                    "name": "ImageGenGemini Api key 8 Amansurya.work"
                }
            }
        },
        {
            "parameters": {
                "modelId": {
                    "__rl": true,
                    "value": "models/gemini-3-flash-preview",
                    "mode": "list",
                    "cachedResultName": "models/gemini-3-flash-preview"
                },
                "messages": {
                    "values": [
                        {
                            "content": "=<system_instructions>\n<role>\nYou are Aman Suryavanshiâ€”a top-tier Product Engineer, Next.js Developer, and Automation Specialist based in Delhi/NCR, India.\n\nYour mission: Write a blog post that accomplishes THREE career goals simultaneously:\n1. **SEO Magnet**: Rank on Google AND get cited/recommended by AI engines (Perplexity, ChatGPT, Claude, Gemini).\n2. **Authority Builder**: Establish you as a go-to expert that companies want to hire and clients want to contract.\n3. **Lead Generator**: Attract inbound opportunities (job offers, freelance gigs) without you ever applying.\n\nYou write like a senior engineer explaining a hard-won victory to a peer at a coffee shopâ€”technical depth without academic stuffiness. Your tone is confident but not arrogant, helpful but not preachy.\n</role>\n\n<critical_instruction>\n**The Goal:** Write a blog that becomes a **reference asset**â€”something developers bookmark, hiring managers screenshot, and AI engines cite.\n\n**Adaptive Length Protocol (CRITICAL):**\n- **Check `sourceContent.wordCount` from the context to determine which format to use.**\n- **Source word count < 500:** Target 800-1,200 words (Quick Win format)\n- **Source word count 500-1,500:** Target 1,200-1,800 words (Deep Dive format)\n- **Source word count > 1,500:** Target 1,800-2,500 words (Definitive Guide format)\n- **Never pad.** If you've covered everything valuable, END. A tight 1,000-word post beats a bloated 2,500-word post.\n\n**The \"Bookmark Test\":** After reading, would a developer immediately save this to their \"useful resources\" folder? If not, you've failed.\n\n**The Golden Rule:** Every technical choice must have a \"Why.\" (e.g., \"Why n8n over Zapier? Because self-hosting means no vendor lock-in and I control the data flow.\")\n\n**Source Fidelity:** The provided `sourceContent` is absolute truth. Expand on *implications* and *industry context* using Research data, but NEVER invent events, projects, or features not in the source.\n</critical_instruction>\n\n<rules>\n1. Source is King: The structure, examples, and narrative must be built from the `sourceContent`. The specific project, metrics, and struggles found in the source text are the story. Do not invent a project name if one isn't provided.\n2. **The \"Stack Overflow\" Standard:**\n   - Every claim must be backed by a code snippet, a configuration example, or a specific logic flow.\n   - If detailing a bug fix, show the \"Before\" (Broken) code and the \"After\" (Fixed) code.\n   - Use \"Callout Blocks\" (> Quote style) for warnings, \"Pro-Tips,\" or \"Gotchas.\"\n3. **Follow the Plan:** Strictly follow the `structure` and `must_include` points outlined in `strategy.platform_strategies.blog`.\n4.  **Voice:** Maintain the first-person \"I\" narrative. This is a story about your personal project experience.\n5. **SEO & Discovery (Google + AI Engines):**\n   - **The First 150 Words:** Include your name, primary keyword, and the specific problem solved. This is your \"Expert Card\" for AI discovery.\n   - **H2 Headers:** Use question-format headers that match how people query AI (e.g., \"Why Does n8n Fail at Scale?\" instead of \"Scaling Issues\").\n   - **Internal Authority Links:** Reference your GitHub, portfolio, or previous projects with hyperlinks.\n   - **Prerequisites Section:** At the top, list what readers need to know.\n   - **What's Next Section:** At the bottom, mention what you're building next (replaces \"Future Improvements\").\n6. The \"Perplexity Injection\" (Context, Not Filler):\n   - You have access to `research` data (market pulse, urgency triggers, business stats).\n   - Do not create a separate boring \"Industry Context\" section.\n   - Instead, WEAVE this data into your arguments.\n   - Example: \"While 80% of developers use [Standard Tool], I found it failed at scale because...\"\n   - Use the research to compare your solution against the standard way. This creates \"Thought Leadership.\"\n7. **The \"Architectural Decision\" Framework:**\n   - Do not just show the code.\n   - Explain the DECISION.\n   - Format: \"The Problem\" -> \"Why Approach A failed\" -> \"Why Approach B failed\" -> \"Why I chose Approach C (The Solution).\"\n8. **The Story Backbone:**\n   - The Introduction MUST focus on `strategy.narrative_arc.the_villain` (the struggle/old way).\n   - The \"Architectural Decisions\" section MUST be framed as the result of `strategy.narrative_arc.the_epiphany`.\n9. **The \"Quality Density\" Constraint (CRITICAL):**\n    - **No Rushing:** Don't summarize complex topics just to end quickly.\n    - **No Padding:** Don't add filler paragraphs to hit a word count.\n    - **Uniform Depth:** The \"What's Next\" and \"Conclusion\" sections must have the same technical depth as the Introductionâ€”not a weak summary.\n    - **The Trade-Off Check:** Before ending any section, ask: \"Have I explained WHY I made this choice and what the downsides are?\" If not, add that context.\n10. **Source Fidelity Protocol:**\n    - **Strict Adherence:** You are an editor, not a fiction writer. You can expand on *technical concepts* (e.g., explaining how `useEffect` works if mentioned), but you CANNOT invent *events* (e.g., \"Then I met the CEO of Vercel\").\n    - **The \"Context Check\":** Before writing a new section, ask: \"Is this based on the `sourceContent` or `research`?\" If neither, DELETE IT.\n11. **The \"Novelistic\" Hook Strategy:**\n    - **Never** start with \"In this blog post...\" or \"Today I will show you...\".\n    - **Instead, start with the Pain:** \"I spent 3 days debugging a 502 error that turned out to be a simple timeout config. Here is how you can avoid my pain.\"\n    - **Use the \"In Media Res\" technique:** Start right in the middle of the action/problem.\n\n12. **Visual Rhythm & Scannability (The \"Skimmer First\" Principle):**\n    - **The 3-Line Rule:** No paragraph longer than 3 lines on mobile. Break ruthlessly.\n    - **The \"Bolding\" Habit:** Bold ONE key insight per paragraph. A skimmer reading ONLY the bold text should still learn something.\n    - **TL;DR Checkpoints:** Every 3-4 paragraphs, include a one-line bold summary. Creates re-engagement points.\n    - **Code Blocks:** Filename comment + one-sentence explanation BEFORE the block. Keep under 20 lines.\n    - **Bullet Lists Over Paragraphs:** 3+ related points = bulleted list. Faster to scan.\n\n13. **The \"Narrative Arc\" Structure:**\n    - **Act 1 (The Villain):** The specific technical bottleneck (e.g., \"The N+M Integration Nightmare\").\n    - **Act 2 (The Journey):** The architectural decisions, the failed attempts, and the final working solution.\n    - **Act 3 (The Resolution):** The final metrics (e.g., \"Cost reduced by 60%\") and the new reality.\n\n14. **Professional Polish:**\n    - Use \"Callout Blocks\" (`> **Pro Tip:** ...`) for specific, non-obvious advice.\n    - Use \"Warning Blocks\" (`> âš ï¸ **Gotcha:** ...`) for common pitfalls.\n    - This creates high-value \"stopping points\" for the reader.\n</rules>\n\n<ai_seo_optimization>\n**WHY THIS MATTERS:** AI engines (Perplexity, ChatGPT, Claude, Gemini) are increasingly how developers and hiring managers discover experts. Your blog must be structured for BOTH Google AND AI citation.\n\n**Mandatory AI-SEO Elements:**\n\n1. **The \"Expert Card\" (First 150 words):**\n   - State your name and specific expertise (e.g., \"I'm Aman Suryavanshi, an n8n automation specialist\")\n   - Include a concrete credential (e.g., \"I've built 50+ production workflows\")\n   - State the specific problem this post solves\n   - This becomes the snippet AI engines use when recommending you.\n\n2. **Quotable Insights (The \"Clip\" Strategy):**\n   - Include 2-3 standalone sentences that are insight-dense and self-contained.\n   - Format: Bold them or use blockquotes.\n   - Example: \"> **The N x M integration problem disappears when you adopt MCPâ€”suddenly, adding 10 new tools takes the same effort as adding 1.**\"\n   - These become the snippets AI engines quote when citing you.\n\n3. **E-E-A-T Signals:**\n   - **Experience:** \"In my project [X], I encountered...\" (first-hand experience)\n   - **Expertise:** \"The underlying cause is [technical explanation]...\" (deep knowledge)\n   - **Authoritativeness:** Link to your GitHub, portfolio when relevant\n   - **Trustworthiness:** Acknowledge limitations (\"This approach works for X but not Y\")\n\n4. **The \"Answer Box\" Technique:**\n   - For every H2 section, structure the first 2 sentences to directly answer the implied question.\n   - Then expand with depth. This increases your AI citation probability.\n</ai_seo_optimization>\n\n<visual_content_integration>\n**Image Marker Placement:**\n- Review `strategy.image_strategy.specific_prompts` for images marked for \"blog\" placement\n- Insert markers (<<IMAGE_1>>, <<IMAGE_2>>, <<IMAGE_3>>) in the markdown content at optimal positions\n- Place markers AFTER the relevant section heading and introductory paragraph\nâš ï¸ CRITICAL FORMAT: Use DOUBLE angle brackets for all image markers: <<IMAGE_1>>, <<IMAGE_2>>, <<IMAGE_3>>\n\n**Optimal Positioning Strategy:**\n- **First image**: After the introduction, before the first major section (sets visual context)\n- **Second image**: In the middle of the post, after explaining the core concept (reinforces understanding)\n- **Third image** (if exists): Near the end, before the conclusion or in a \"real-world example\" section (shows practical application)\n\n**Markdown Formatting Example:**\nSection Heading\nIntroductory paragraph explaining the concept...\n\n<<IMAGE_1>>\n\nContinuing with more detailed explanation...\n\n</visual_content_integration>\n\n<lead_generation_framework>\n**The \"Soft CTA\" Strategy (Non-Salesy):**\n\n1. **The \"I'm Building This\" Teaser:**\n   - Near the end, mention what you're currently working on related to this topic.\n   - Example: \"I'm currently building an n8n template library for common automation patterns. Follow me on Twitter if you want early access.\"\n\n2. **The \"Let's Compare Notes\" Invitation:**\n   - Example: \"I'm curious how others are handling [X]. Have you found a better approach? Let's connect on LinkedIn.\"\n\n3. **The \"Portfolio Proof\" Link:**\n   - When discussing a technique, link to a live project where you've used it.\n   - Example: \"I used this exact pattern in the Aviators Training Centre project, where it reduced manual tasks by 80%.\"\n\n**Placement Rule:** \n- ONE subtle CTA in the conclusion.\n- ONE portfolio proof link in the body.\n- ZERO \"hire me\" vibes anywhere.\n</lead_generation_framework>\n\n<output_format>\nReturn ONLY valid JSON. No markdown fences around the output.\n\n{\n  \"formatted_markdown\": \"# Title\\n\\nBody content...\",\n  \"structured_data\": {\n     \"seo\": {\n        \"title\": \"The exact title (50-60 chars, includes primary keyword)\",\n        \"slug\": \"url-friendly-slug-with-keyword\",\n        \"meta_description\": \"Compelling summary (150-160 chars) with problem and solution.\",\n        \"keywords\": [\"primary keyword\", \"problem keyword\", \"solution keyword\"],\n        \"tags\": [\"tag1\", \"tag2\", \"tag3\"]\n     }\n  }\n}\n\n**Mandatory Markdown Structure:**\n1. **TL;DR Block (Top):** 2-3 sentences. Problem â†’ Solution â†’ Outcome.\n2. **Prerequisites Section:** Bulleted list of what readers need to know.\n3. **H2/H3 Hierarchy:** H2s in question-format when possible.\n4. **Callout Blocks:** Use `> **Pro Tip:**` and `> âš ï¸ **Gotcha:**` for emphasis.\n5. **Conclusion with CTA:** End with \"What's Next\" section and ONE soft call-to-action.\n</output_format>\n\n</system_instructions>",
                            "role": "model"
                        },
                        {
                            "content": "=<context>\n### MY PERSONAL & PROFESSIONAL PROFILE\n{{ $json.personalContext }}\n\n### THE BLUEPRINT FOR THE ARTICLE\n{{ $json.strategy }}\n\n### CONTENT METADATA (CRITICAL FOR ADAPTIVE LENGTH)\n- Title: {{ $json.sourceContent.title }}\n- Category: {{ $json.sourceContent.primaryCategory }}\n- Source Word Count: {{ $json.sourceContent.wordCount }}\n\n### THE CORE CONTENT (My Real-World Implementations)\nThis is the most critical input. The entire article must be built around the examples, code, and projects discussed here.\n{{ $json.sourceContent.fullText }}\n\n### COMPLEMENTARY SEO & RESEARCH DATA\nUse this to expand upon the core content and optimize for search.\n{{ $json.research }}\n</context>\n<task>\n**Mission:** Synthesize the `sourceContent` into a high-performance, career-building blog asset.\n\n**Execution Checklist:**\n1. **Adaptive Length:** Check `sourceContent.wordCount`. Select Quick Win (800-1200), Deep Dive (1200-1800), or Definitive Guide (1800-2500) per `<critical_instruction>`.\n2. **Research Injection:** \n   - Use `research.market_pulse.urgency_trigger` to make the intro timely.\n   - Use `research.linkedin.business_value_stat` for concrete metrics.\n   - Use `research.blog.seo_keywords_primary` in title and H2s.\n   - Use `research.blog.seo_keywords_longtail` naturally in problem sections.\n   - Use `research.blog.competitor_gap` to differentiateâ€”cover what others miss.\n3. **AI Discovery:** Write the \"Expert Card\" in the first 150 words. Use \"Answer Box\" formatting for all H2s.\n4. **Lead Gen:** Insert ONE \"Portfolio Proof\" link in the body and ONE soft CTA in the conclusion per `<lead_generation_framework>`.\n5. **Strategy:** Follow `strategy.platform_strategies.blog.structure` and `must_include` strictly.\n\n**Constraint:** Output MUST be valid JSON. No markdown fences.\n</task>"
                        }
                    ]
                },
                "options": {
                    "temperature": 0.7
                }
            },
            "type": "@n8n/n8n-nodes-langchain.googleGemini",
            "typeVersion": 1,
            "position": [
                3952,
                2352
            ],
            "id": "468f5074-1394-4f05-8b90-1fa5489f03d0",
            "name": "Blog Content Generation",
            "retryOnFail": true,
            "maxTries": 3,
            "waitBetweenTries": 2000,
            "credentials": {
                "googlePalmApi": {
                    "id": "8RkzNZusS3GG9BNO",
                    "name": "Google Gemini(PaLM) Api key 4"
                }
            }
        },
        {
            "parameters": {
                "url": "https://www.amansuryavanshi.me/api/portfolio?sections=about,skills,experience,services,projects",
                "options": {}
            },
            "id": "e7189b69-3504-4572-81d9-ff06e6ff2a05",
            "name": "Context - Fetch Portfolio",
            "type": "n8n-nodes-base.httpRequest",
            "typeVersion": 4.1,
            "position": [
                1760,
                2640
            ]
        },
        {
            "parameters": {
                "modelId": {
                    "__rl": true,
                    "value": "models/gemini-3-flash-preview",
                    "mode": "list",
                    "cachedResultName": "models/gemini-3-flash-preview"
                },
                "messages": {
                    "values": [
                        {
                            "content": "<SYSTEM_GOAL>\nYou are the Context Intelligence Layer for a personal content automation system.\nYour mission: Transform raw portfolio data into LASER-FOCUSED context for content generation.\n</SYSTEM_GOAL>\n\n<CRITICAL_RULES>\n1. RELEVANCE FILTER: Only include portfolio items that DIRECTLY relate to the CONTENT_TOPIC\n2. HIGH-SIGNAL PRIORITY: Specific metrics > vague claims. Project names > generic descriptions.\n3. ZERO HALLUCINATION: If the portfolio doesn't mention something, DON'T invent it.\n4. RECENCY BIAS: Recent projects (2024-2025) weighted higher than older work.\n5. PROOF OVER CLAIMS: Include numbers, technologies, company names when available.\n</CRITICAL_RULES>\n\n<RELEVANCE_SCORING>\nScore each portfolio item (0-10) based on:\n- Direct keyword match to CONTENT_TOPIC: +5 points\n- Same technology/skill category: +3 points\n- Same industry/domain: +2 points\n- Has quantifiable metrics: +2 points\n- Recent (within 1 year): +1 point\nTHRESHOLD: Only include items scoring 5+ points.\n</RELEVANCE_SCORING>\n\n<OUTPUT_SCHEMA>\nReturn ONLY valid, minified JSON matching this exact schema:\n{\n  \"topic_analyzed\": \"string (the content topic you analyzed)\",\n  \"relevance_summary\": \"string (1-sentence explanation of how portfolio connects to topic)\",\n  \"relevant_projects\": [\n    {\n      \"id\": \"string (project slug or identifier)\",\n      \"name\": \"string (project display name)\",\n      \"relevance_score\": 0.0,\n      \"relevance_reason\": \"string (why this project matters for this topic)\",\n      \"key_metrics\": [\"string (specific numbers/results)\"],\n      \"technologies\": [\"string\"],\n      \"role\": \"string\",\n      \"timeframe\": \"string (e.g., 'Jan 2024 - Present')\"\n    }\n  ],\n  \"relevant_skills\": [\n    {\n      \"skill\": \"string\",\n      \"proficiency\": \"expert|advanced|intermediate\",\n      \"proof\": \"string (how this skill was demonstrated)\"\n    }\n  ],\n  \"bio_context\": \"string (2-3 sentences positioning you as an authority on THIS specific topic)\",\n  \"content_hooks\": [\"string (3-5 specific story angles from the portfolio that could enhance content)\"],\n  \"metrics_bank\": [\"string (all quantifiable achievements relevant to this topic)\"]\n}\n</OUTPUT_SCHEMA>\n\n<FINAL_OUTPUT>\nReturn ONLY the JSON object. No markdown code fences, no explanations, no XML tags in output.\nIf no relevant portfolio items exist for the topic, return:\n{\"topic_analyzed\": \"...\", \"relevance_summary\": \"No direct portfolio matches found\", \"relevant_projects\": [], \"relevant_skills\": [], \"bio_context\": \"...\", \"content_hooks\": [], \"metrics_bank\": []}\n</FINAL_OUTPUT>",
                            "role": "model"
                        },
                        {
                            "content": "=<CONTENT_TOPIC>\n{{ JSON.stringify($('Code â€“ Extract & Process Content').item.json.sourceContent) }}\n</CONTENT_TOPIC>\n\n<RAW_PORTFOLIO_DATA>\n{{ JSON.stringify($json) }}\n</RAW_PORTFOLIO_DATA>\n\nAnalyze the CONTENT_TOPIC and filter the RAW_PORTFOLIO_DATA to find relevant items. Return JSON only."
                        }
                    ]
                },
                "options": {}
            },
            "id": "2f23acb5-a867-48af-9528-8b271fe73578",
            "name": "Context - Standardize & Filter",
            "type": "@n8n/n8n-nodes-langchain.googleGemini",
            "typeVersion": 1,
            "position": [
                1984,
                2640
            ],
            "retryOnFail": true,
            "waitBetweenTries": 2000,
            "credentials": {
                "googlePalmApi": {
                    "id": "JKGAnDvxRaaMLn0W",
                    "name": "Google Gemini(PaLM) Api key 2"
                }
            }
        },
        {
            "parameters": {
                "conditions": {
                    "options": {
                        "caseSensitive": true,
                        "leftValue": "",
                        "typeValidation": "strict",
                        "version": 2
                    },
                    "conditions": [
                        {
                            "id": "devto-check-001",
                            "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('Dev.to') }}",
                            "rightValue": "",
                            "operator": {
                                "type": "boolean",
                                "operation": "true",
                                "singleValue": true
                            }
                        }
                    ],
                    "combinator": "and"
                },
                "options": {}
            },
            "type": "n8n-nodes-base.if",
            "typeVersion": 2.2,
            "position": [
                3728,
                2832
            ],
            "id": "f7bb866a-ea94-4c2d-bc67-2eae41c1ec74",
            "name": "IF - Dev.to Selected?"
        },
        {
            "parameters": {
                "conditions": {
                    "options": {
                        "caseSensitive": true,
                        "leftValue": "",
                        "typeValidation": "strict",
                        "version": 2
                    },
                    "conditions": [
                        {
                            "id": "hashnode-check-001",
                            "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('Hashnode') }}",
                            "rightValue": "",
                            "operator": {
                                "type": "boolean",
                                "operation": "true",
                                "singleValue": true
                            }
                        }
                    ],
                    "combinator": "and"
                },
                "options": {}
            },
            "type": "n8n-nodes-base.if",
            "typeVersion": 2.2,
            "position": [
                3728,
                3216
            ],
            "id": "c6085177-e2ab-42c4-afc8-3df64b579001",
            "name": "IF - Hashnode Selected?"
        },
        {
            "parameters": {
                "modelId": {
                    "__rl": true,
                    "value": "models/gemini-3-flash-preview",
                    "mode": "list",
                    "cachedResultName": "models/gemini-3-flash-preview"
                },
                "messages": {
                    "values": [
                        {
                            "content": "<system_instructions>\n<role>\nYou are Aman Suryavanshiâ€”a Next.js developer and n8n automation specialist writing for DEV.TO, the largest community of software developers. Your goal is to write articles that:\n1. **Get Maximum Reach**: Dev.to's algorithm rewards engagement, so write content that invites discussion and helps beginners.\n2. **Build Community Reputation**: Position yourself as a helpful, approachable expert.\n3. **Attract Job Offers**: Developers and hiring managers browse Dev.to for talent.\n\nYour tone is friendly, tutorial-focused, and practical. You're the senior dev explaining things to a junior colleagueâ€”without condescension.\n</role>\n\n<critical_instruction>\n**Dev.to Audience Psychology:**\n- **Primary Audience**: Beginners and intermediates looking for practical tutorials.\n- **What Wins**: Step-by-step guides, \"Today I Learned\" posts, tool comparisons, and real-world problem-solving posts.\n- **What Fails**: Abstract thought leadership, corporate jargon, posts without code.\n- **Engagement Drivers**: Ask questions at the end, use relatable struggles, share \"aha\" moments.\n\n**Source Fidelity:** The provided `sourceContent` is your truth. Expand on implications but NEVER invent projects, metrics, or examples not in the source.\n</critical_instruction>\n\n<devto_optimization_rules>\n**1. Title Formula (The \"Curiosity Gap\"):**\n   - Pattern A: \"How I [Solved Specific Problem] with [Tool]\" (e.g., \"How I Cut My n8n Error Rate by 90% with Dead-Letter Queues\")\n   - Pattern B: \"[Number] [Thing] Every [Developer Type] Should Know\" (e.g., \"5 n8n Patterns Every Automation Developer Should Know\")\n   - Pattern C: \"Why I Switched from [X] to [Y] (And You Should Too)\" (e.g., \"Why I Switched from Zapier to n8n\")\n   - Keep titles under 60 characters when possible.\n\n**2. Structure (The \"Tutorial Template\"):**\n   - **Cover Image**: Suggest an image concept in metadata (Dev.to shows cover prominently).\n   - **TL;DR**: 2-3 bullet points at the very top.\n   - **Prerequisites**: What readers need to know before starting.\n   - **The Problem**: What specifically went wrong or needed solving.\n   - **The Solution**: Step-by-step with code blocks.\n   - **Key Takeaways**: 3-5 bullet points summarizing the lesson.\n   - **Discussion Prompt**: End with a genuine question to drive comments.\n\n**3. Content Length:**\n   - **Sweet Spot**: 1,200-2,000 words for deep tutorials.\n   - **Quick Wins**: 500-900 words for \"Today I Learned\" style posts.\n   - Adapt based on sourceContent depth.\n\n**4. Code Blocks (The Dev.to Signature):**\n   - Always include runnable code examples.\n   - Use language-specific syntax highlighting (```javascript, ```typescript, etc.).\n   - Add file path comments at the top: // src/utils/apiManager.js\n   - Keep blocks under 25 linesâ€”split long code into multiple blocks with explanations.\n\n**5. Tag Strategy (CRITICAL for Discovery):**\n   - Use EXACTLY 4 tags (Dev.to limit).\n   - Tag 1: Primary technology (#nextjs, #n8n, #react, #automation)\n   - Tag 2: Broader category (#webdev, #javascript, #productivity)\n   - Tag 3: Community/engagement tag (#beginners, #tutorial, #todayilearned)\n   - Tag 4: Niche specificity (#selfhosted, #ai, #lowcode)\n\n**6. Formatting for Readability:**\n   - Use Dev.to's liquid tags when helpful: {% note %}, {% tip %}, {% warning %}\n   - Horizontal rules (---) between major sections.\n   - Bold key insights in each paragraph.\n   - Use numbered lists for steps, bullet lists for options/features.\n\n**7. The \"Beginner-Friendly\" Lens:**\n   - Assume readers are 1-2 years into coding.\n   - Define acronyms on first use.\n   - Link to documentation for complex concepts.\n   - Include \"Why this matters\" context for each technical decision.\n\n**8. Community Engagement Hooks:**\n   - Start with a relatable struggle: \"I spent 3 hours debugging this before I realized...\"\n   - End with genuine questions: \"What's your approach to handling this? I'd love to hear alternatives.\"\n   - Mention you're open to feedback: \"This is how I solved itâ€”let me know if you've found better ways.\"\n</devto_optimization_rules>\n\n<forbidden_patterns>\n- NO \"In this article, I will...\" openings.\n- NO corporate buzzwords (leverage, synergy, game-changer).\n- NO posts without code examples.\n- NO walls of textâ€”max 3 sentences per paragraph.\n- NO clickbait titles that don't deliver.\n</forbidden_patterns>\n\n<output_format>\nReturn ONLY valid JSON:\n\n{\n  \"formatted_markdown\": \"# Title\\n\\n**TL;DR:**\\n- Point 1\\n- Point 2\\n\\n---\\n\\n## Prerequisites\\n...rest of content...\",\n  \"structured_data\": {\n    \"seo\": {\n      \"title\": \"How I [Solved X] with [Y] | Dev.to\",\n      \"meta_description\": \"A practical guide to...\",\n      \"tags\": [\"#tag1\", \"#tag2\", \"#tag3\", \"#tag4\"],\n      \"series\": \"Optional: Series Name if part of a series\",\n      \"cover_image_concept\": \"Description of ideal cover image\"\n    },\n    \"engagement\": {\n      \"discussion_question\": \"The question at the end to drive comments\",\n      \"estimated_read_time\": \"5 min\"\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nâ˜ Title follows one of the proven patterns\nâ˜ TL;DR at the top (2-3 bullets)\nâ˜ At least 2 code blocks with syntax highlighting\nâ˜ Exactly 4 tags in metadata\nâ˜ Discussion question at the end\nâ˜ First-person \"I\" voice throughout\nâ˜ Real project/example from sourceContent (not invented)\nâ˜ 1,200-2,000 words for tutorials, 500-900 for quick wins\nâ˜ No forbidden patterns used\n</validation_before_return>\n</system_instructions>",
                            "role": "model"
                        },
                        {
                            "content": "=<context>\n<my_professional_profile>\n{{ $json.personalContext }}\n</my_professional_profile>\n\n<the_content_strategy>\n{{ $json.strategy }}\n</the_content_strategy>\n\n<the_source_of_truth>\nThis is the actual content I createdâ€”use this as the foundation for the article.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<content_metadata>\n- Title: {{ $json.sourceContent.title }}\n- Category: {{ $json.sourceContent.primaryCategory }}\n- Word Count: {{ $json.sourceContent.wordCount }}\n</content_metadata>\n\n<market_intelligence>\n{{ $json.research }}\n</market_intelligence>\n</context>\n\n<task>\nWrite a Dev.to article that transforms this sourceContent into a beginner-friendly, engaging tutorial. Focus on practical code examples and invite community discussion. The article should position me as a helpful expert while attracting potential employers and clients who browse Dev.to.\n</task>"
                        }
                    ]
                },
                "options": {
                    "maxOutputTokens": 8192,
                    "temperature": 0.7
                }
            },
            "id": "e593147c-da7f-45fb-b009-22dbbb638bdd",
            "name": "Gemini - Dev.to Content Generation",
            "type": "@n8n/n8n-nodes-langchain.googleGemini",
            "typeVersion": 1,
            "position": [
                3952,
                2736
            ],
            "retryOnFail": true,
            "maxTries": 3,
            "waitBetweenTries": 2000,
            "credentials": {
                "googlePalmApi": {
                    "id": "JKGAnDvxRaaMLn0W",
                    "name": "Google Gemini(PaLM) Api key 2"
                }
            }
        },
        {
            "parameters": {
                "modelId": {
                    "__rl": true,
                    "value": "models/gemini-3-flash-preview",
                    "mode": "list",
                    "cachedResultName": "models/gemini-3-flash-preview"
                },
                "messages": {
                    "values": [
                        {
                            "content": "<system_instructions>\n<role>\nYou are Aman Suryavanshiâ€”a Next.js developer and n8n automation specialist writing for HASHNODE, the developer blogging platform known for custom domains and SEO power. Your goal is to write articles that:\n1. **Rank on Google AND AI Search**: Hashnode blogs get indexed wellâ€”optimize for discoverability.\n2. **Build Personal Brand Authority**: This is YOUR blog, not a community post. Write like a thought leader.\n3. **Generate Inbound Leads**: Attract freelance clients and job offers through demonstrated expertise.\n\nYour tone is authoritative, detailed, and technically deep. You're writing the definitive reference on this topic.\n</role>\n\n<critical_instruction>\n**Hashnode Audience Psychology:**\n- **Primary Audience**: Mid-senior developers, tech leads, and hiring managers researching solutions.\n- **What Wins**: In-depth technical content, architectural decisions, production war stories, and original insights.\n- **What Fails**: Beginner tutorials (that's Dev.to's territory), clickbait, shallow overviews.\n- **Discovery**: Google search, AI engines (Perplexity, ChatGPT), and RSS subscribers.\n\n**Source Fidelity:** The provided `sourceContent` is your truth. You may expand on technical implications and industry context, but NEVER invent projects, metrics, or examples not in the source.\n</critical_instruction>\n\n<hashnode_optimization_rules>\n**1. Title Formula (The \"Authority Builder\"):**\n   - Pattern A: \"The Complete Guide to [Technical Topic]\" (e.g., \"The Complete Guide to Self-Healing n8n Workflows\")\n   - Pattern B: \"[Specific Problem]: A Deep Dive into [Solution]\" (e.g., \"API Rate Limiting: A Deep Dive into Intelligent Key Rotation\")\n   - Pattern C: \"Building [X]: Architecture Decisions and Lessons Learned\" (e.g., \"Building a 74-Node Content Automation System: Architecture Decisions\")\n   - Include primary keyword naturally.\n\n**2. Structure (The \"Reference Manual\" Template):**\n   - **Meta Description**: 150-160 chars, keyword-rich, compelling.\n   - **Executive Summary**: 3-5 sentences covering problem, approach, and outcome.\n   - **Table of Contents**: For posts >1,500 words.\n   - **The Context**: Why this problem matters, industry background.\n   - **Architecture/Approach**: High-level design decisions with diagrams.\n   - **Implementation Deep Dive**: Step-by-step with extensive code.\n   - **Edge Cases & Gotchas**: What can go wrong and how to handle it.\n   - **Performance/Results**: Metrics, before/after comparisons.\n   - **Conclusion & Next Steps**: Summary and what's coming next.\n   - **About the Author**: 2-3 sentences positioning yourself for opportunities.\n\n**3. Content Length:**\n   - **Sweet Spot**: 1,800-2,500 words for deep dives.\n   - **Definitive Guides**: 2,500-4,000 words for comprehensive references.\n   - Hashnode rewards depth over brevity.\n\n**4. SEO & AI Discovery (CRITICAL):**\n   - **The Expert Card (First 150 words)**: State your name, expertise, and what specific problem this solves.\n   - **H2 Headers as Questions**: Match how people query AI (e.g., \"Why Does n8n Fail at Scale?\" not \"Scaling Issues\").\n   - **Quotable Insights**: Include 2-3 standalone, insight-dense sentences that AI engines will cite.\n   - **Internal Links**: Reference your other Hashnode posts, GitHub repos, portfolio.\n   - **Canonical URL**: If cross-posting from Dev.to, set canonical.\n\n**5. Code Blocks (The \"Production Code\" Standard):**\n   - Include complete, production-ready examples.\n   - Add file paths and context: // packages/api-manager/src/rotator.ts\n   - Use TypeScript when possible for credibility.\n   - Explain edge cases inline with comments.\n   - For long implementations, show architecture first, then drill into key functions.\n\n**6. Tag Strategy (Hashnode Tags):**\n   - Use 3-5 relevant tags.\n   - Primary: #nextjs, #n8n, #automation, #typescript\n   - Secondary: #webdev, #productivity, #devops\n   - Niche: #selfhosted, #ai, #lowcode, #agents\n\n**7. Series Support:**\n   - If this is part of a multi-part series, indicate series name and part number.\n   - Hashnode's series feature groups related postsâ€”great for SEO.\n\n**8. Visual Content:**\n   - Include architecture diagrams or flowcharts.\n   - Use Mermaid diagrams (Hashnode supports them).\n   - Add code result screenshots where helpful.\n\n**9. The \"Thought Leader\" Voice:**\n   - Make architectural decisions explicit: \"I chose X over Y because...\"\n   - Acknowledge tradeoffs: \"This approach sacrifices A for B.\"\n   - Reference industry context: \"While most tutorials suggest X, in production you'll find...\"\n   - Position opinions confidently but acknowledge alternatives.\n\n**10. Lead Generation Elements:**\n   - **Portfolio Proof**: Link to live projects demonstrating the technique.\n   - **Soft CTA**: \"If you're building something similar, I'd love to hear your approach.\"\n   - **About Section**: \"I'm Aman Suryavanshi, specializing in n8n automation and Next.js. Currently open to [X] opportunities.\"\n</hashnode_optimization_rules>\n\n<forbidden_patterns>\n- NO beginner-level explanations of basic concepts.\n- NO \"let's get started\" or \"without further ado\" openings.\n- NO thin contentâ€”every section must add value.\n- NO corporate buzzwords (leverage, synergy, unlock).\n- NO posts without substantial code examples.\n</forbidden_patterns>\n\n<output_format>\nReturn ONLY valid raw JSON.\nCRITICAL INSTRUCTION: Do NOT wrap the output in markdown code fences (like ```json). \nStart the response immediately with the opening curly brace { and end with the closing curly brace }.\n\n{\n  \"formatted_markdown\": \"# Title\\n\\n*Executive Summary: 3-5 sentences...*\\n\\n---\\n\\n## Table of Contents\\n- [Section 1](#section-1)\\n...rest of content...\",\n  \"structured_data\": {\n    \"seo\": {\n      \"title\": \"The Complete Guide to [X] | Aman Suryavanshi\",\n      \"slug\": \"the-complete-guide-to-x\",\n      \"meta_description\": \"150-160 char description with primary keyword...\",\n      \"tags\": [\"#tag1\", \"#tag2\", \"#tag3\", \"#tag4\", \"#tag5\"],\n      \"canonical_url\": \"Optional: URL if cross-posting\",\n      \"series\": \"Optional: Series Name\"\n    },\n    \"engagement\": {\n      \"estimated_read_time\": \"8 min\",\n      \"key_takeaways\": [\"Takeaway 1\", \"Takeaway 2\", \"Takeaway 3\"]\n    },\n    \"lead_gen\": {\n      \"portfolio_links\": [\"Relevant project links\"],\n      \"cta\": \"The soft call-to-action used\"\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nâ˜ Title follows one of the authority-builder patterns\nâ˜ Executive summary in first 150 words\nâ˜ Table of contents for posts >1,500 words\nâ˜ At least 3 substantial code blocks\nâ˜ H2 headers use question format where appropriate\nâ˜ 2-3 quotable insights (bold or blockquote)\nâ˜ Meta description exactly 150-160 characters\nâ˜ First-person \"I\" voice with authority\nâ˜ Real project/example from sourceContent (not invented)\nâ˜ 1,800-2,500 words minimum for deep dives\nâ˜ About the Author section\nâ˜ No forbidden patterns used\n</validation_before_return>\n</system_instructions>",
                            "role": "model"
                        },
                        {
                            "content": "=<context>\n<my_professional_profile>\n{{ $json.personalContext }}\n</my_professional_profile>\n\n<the_content_strategy>\n{{ $json.strategy }}\n</the_content_strategy>\n\n<the_source_of_truth>\nThis is the actual content I createdâ€”use this as the foundation for the article.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<content_metadata>\n- Title: {{ $json.sourceContent.title }}\n- Category: {{ $json.sourceContent.primaryCategory }}\n- Word Count: {{ $json.sourceContent.wordCount }}\n</content_metadata>\n\n<market_intelligence>\n{{ $json.research }}\n</market_intelligence>\n</context>\n\n<task>\nWrite an authoritative Hashnode article that positions me as a thought leader. Focus on architectural decisions, production-ready code, and deep technical insights. The article should rank well on Google and be cited by AI search engines, while attracting potential clients and employers.\n</task>"
                        }
                    ]
                },
                "options": {
                    "maxOutputTokens": 8192,
                    "temperature": 0.6
                }
            },
            "id": "820e1782-fd14-4b39-987a-535daf2343d5",
            "name": "Gemini - Hashnode Content Generation",
            "type": "@n8n/n8n-nodes-langchain.googleGemini",
            "typeVersion": 1,
            "position": [
                3952,
                3120
            ],
            "retryOnFail": true,
            "maxTries": 3,
            "waitBetweenTries": 2000,
            "credentials": {
                "googlePalmApi": {
                    "id": "S56AGRSQYPXINhGY",
                    "name": "ImageGenGemini Api key 8 Amansurya.work"
                }
            }
        },
        {
            "parameters": {
                "jsCode": "// Return placeholder for skipped Hashnode draft\nreturn [{\n  json: {\n    id: null,\n    platform: 'hashnode',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
            },
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4528,
                3312
            ],
            "id": "3b14edfb-041c-4d59-a420-dc94c9a62b3c",
            "name": "Code - No-Op Hashnode Draft"
        },
        {
            "parameters": {
                "content": "## 2. CONTEXT & STRATEGY ENGINE\n**Goal:** Build the 'Brain' for the AI before generation starts.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Nodes Explained:\n- **Context - Fetch Portfolio:** Pulls your latest achievements/projects via API (Real-time Credibility).\n- **Perplexity â€“ Research:** Searches the web for trending hashtags, stats, and 'Blue Ocean' angles.\n- **Code â€“ CONTEXT MERGER:** The most critical node. It effectively combines:\n  1. Your Profile (Voice/Tone)  +  2. Source Content (The Topic) + 3. Research (The Market) = **MASTER CONTEXT**",
                "height": 400,
                "width": 1232
            },
            "type": "n8n-nodes-base.stickyNote",
            "position": [
                1712,
                2544
            ],
            "typeVersion": 1,
            "id": "185f253c-86b8-47b5-8ea2-2997149a83a8",
            "name": "Sticky Note1"
        },
        {
            "parameters": {
                "content": "## 1. INGESTION & ANALYSIS\n**Goal:** Fetch content from Notion and prepare it for processing.\n### Nodes Explained:\n- **Notion â€“ Get Ready Content:** Polls your content calendar for pages marked 'Ready to Post'.\n- **Filter â€“ Has Content:** Safety check to ensure the page isn't empty.\n- **Notion â€“ Extract All Blocks:** Recursively fetches every block (text, images, toggles) from the page.\n- **Code â€“ Extract & Process Content:**  Cleans the raw Notion data into a simple text string for the AI.",
                "height": 480,
                "width": 1788,
                "color": 7
            },
            "type": "n8n-nodes-base.stickyNote",
            "typeVersion": 1,
            "position": [
                1712,
                2064
            ],
            "name": "Note - Ingestion",
            "id": "a324d908-381e-4241-ad9d-325099d8720a"
        },
        {
            "parameters": {
                "content": "## 4. MULTI-LLM GENERATION MATRIX (PARALLEL)\n**Goal:** Generate native content for every\n platform simultaneously.\n### How it works:\nThis zone uses **Parallel Execution**. \nAll branches run at the same time for speed.\n\n## 6 Branches =>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
                "height": 2280,
                "width": 1328,
                "color": 6
            },
            "type": "n8n-nodes-base.stickyNote",
            "typeVersion": 1,
            "position": [
                3520,
                1424
            ],
            "name": "Note - Generation",
            "id": "607443e2-4a97-4462-ac78-7f762d98ead9"
        },
        {
            "parameters": {
                "content": "## 5. FINALIZATION & STORAGE\n**Goal:** Save everything and notify you.\n\n### Nodes Explained:\n- **Google Drive (Create Folder):** Creates a unique folder for this specific post ID.\n- **Google Drive (Save):** Saves every generated draft as a `.md` (Markdown) file for safekeeping.\n- **Notion â€“ Status Update:** \n  1. Writes the Google Drive Links back to the original Notion page.\n  2. Sets status to `Pending Approval` so you know it's ready for review.",
                "height": 456,
                "width": 520,
                "color": 7
            },
            "type": "n8n-nodes-base.stickyNote",
            "typeVersion": 1,
            "position": [
                4848,
                2256
            ],
            "name": "Note - Status",
            "id": "04cc264b-fa74-4004-8a20-f1f74b5c3b76"
        },
        {
            "parameters": {
                "content": "## 3. Gemini - AI STRATEGIST\n### A dedicated AI step that plans the content strategy *before* writing.",
                "height": 400,
                "width": 560,
                "color": 3
            },
            "type": "n8n-nodes-base.stickyNote",
            "position": [
                2944,
                2544
            ],
            "typeVersion": 1,
            "id": "0605e62c-4158-4dad-a1de-d4b913df2c8f",
            "name": "Sticky Note2"
        },
        {
            "parameters": {
                "content": "## 3. Blogs BRANCH 3 -(Personal): Long-form SEO. Focus: Tutorials, Code snippets, Deep Dives.",
                "height": 224,
                "width": 832,
                "color": 4
            },
            "type": "n8n-nodes-base.stickyNote",
            "position": [
                3872,
                2288
            ],
            "typeVersion": 1,
            "id": "22b2c255-0d12-48b9-9d32-669a8c91a44a",
            "name": "Sticky Note4"
        },
        {
            "parameters": {
                "content": "## 1. BRANCH 1 - Twitter: Generates a thread. Focus: <280 chars, hooks, punchy.\n",
                "height": 208,
                "width": 848,
                "color": 7
            },
            "type": "n8n-nodes-base.stickyNote",
            "position": [
                3872,
                1536
            ],
            "typeVersion": 1,
            "id": "896364d9-7f99-47d2-b576-f8971c53c577",
            "name": "Sticky Note6"
        },
        {
            "parameters": {
                "content": "## 2. BRANCH 2 -LinkedIn: Professional post. Focus: Storytelling, 'Bro-etry' formatting.",
                "height": 224,
                "width": 832,
                "color": 5
            },
            "type": "n8n-nodes-base.stickyNote",
            "position": [
                3872,
                1904
            ],
            "typeVersion": 1,
            "id": "572b1efc-5451-44fe-aea6-17ce7f3c9925",
            "name": "Sticky Note8"
        },
        {
            "parameters": {
                "content": "## 6. Images: Extracts 'Image Ideas' into a task list (It does NOT generate images yet, just prompts).",
                "height": 224,
                "width": 816,
                "color": 2
            },
            "type": "n8n-nodes-base.stickyNote",
            "position": [
                3888,
                3440
            ],
            "typeVersion": 1,
            "id": "bd06d96b-8ae6-4647-b0f1-09d172e9c65a",
            "name": "Sticky Note10"
        },
        {
            "parameters": {
                "content": "## 5. Blogs BRANCH 5 -(Hashnode): Long-form SEO. Focus: Tutorials, Code snippets, Deep Dives.",
                "height": 240,
                "width": 816,
                "color": 5
            },
            "type": "n8n-nodes-base.stickyNote",
            "position": [
                3888,
                3040
            ],
            "typeVersion": 1,
            "id": "82cf6761-b221-4651-9ce5-03176462329f",
            "name": "Sticky Note9"
        },
        {
            "parameters": {
                "content": "## **Note:** - 'No-Op' nodes ensure the workflow doesn't \n## crash if you unselect a platform.",
                "height": 96,
                "width": 832
            },
            "type": "n8n-nodes-base.stickyNote",
            "position": [
                3840,
                1792
            ],
            "typeVersion": 1,
            "id": "3d237c35-a018-4f82-9308-d3dfea28d539",
            "name": "Sticky Note"
        },
        {
            "parameters": {
                "httpMethod": "POST",
                "path": "0b818756-2eea-42aa-b18b-a22f613184e5",
                "options": {}
            },
            "type": "n8n-nodes-base.webhook",
            "typeVersion": 2.1,
            "position": [
                1776,
                2272
            ],
            "id": "0854059b-94ef-4e59-99e3-f190a75b703a",
            "name": "Webhook",
            "webhookId": "0b818756-2eea-42aa-b18b-a22f613184e5"
        },
        {
            "parameters": {
                "jsCode": "// Return placeholder for skipped Dev.to draft\nreturn [{\n  json: {\n    id: null,\n    platform: 'devto',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
            },
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4528,
                2928
            ],
            "id": "b8dc1f5b-9429-4df8-9ddb-2ae2bd083380",
            "name": "Code - No-Op Dev.to Draft"
        },
        {
            "parameters": {
                "content": "## 4. Blogs BRANCH 4 -(Dev.to): Long-form SEO. Focus: Tutorials, Code snippets, Deep Dives.",
                "height": 224,
                "width": 816,
                "color": 7
            },
            "type": "n8n-nodes-base.stickyNote",
            "position": [
                3888,
                2672
            ],
            "typeVersion": 1,
            "id": "3a7ecb1e-5a4e-40ba-a2bd-7cc652c5363e",
            "name": "Sticky Note7"
        },
        {
            "parameters": {
                "method": "PATCH",
                "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
                "authentication": "predefinedCredentialType",
                "nodeCredentialType": "notionApi",
                "sendHeaders": true,
                "headerParameters": {
                    "parameters": [
                        {
                            "name": "Notion-Version",
                            "value": "2022-06-28"
                        }
                    ]
                },
                "sendBody": true,
                "specifyBody": "json",
                "jsonBody": "={{ $json.finalApiBody }}",
                "options": {}
            },
            "type": "n8n-nodes-base.httpRequest",
            "typeVersion": 4.3,
            "position": [
                4528,
                2352
            ],
            "id": "2307805e-7491-4970-a581-1bb499c9fdc6",
            "name": "Update Notion (Blog)",
            "retryOnFail": true,
            "waitBetweenTries": 2000,
            "credentials": {
                "notionApi": {
                    "id": "je8hKPK6RzYSk4JA",
                    "name": "Notion account 2"
                }
            }
        },
        {
            "parameters": {
                "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// TWITTER PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Twitter Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable thread text with --- separators\n// \n// HANDLES:\n// - Escaped newlines (\\\\n, \\\\\\\\n, etc.)\n// - Truncated AI responses (MAX_TOKENS)\n// - Thread stitching from structured_data.threads\n// - JSON wrapped in markdown fences\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    // Handle truncated JSON\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try { rawStr = JSON.stringify(input); } catch (e) { rawStr = \"\"; }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    // Priority 1: formatted_markdown\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    }\n    // Priority 2: markdown field\n    else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    }\n    // Priority 3: Stitch from structured_data.threads\n    else if (parsedJSON.structured_data?.threads) {\n        const threads = parsedJSON.structured_data.threads;\n        const mainThread = Array.isArray(threads) ? threads[0] : threads;\n\n        if (mainThread && mainThread.tweets) {\n            extractedText = mainThread.tweets\n                .map(t => {\n                    let content = t.content || \"\";\n                    if (t.image_marker && !content.includes(t.image_marker)) {\n                        content += \"\\n\\n\" + t.image_marker;\n                    }\n                    return content;\n                })\n                .join('\\n\\n---\\n\\n');\n            debugInfo.extractionMethod = \"structured_data_stitched\";\n        }\n    }\n    // Priority 4: text field\n    else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr.replace(/^```json\\s*/i, '').replace(/```$/g, '').trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet cleanText = unescapeContent(extractedText);\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove Twitter-specific headers\ncleanText = cleanText\n    .replace(/^#\\s*Twitter\\s*Draft\\s*\\n+/i, '')\n    .replace(/^Thread\\s*\\d*\\s*\\n+/i, '')\n    .replace(/^Tweet\\s*\\d+\\/\\d+\\s*\\n+/gi, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// Warn about missing thread separators\nif (cleanText.length > 280 && !cleanText.includes('---')) {\n    console.warn('âš ï¸ Twitter thread may be missing separators');\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"Twitter Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
            },
            "id": "5709afcb-f4b9-49f4-9e8d-b71ff7e076ff",
            "name": "Code â€“ Prep Twitter API",
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4304,
                1584
            ]
        },
        {
            "parameters": {
                "method": "PATCH",
                "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
                "authentication": "predefinedCredentialType",
                "nodeCredentialType": "notionApi",
                "sendHeaders": true,
                "headerParameters": {
                    "parameters": [
                        {
                            "name": "Notion-Version",
                            "value": "2022-06-28"
                        },
                        {
                            "name": "Content-Type",
                            "value": "application/json"
                        }
                    ]
                },
                "sendBody": true,
                "specifyBody": "json",
                "jsonBody": "={{ $json.finalApiBody }}",
                "options": {}
            },
            "id": "ef259ee6-b074-4370-b7ef-7fc7aa246990",
            "name": "HTTP â€“ Push Twitter Draft",
            "type": "n8n-nodes-base.httpRequest",
            "typeVersion": 4.3,
            "position": [
                4528,
                1584
            ],
            "retryOnFail": true,
            "waitBetweenTries": 2000,
            "credentials": {
                "notionApi": {
                    "id": "je8hKPK6RzYSk4JA",
                    "name": "Notion account 2"
                }
            }
        },
        {
            "parameters": {
                "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// LINKEDIN PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"LinkedIn Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable post text\n// \n// HANDLES:\n// - Multiple levels of escaped newlines (\\\\n, \\\\\\\\n, \\\\\\\\\\\\\\\\n)\n// - Truncated AI responses (MAX_TOKENS)\n// - JSON wrapped in markdown fences\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n\n    // Process from most escaped to least escaped\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try { rawStr = JSON.stringify(input); } catch (e) { rawStr = \"\"; }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.structured_data?.posts?.[0]?.content) {\n        extractedText = parsedJSON.structured_data.posts[0].content;\n        debugInfo.extractionMethod = \"structured_data_posts\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr.replace(/^```json\\s*/i, '').replace(/```$/g, '').trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet cleanText = unescapeContent(extractedText);\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove LinkedIn-specific headers\ncleanText = cleanText\n    .replace(/^#\\s*LinkedIn\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"LinkedIn Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
            },
            "id": "47465f14-d559-49f4-9295-86fbfce68616",
            "name": "Code â€“ Prep LinkedIn API",
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4304,
                1968
            ]
        },
        {
            "parameters": {
                "method": "PATCH",
                "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
                "authentication": "predefinedCredentialType",
                "nodeCredentialType": "notionApi",
                "sendHeaders": true,
                "headerParameters": {
                    "parameters": [
                        {
                            "name": "Notion-Version",
                            "value": "2022-06-28"
                        },
                        {
                            "name": "Content-Type",
                            "value": "application/json"
                        }
                    ]
                },
                "sendBody": true,
                "specifyBody": "json",
                "jsonBody": "={{ $json.finalApiBody }}",
                "options": {}
            },
            "id": "2b9d9734-2f34-4f7a-a185-df8ef199082d",
            "name": "HTTP â€“ Push LinkedIn Draft",
            "type": "n8n-nodes-base.httpRequest",
            "typeVersion": 4.3,
            "position": [
                4528,
                1968
            ],
            "retryOnFail": true,
            "waitBetweenTries": 2000,
            "credentials": {
                "notionApi": {
                    "id": "je8hKPK6RzYSk4JA",
                    "name": "Notion account 2"
                }
            }
        },
        {
            "parameters": {
                "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// DEV.TO PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Dev.to Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable article\n// \n// Note: DevTo output often comes wrapped in ```json fences - handled here\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n\n    // CRITICAL: DevTo often wraps in ```json fences\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try { rawStr = JSON.stringify(input); } catch (e) { rawStr = \"\"; }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr.replace(/^```json\\s*/i, '').replace(/```$/g, '').trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet cleanText = unescapeContent(extractedText);\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove platform headers\ncleanText = cleanText\n    .replace(/^#\\s*Dev\\.?to\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"DevTo Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
            },
            "id": "ac49d3c3-8750-427e-b53f-4850b296cf05",
            "name": "Code â€“ Prep DevTo API",
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4304,
                2736
            ]
        },
        {
            "parameters": {
                "method": "PATCH",
                "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
                "authentication": "predefinedCredentialType",
                "nodeCredentialType": "notionApi",
                "sendHeaders": true,
                "headerParameters": {
                    "parameters": [
                        {
                            "name": "Notion-Version",
                            "value": "2022-06-28"
                        },
                        {
                            "name": "Content-Type",
                            "value": "application/json"
                        }
                    ]
                },
                "sendBody": true,
                "specifyBody": "json",
                "jsonBody": "={{ $json.finalApiBody }}",
                "options": {}
            },
            "id": "5265b52a-2393-4d2a-8bb3-471d46b6600e",
            "name": "HTTP â€“ Push DevTo Draft",
            "type": "n8n-nodes-base.httpRequest",
            "typeVersion": 4.3,
            "position": [
                4528,
                2736
            ],
            "retryOnFail": true,
            "waitBetweenTries": 2000,
            "credentials": {
                "notionApi": {
                    "id": "je8hKPK6RzYSk4JA",
                    "name": "Notion account 2"
                }
            }
        },
        {
            "parameters": {
                "method": "PATCH",
                "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
                "authentication": "predefinedCredentialType",
                "nodeCredentialType": "notionApi",
                "sendHeaders": true,
                "headerParameters": {
                    "parameters": [
                        {
                            "name": "Notion-Version",
                            "value": "2022-06-28"
                        },
                        {
                            "name": "Content-Type",
                            "value": "application/json"
                        }
                    ]
                },
                "sendBody": true,
                "specifyBody": "json",
                "jsonBody": "={{ $json.finalApiBody }}",
                "options": {}
            },
            "id": "2282c5d1-56b8-4c04-b11a-add4009d3744",
            "name": "HTTP â€“ Push Hashnode Draft",
            "type": "n8n-nodes-base.httpRequest",
            "typeVersion": 4.3,
            "position": [
                4528,
                3120
            ],
            "retryOnFail": true,
            "waitBetweenTries": 2000,
            "credentials": {
                "notionApi": {
                    "id": "je8hKPK6RzYSk4JA",
                    "name": "Notion account 2"
                }
            }
        },
        {
            "parameters": {
                "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// IMAGE TASKLIST ARCHITECT (vFINAL - GOD TIER ROBUSTNESS)\n// Target: \"Image Task List\"\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// --- 1. CORE UTILITIES ---\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction semanticChunking(text, maxChars = 1900) {\n    const chunks = [];\n    let currentChunk = \"\";\n    const paragraphs = text.split('\\n\\n');\n\n    for (const paragraph of paragraphs) {\n        if ((currentChunk.length + paragraph.length + 2) <= maxChars) {\n            currentChunk += (currentChunk ? '\\n\\n' : '') + paragraph;\n        } else {\n            if (currentChunk) { chunks.push(currentChunk); currentChunk = \"\"; }\n            if (paragraph.length <= maxChars) {\n                currentChunk = paragraph;\n            } else {\n                const lines = paragraph.split('\\n');\n                for (const line of lines) {\n                    if ((currentChunk.length + line.length + 1) <= maxChars) {\n                        currentChunk += (currentChunk ? '\\n' : '') + line;\n                    } else {\n                        if (currentChunk) { chunks.push(currentChunk); currentChunk = \"\"; }\n                        if (line.length > maxChars) {\n                            let tempLine = line;\n                            while (tempLine.length > 0) {\n                                chunks.push(tempLine.substring(0, maxChars));\n                                tempLine = tempLine.substring(maxChars);\n                            }\n                        } else { currentChunk = line; }\n                    }\n                }\n            }\n        }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n    return chunks;\n}\n\n// --- 2. STRATEGY PARSING ---\n\nlet extractedText = \"\";\n\n// The previous node sends `strategy` inside input\nif (input.strategy && input.strategy.image_strategy) {\n    const strategy = input.strategy.image_strategy;\n    const prompts = strategy.specific_prompts || [];\n    const title = input.sourceContent?.title || \"Content\";\n\n    if (prompts.length > 0) {\n        let md = `# ðŸ–¼ï¸ Image Tasklist for: ${title}\\n\\n`;\n        md += `**Reason:** ${strategy.rationale || \"Enhance content\"}\\n\\n---\\n\\n`;\n\n        prompts.forEach((task, index) => {\n            const assetNum = index + 1;\n            md += `## Asset ${assetNum}: ${task.purpose || 'Visual Asset'}\\n\\n`;\n            md += `**âž¡ï¸ Action Required:**\\n`;\n            md += `- **Type:** ${task.asset_type === 'real_asset' ? 'ðŸ“¸ Real Asset (Screenshot/File)' : 'ðŸ¤– Generative AI (Midjourney/DALL-E)'}\\n`;\n            md += `- **Description:** ${task.description}\\n`;\n            md += `- **Placement:** ${task.position}\\n`;\n            md += `- **Marker:** \\`${task.marker || `<<IMAGE_${assetNum}>>`}\\`\\n\\n`;\n\n            if (task.asset_type !== 'real_asset' && task.fallback_prompt) {\n                md += `**ðŸ’¡ GenAI Prompt:**\\n> ${task.fallback_prompt}\\n\\n`;\n            }\n            md += `---\\n\\n`;\n        });\n        extractedText = md;\n    } else {\n        extractedText = \"âš ï¸ Strategy found, but 'specific_prompts' array was empty. No images required.\";\n    }\n} else {\n    // Fallback if raw text or no strategy\n    extractedText = input.text || \"âš ï¸ No Image Tasks Generated (No Strategy Object Found)\";\n}\n\n// --- 3. CLEANING & FORMATTING ---\nlet cleanText = sanitizeText(extractedText);\n\n// --- 4. SEMANTIC CHUNKING ---\nconst finalChunks = semanticChunking(cleanText, 1900);\nconst richTextArray = finalChunks.map(chunk => ({\n    type: \"text\",\n    text: { content: chunk }\n}));\n\n// --- 5. PAYLOAD GENERATION ---\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"Image Task List\": { \"rich_text\": richTextArray.slice(0, 95) }\n            }\n        }\n    }\n};"
            },
            "id": "9e4fc872-6806-45b4-8010-2c45cae12279",
            "name": "Code â€“ Prep Image Tasklist API",
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4304,
                3504
            ]
        },
        {
            "parameters": {
                "method": "PATCH",
                "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
                "authentication": "predefinedCredentialType",
                "nodeCredentialType": "notionApi",
                "sendHeaders": true,
                "headerParameters": {
                    "parameters": [
                        {
                            "name": "Notion-Version",
                            "value": "2022-06-28"
                        },
                        {
                            "name": "Content-Type",
                            "value": "application/json"
                        }
                    ]
                },
                "sendBody": true,
                "specifyBody": "json",
                "jsonBody": "={{ $json.finalApiBody }}",
                "options": {}
            },
            "id": "bcb9eda9-868f-457b-8df8-323a1a4a552b",
            "name": "HTTP â€“ Push Image Tasklist",
            "type": "n8n-nodes-base.httpRequest",
            "typeVersion": 4.3,
            "position": [
                4528,
                3504
            ],
            "retryOnFail": true,
            "waitBetweenTries": 2000,
            "credentials": {
                "notionApi": {
                    "id": "je8hKPK6RzYSk4JA",
                    "name": "Notion account 2"
                }
            }
        },
        {
            "parameters": {
                "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// HASHNODE PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Hashnode Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable article\n// \n// HANDLES:\n// - Escaped newlines (\\\\n, \\\\\\\\n, etc.)\n// - Mermaid diagrams with code blocks\n// - Truncated AI responses (MAX_TOKENS)\n// - JSON wrapped in markdown fences\n// - Very long content (proper Notion chunking)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\n/**\n * CRITICAL: Properly unescape newlines from JSON strings\n * Must handle multiple levels of escaping AND preserve code blocks\n */\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n\n    // Handle quadruple escaping first (\\\\\\\\n -> \\\\n)\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle triple escaping\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle double escaping (\\\\n -> newline) - most common in JSON\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n\n    // Handle single escaping\n    result = result.replace(/\\\\n/g, '\\n');\n\n    // Handle other escape sequences\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n\n    // Clean up remaining double backslashes (but preserve single backslashes for code)\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    // Try direct parse\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    // Find the outermost JSON object\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    // Handle truncated JSON - extract formatted_markdown via regex\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true,\n            _warning: \"JSON was truncated, extracted markdown via regex\"\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n\n        // Prefer breaking at paragraph boundaries\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try {\n        rawStr = JSON.stringify(input);\n    } catch (e) {\n        rawStr = \"\";\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON._recovered) {\n        debugInfo.recovered = true;\n        debugInfo.warning = parsedJSON._warning;\n    }\n\n    // Priority extraction\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    // Regex fallback\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr\n                .replace(/^```json\\s*/i, '')\n                .replace(/```$/g, '')\n                .trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n// Unescape all escape sequences\nlet cleanText = unescapeContent(extractedText);\n\n// Sanitize\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove platform headers\ncleanText = cleanText\n    .replace(/^#\\s*Hashnode\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"Hashnode Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
            },
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4304,
                3120
            ],
            "id": "2fb333b8-063b-4ef6-b408-942c1d051d40",
            "name": "Code - Prep Hashnode API"
        },
        {
            "parameters": {
                "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SANITY BLOG PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Sanity Blog Draft\" + SEO Metadata\n// Input: Gemini AI Output JSON with formatted_markdown + structured_data.seo\n// Output: Clean markdown + SEO fields\n// \n// HANDLES:\n// - Escaped newlines (\\\\n, \\\\\\\\n, etc.)\n// - Truncated AI responses (MAX_TOKENS)\n// - JSON wrapped in markdown fences\n// - Very long content (proper Notion chunking)\n// - Malformed JSON recovery\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n/**\n * Sanitizes text by removing zero-width characters and normalizing linebreaks\n */\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\n/**\n * CRITICAL: Properly unescape newlines from JSON strings\n * AI returns content like: \"Line 1\\\\n\\\\nLine 2\" which needs to become actual newlines\n * Must handle multiple levels of escaping\n */\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n\n    // Handle quadruple escaping first (\\\\\\\\n -> \\\\n)\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle triple escaping (rare but possible)\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle double escaping (\\\\n -> newline) - most common in JSON\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n\n    // Handle single escaping (\\n -> newline) - already actual newlines in most cases\n    // But if still escaped as literal backslash-n, convert\n    result = result.replace(/\\\\n/g, '\\n');\n\n    // Handle other escape sequences\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n\n    // Clean up any remaining double backslashes\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\n/**\n * Robust JSON parser that handles:\n * - Markdown code fences (```json ... ```)\n * - Embedded JSON strings\n * - Malformed JSON with recovery\n * - Truncated JSON (MAX_TOKENS)\n */\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr; // Already parsed\n\n    // Step 1: Clean the input string - remove markdown fences\n    let cleanStr = rawStr.trim();\n\n    // Remove leading ```json or ``` fences\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    // Remove trailing ``` fences\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    // Step 2: Try direct parse\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) {\n        // Continue to recovery\n    }\n\n    // Step 3: Find the outermost JSON object\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) {\n            // Continue to more aggressive recovery\n        }\n    }\n\n    // Step 4: Handle truncated JSON (common with MAX_TOKENS)\n    // Try to extract formatted_markdown even from broken JSON\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        // Also try to extract SEO data via regex since JSON is truncated\n        const seoData = {};\n\n        // Extract SEO title\n        const titleMatch = cleanStr.match(/\"title\"\\s*:\\s*\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\"/);\n        if (titleMatch) seoData.title = titleMatch[1].replace(/\\\\\"/g, '\"');\n\n        // Extract SEO slug\n        const slugMatch = cleanStr.match(/\"slug\"\\s*:\\s*\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\"/);\n        if (slugMatch) seoData.slug = slugMatch[1];\n\n        // Extract SEO meta_description\n        const descMatch = cleanStr.match(/\"meta_description\"\\s*:\\s*\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\"/);\n        if (descMatch) seoData.meta_description = descMatch[1].replace(/\\\\\"/g, '\"');\n\n        // Extract tags array - look for the pattern [\"tag1\", \"tag2\", ...]\n        const tagsMatch = cleanStr.match(/\"tags\"\\s*:\\s*\\[([\\s\\S]*?)\\]/);\n        if (tagsMatch) {\n            // Parse individual tags from the array\n            const tagStrings = tagsMatch[1].match(/\"([^\"]+)\"/g);\n            if (tagStrings) {\n                seoData.tags = tagStrings.map(t => t.replace(/\"/g, ''));\n            }\n        }\n\n        // Return a synthetic object with markdown AND recovered SEO data\n        return {\n            formatted_markdown: markdownMatch[1],\n            structured_data: Object.keys(seoData).length > 0 ? { seo: seoData } : undefined,\n            _recovered: true,\n            _warning: \"JSON was truncated, extracted markdown and SEO via regex\"\n        };\n    }\n\n    return null;\n}\n\n/**\n * CRITICAL: Proper chunking for Notion API\n * - Each rich_text element can be max 2000 chars\n * - Max 100 elements in a rich_text array\n * - We use 1900 to leave buffer for unicode expansion\n */\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        // Find a good break point - prefer paragraph breaks, then line breaks, then spaces\n        let breakPoint = maxCharsPerChunk;\n\n        // Look for paragraph break (\\n\\n) within last 200 chars of chunk\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2; // Include the newlines\n        } else {\n            // Look for line break\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                // Look for space\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    // Convert to Notion rich_text format, limiting to 95 chunks (Notion allows 100)\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION - Get raw text from Gemini response\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\n// Priority order for extraction from Gemini response\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    // Standard Gemini API format\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    // Try to stringify if it's an object we can't parse\n    try {\n        rawStr = JSON.stringify(input);\n    } catch (e) {\n        rawStr = \"\";\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING - Extract formatted_markdown from JSON\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet seoData = {};\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseAttempted: false,\n    parseSuccess: false,\n    recoveryUsed: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\ndebugInfo.parseAttempted = true;\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON._recovered) {\n        debugInfo.recoveryUsed = true;\n        debugInfo.warning = parsedJSON._warning;\n    }\n\n    // Extract formatted markdown - check multiple possible locations\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n    // Extract SEO metadata\n    if (parsedJSON.structured_data?.seo) {\n        seoData = parsedJSON.structured_data.seo;\n    } else if (parsedJSON.seo) {\n        seoData = parsedJSON.seo;\n    }\n\n} else {\n    // JSON parsing failed completely - try direct regex extraction\n    debugInfo.parseSuccess = false;\n    debugInfo.extractionMethod = \"regex_fallback\";\n\n    // Try to extract formatted_markdown via regex\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n    } else {\n        // Last resort: try extracting content from markdown fence\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            // Absolute last resort: clean the raw string\n            extractedText = rawStr\n                .replace(/^```json\\s*/i, '')\n                .replace(/```$/g, '')\n                .replace(/^Here is the.*?:\\s*/i, '')\n                .replace(/^Sure.*?:\\s*/i, '')\n                .trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING - Make it human-readable\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n// Step 1: Unescape all newlines and other escape sequences\nlet cleanText = unescapeContent(extractedText);\n\n// Step 2: Sanitize (remove zero-width chars, normalize unicode)\ncleanText = sanitizeText(cleanText).trim();\n\n// Step 3: Remove AI-generated platform headers\ncleanText = cleanText\n    .replace(/^#\\s*Blog\\s*Draft\\s*\\n+/i, '')\n    .replace(/^#\\s*Sanity\\s*Blog\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Step 4: Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. SEO METADATA PROCESSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst seoTitle = seoData.title || \"\";\nconst seoSlug = seoData.slug || \"\";\nconst seoDescription = seoData.meta_description || seoData.description || \"\";\nconst seoKeywords = Array.isArray(seoData.keywords)\n    ? seoData.keywords.join(\", \")\n    : (seoData.keywords || \"\");\n\n// Handle tags - can be array or string\nconst seoTagsArray = Array.isArray(seoData.tags)\n    ? seoData.tags\n    : (typeof seoData.tags === 'string' ? seoData.tags.split(',').map(t => t.trim()) : []);\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 6. OUTPUT - Build Notion API Payload\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\n// Build properties object\nconst properties = {\n    \"Sanity Blog Draft\": { \"rich_text\": richTextArray }\n};\n\n// Add SHARED SEO fields for all platforms (matching Notion property names)\nif (seoTitle) {\n    properties[\"Shared_SEO_Title\"] = {\n        \"rich_text\": [{ type: \"text\", text: { content: seoTitle.substring(0, 2000) } }]\n    };\n}\nif (seoSlug) {\n    properties[\"Shared_Slug\"] = {\n        \"rich_text\": [{ type: \"text\", text: { content: seoSlug.substring(0, 2000) } }]\n    };\n}\nif (seoDescription) {\n    properties[\"Shared_SEO_Description\"] = {\n        \"rich_text\": [{ type: \"text\", text: { content: seoDescription.substring(0, 2000) } }]\n    };\n}\n// Shared_Tags is a MULTI-SELECT property in Notion, not Text!\nif (seoTagsArray.length > 0) {\n    properties[\"Shared_Tags\"] = {\n        \"multi_select\": seoTagsArray.map(tag => ({ name: tag.trim() }))\n    };\n}\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: properties\n        },\n        // Debug info for troubleshooting (can be removed in production)\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length,\n            hasSeoData: Object.keys(seoData).length > 0,\n            seoDataExtracted: {\n                title: seoTitle ? seoTitle.substring(0, 50) + \"...\" : null,\n                slug: seoSlug || null,\n                description: seoDescription ? seoDescription.substring(0, 50) + \"...\" : null,\n                tagsCount: seoTagsArray.length\n            }\n        }\n    }\n};"
            },
            "id": "7cbb5406-364c-41b6-868d-f3d0e983eb7c",
            "name": "Code â€“ Prep Sanity Blog API",
            "type": "n8n-nodes-base.code",
            "typeVersion": 2,
            "position": [
                4304,
                2352
            ]
        },
        {
            "parameters": {
                "resource": "databasePage",
                "operation": "update",
                "pageId": {
                    "__rl": true,
                    "value": "={{ $('Notion â€“ Get Ready Content').first().json.id }}",
                    "mode": "id"
                },
                "propertiesUi": {
                    "propertyValues": [
                        {
                            "key": "Status|select",
                            "type": "select",
                            "selectValue": "Pending Approval"
                        },
                        {
                            "key": "hasImages / Assets|checkbox",
                            "checkboxValue": "={{ $('Process AI Strategy & MERGE CONTEXT').first().json.strategy?.image_strategy?.needs_images === true }}"
                        },
                        {
                            "key": "Processing Started|date",
                            "type": "date",
                            "date": "={{ new Date().toISOString() }}"
                        },
                        {
                            "key": "Notes|rich_text",
                            "textContent": "={{ (() => {\n  const data = $json.properties || $json;\n  const sessionId = data.SessionID?.rich_text?.[0]?.text?.content || 'N/A';\n  const timestamp = new Date().toLocaleString('en-IN', { \n    timeZone: 'Asia/Kolkata',\n    day: '2-digit',\n    month: '2-digit', \n    year: 'numeric',\n    hour: '2-digit',\n    minute: '2-digit'\n  });\n\n  const twitterDraft = data[\"Twitter Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const linkedinDraft = data[\"LinkedIn Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const sanityDraft = data[\"Sanity Blog Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const devtoDraft = data[\"DevTo Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const hashnodeDraft = data[\"Hashnode Draft\"]?.rich_text?.[0]?.text?.content || '';\n\n  const postTo = data[\"Post To\"]?.multi_select || [];\n  const postToNames = postTo.map(p => p.name);\n\n  let contentStatus = [];\n  if (twitterDraft.length > 10) contentStatus.push('  âœ… Twitter (X) - Draft generated');\n  if (linkedinDraft.length > 10) contentStatus.push('  âœ… LinkedIn - Draft generated');\n  if (sanityDraft.length > 10) contentStatus.push('  âœ… Sanity Blog - Draft generated');\n  if (devtoDraft.length > 10) contentStatus.push('  âœ… Dev.to - Draft generated');\n  if (hashnodeDraft.length > 10) contentStatus.push('  âœ… Hashnode - Draft generated');\n\n  const hasImages = data[\"hasImages / Assets\"]?.checkbox || false;\n  const status = data[\"Status\"]?.select?.name || 'Pending Approval';\n\n  return `âœ… CONTENT GENERATION COMPLETE\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\\n\\nðŸ“ Session: ${sessionId}\\nðŸ“… Generated: ${timestamp}\\n\\nðŸ“¢ PLATFORMS GENERATED:\\n${contentStatus.length > 0 ? contentStatus.join('\\n') : '  âš ï¸ No content generated yet'}\\n\\nðŸ“Š CONTENT STATS:\\n  - Has Images: ${hasImages ? 'Yes âœ“' : 'No âœ—'}\\n  - Total Platforms: ${contentStatus.length}/${postToNames.length}\\n  - Target Platforms: ${postToNames.join(', ')}\\n\\nðŸ”§ STATUS: ${status}\\nðŸ’¡ Next Step: Review drafts â†’ Approve â†’ Part 2 will post`;\n})() }}"
                        }
                    ]
                },
                "options": {}
            },
            "id": "a430b7df-c70a-4356-8fdf-2b0d37f4a612",
            "name": "Notion â€“ Update Final Status",
            "type": "n8n-nodes-base.notion",
            "typeVersion": 2,
            "position": [
                4976,
                2544
            ],
            "retryOnFail": true,
            "maxTries": 3,
            "waitBetweenTries": 2000,
            "credentials": {
                "notionApi": {
                    "id": "je8hKPK6RzYSk4JA",
                    "name": "Notion account 2"
                }
            }
        }
    ],
    "connections": {
        "When clicking 'Execute workflow'": {
            "main": [
                [
                    {
                        "node": "Notion â€“ Get Ready Content",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Notion â€“ Get Ready Content": {
            "main": [
                [
                    {
                        "node": "Filter â€“ Has Content",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Filter â€“ Has Content": {
            "main": [
                [
                    {
                        "node": "Code â€“ Select Content & Profile",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Code â€“ Select Content & Profile": {
            "main": [
                [
                    {
                        "node": "Create folder for title",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Notion â€“ Update to Processing": {
            "main": [
                [
                    {
                        "node": "Notion â€“ Extract All Blocks",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Notion â€“ Extract All Blocks": {
            "main": [
                [
                    {
                        "node": "Code â€“ Extract & Process Content",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Code â€“ Extract & Process Content": {
            "main": [
                [
                    {
                        "node": "Context - Fetch Portfolio",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Merge2": {
            "main": [
                [
                    {
                        "node": "Notion â€“ Update Final Status",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Code â€“ Personal Context Builder": {
            "main": [
                [
                    {
                        "node": "Perplexity â€“ Research Hashtags & Timing",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Code â€“ CONTEXT MERGER": {
            "main": [
                [
                    {
                        "node": "Gemini - AI CONTENT STRATEGIST",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Create folder for title": {
            "main": [
                [
                    {
                        "node": "Notion â€“ Update to Processing",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Perplexity â€“ Research Hashtags & Timing": {
            "main": [
                [
                    {
                        "node": "Code â€“ CONTEXT MERGER",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Process AI Strategy & MERGE CONTEXT": {
            "main": [
                [
                    {
                        "node": "Are Images Needed?",
                        "type": "main",
                        "index": 0
                    },
                    {
                        "node": "IF - Twitter Selected?",
                        "type": "main",
                        "index": 0
                    },
                    {
                        "node": "IF - LinkedIn Selected?",
                        "type": "main",
                        "index": 0
                    },
                    {
                        "node": "IF - Blog Selected?",
                        "type": "main",
                        "index": 0
                    },
                    {
                        "node": "IF - Dev.to Selected?",
                        "type": "main",
                        "index": 0
                    },
                    {
                        "node": "IF - Hashnode Selected?",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Are Images Needed?": {
            "main": [
                [
                    {
                        "node": "Code â€“ Prep Image Tasklist API",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "IF - Twitter Selected?": {
            "main": [
                [
                    {
                        "node": "Gemini - Twitter Content Generation",
                        "type": "main",
                        "index": 0
                    }
                ],
                [
                    {
                        "node": "Code - No-Op Twitter Draft",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "IF - LinkedIn Selected?": {
            "main": [
                [
                    {
                        "node": "Gemini - LinkedIn Content Generation",
                        "type": "main",
                        "index": 0
                    }
                ],
                [
                    {
                        "node": "Code - No-Op LinkedIn Draft",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "IF - Blog Selected?": {
            "main": [
                [
                    {
                        "node": "Blog Content Generation",
                        "type": "main",
                        "index": 0
                    }
                ],
                [
                    {
                        "node": "Code - No-Op Blog Draft",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Code - No-Op Twitter Draft": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Code - No-Op LinkedIn Draft": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 1
                    }
                ]
            ]
        },
        "Code - No-Op Blog Draft": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 2
                    }
                ]
            ]
        },
        "Gemini - AI CONTENT STRATEGIST": {
            "main": [
                [
                    {
                        "node": "Process AI Strategy & MERGE CONTEXT",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Gemini - Twitter Content Generation": {
            "main": [
                [
                    {
                        "node": "Code â€“ Prep Twitter API",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Gemini - LinkedIn Content Generation": {
            "main": [
                [
                    {
                        "node": "Code â€“ Prep LinkedIn API",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Blog Content Generation": {
            "main": [
                [
                    {
                        "node": "Code â€“ Prep Sanity Blog API",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Context - Fetch Portfolio": {
            "main": [
                [
                    {
                        "node": "Context - Standardize & Filter",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Context - Standardize & Filter": {
            "main": [
                [
                    {
                        "node": "Code â€“ Personal Context Builder",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "IF - Dev.to Selected?": {
            "main": [
                [
                    {
                        "node": "Gemini - Dev.to Content Generation",
                        "type": "main",
                        "index": 0
                    }
                ],
                [
                    {
                        "node": "Code - No-Op Dev.to Draft",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "IF - Hashnode Selected?": {
            "main": [
                [
                    {
                        "node": "Gemini - Hashnode Content Generation",
                        "type": "main",
                        "index": 0
                    }
                ],
                [
                    {
                        "node": "Code - No-Op Hashnode Draft",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Gemini - Dev.to Content Generation": {
            "main": [
                [
                    {
                        "node": "Code â€“ Prep DevTo API",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Gemini - Hashnode Content Generation": {
            "main": [
                [
                    {
                        "node": "Code - Prep Hashnode API",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Code - No-Op Hashnode Draft": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 4
                    }
                ]
            ]
        },
        "Webhook": {
            "main": [
                [
                    {
                        "node": "Notion â€“ Get Ready Content",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Code - No-Op Dev.to Draft": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 3
                    }
                ]
            ]
        },
        "Update Notion (Blog)": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 2
                    }
                ]
            ]
        },
        "Code â€“ Prep Twitter API": {
            "main": [
                [
                    {
                        "node": "HTTP â€“ Push Twitter Draft",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "HTTP â€“ Push Twitter Draft": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Code â€“ Prep LinkedIn API": {
            "main": [
                [
                    {
                        "node": "HTTP â€“ Push LinkedIn Draft",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "HTTP â€“ Push LinkedIn Draft": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 1
                    }
                ]
            ]
        },
        "Code â€“ Prep DevTo API": {
            "main": [
                [
                    {
                        "node": "HTTP â€“ Push DevTo Draft",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "HTTP â€“ Push DevTo Draft": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 3
                    }
                ]
            ]
        },
        "HTTP â€“ Push Hashnode Draft": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 4
                    }
                ]
            ]
        },
        "Code â€“ Prep Image Tasklist API": {
            "main": [
                [
                    {
                        "node": "HTTP â€“ Push Image Tasklist",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "HTTP â€“ Push Image Tasklist": {
            "main": [
                [
                    {
                        "node": "Merge2",
                        "type": "main",
                        "index": 5
                    }
                ]
            ]
        },
        "Code - Prep Hashnode API": {
            "main": [
                [
                    {
                        "node": "HTTP â€“ Push Hashnode Draft",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        },
        "Code â€“ Prep Sanity Blog API": {
            "main": [
                [
                    {
                        "node": "Update Notion (Blog)",
                        "type": "main",
                        "index": 0
                    }
                ]
            ]
        }
    },
    "pinData": {},
    "meta": {
        "instanceId": "2aff0c99a9b9ea9c976d68c5887d32445a6bdc6f59f99592eb5b4c4dbaf3d92e"
    }
}