{
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        1776,
        2400
      ],
      "id": "57b96b2a-02d9-4bd0-a8fb-fc493d9cd8b2",
      "name": "When clicking 'Execute workflow'"
    },
    {
      "parameters": {
        "resource": "databasePage",
        "operation": "getAll",
        "databaseId": {
          "__rl": true,
          "value": "21a34bf1-f7e5-8035-b16f-d5ebf63a86a9",
          "mode": "list"
        },
        "returnAll": true,
        "filterType": "manual",
        "filters": {
          "conditions": [
            {
              "key": "Status|select",
              "condition": "equals",
              "selectValue": "Ready to Generate"
            }
          ]
        },
        "options": {
          "sort": {
            "sortValue": [
              {
                "key": "ManualOrder|number",
                "direction": "ascending"
              },
              {
                "key": "Priority|select",
                "direction": "ascending"
              },
              {
                "timestamp": true,
                "key": "created_time",
                "direction": "ascending"
              }
            ]
          }
        }
      },
      "id": "ac78d29e-6134-4cf8-8ff3-bdc57d5baeb2",
      "name": "Notion â€“ Get Ready Content",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2,
      "position": [
        2000,
        2352
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "leftValue": "={{ $input.all().length > 0 }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              },
              "id": "6855ced2-6ef0-4ea1-acd1-a9326c4b67f9"
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "1a58c3cf-7f2d-4cc8-a888-427b634cf439",
      "name": "Filter â€“ Has Content",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        2224,
        2352
      ]
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\r\n// CONTENT SELECTION & PROFILE SETUP (V2 - Updated Feb 2026)\r\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\r\nconst items = $input.all();\r\n\r\nif (!items || items.length === 0) {\r\n    console.log('âŒ No content ready for processing');\r\n    return [];\r\n}\r\n\r\n// Get first item (priority + FIFO)\r\nconst item = items[0].json;\r\nconsole.log('ðŸŽ¯ Processing item:', item.id);\r\n\r\n// Enhanced property extraction with fallbacks\r\nconst getProperty = (obj, path, defaultValue = '') => {\r\n    const keys = path.split('.');\r\n    let result = obj;\r\n    for (const key of keys) {\r\n        if (result && typeof result === 'object' && key in result) {\r\n            result = result[key];\r\n        } else {\r\n            return defaultValue;\r\n        }\r\n    }\r\n    return result || defaultValue;\r\n};\r\n\r\nconst title = getProperty(item, 'properties.Content Pages.title.0.plain_text') ||\r\n    getProperty(item, 'properties.title.title.0.plain_text') ||\r\n    getProperty(item, 'properties.Name.title.0.plain_text') ||\r\n    getProperty(item, 'name') ||\r\n    'Untitled Content';\r\n\r\nconst category = getProperty(item, 'properties.Category.select.name') ||\r\n    'Learning';\r\n\r\nconst priority = getProperty(item, 'properties.Priority.select.name') ||\r\n    'normal';\r\n\r\n// â”€â”€ User Profile (Single Source of Truth) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\r\n// Keep in sync with GEMINI.md and prompt <role> sections\r\nconst userProfile = {\r\n    name: 'Aman Suryavanshi',\r\n    role: 'AI Solutions Architect | Full-Stack Agentic Developer',\r\n    focus: 'Building intelligent multi-agent systems AND the frontend interfaces that let non-technical people control them',\r\n    personality: 'High-agency, authentic, builder-mindset, detail-oriented',\r\n    expertise: [\r\n        'Next.js', 'React', 'TypeScript',\r\n        'n8n Automation', 'LangGraph', 'Agentic AI',\r\n        'SEO/AEO/GEO', 'Full-Stack Development'\r\n    ],\r\n    audience: 'Tech community, hiring managers, AI enthusiasts, developers, startup founders',\r\n    timezone: 'Asia/Kolkata',\r\n    location: 'Delhi/NCR, India',\r\n    writing_style: {\r\n        twitter: 'Punchy, confident, thread-friendly, opinionated, no fluff',\r\n        linkedin: 'Professional, story-driven, results-oriented, high-agency voice',\r\n        blog: 'Authoritative, technically deep, reference-quality, SEO-optimized'\r\n    },\r\n    content_goals: {\r\n        primary: 'Build authority that attracts job offers (target: 15-25L) and freelance clients',\r\n        secondary: 'Establish thought leadership in agentic AI and automation space',\r\n        engagement: 'Generate inbound opportunities through demonstrated expertise'\r\n    },\r\n    brand_position: 'I build intelligent multi-agent systems AND the frontend interfaces that let non-technical people control them'\r\n};\r\n\r\nconst sessionId = `session_${Date.now()}_${(item.id || '').toString().substring(0, 8)}`;\r\n\r\nreturn [{\r\n    json: {\r\n        id: item.id,\r\n        title: title,\r\n        category: category,\r\n        priority: priority,\r\n        sessionId: sessionId,\r\n        userProfile: userProfile,\r\n        processingStartTime: new Date().toISOString(),\r\n        remainingItems: items.length - 1,\r\n        originalId: item.id\r\n    }\r\n}];"
      },
      "id": "b52c9b71-f0b5-4aa2-8d61-a3d8eb5b50bf",
      "name": "Code â€“ Select Content & Profile",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2448,
        2352
      ]
    },
    {
      "parameters": {
        "resource": "databasePage",
        "operation": "update",
        "pageId": {
          "__rl": true,
          "value": "={{ $('Code â€“ Select Content & Profile').item.json.id }}",
          "mode": "id"
        },
        "propertiesUi": {
          "propertyValues": [
            {
              "key": "Status|select",
              "type": "select",
              "selectValue": "Generating"
            },
            {
              "key": "SessionID|rich_text",
              "richText": true,
              "text": {
                "text": [
                  {
                    "text": "={{ $('Code â€“ Select Content & Profile').item.json.sessionId }}",
                    "annotationUi": {}
                  }
                ]
              }
            },
            {
              "key": "Processing Started|date",
              "type": "date",
              "date": "={{ $('Code â€“ Select Content & Profile').item.json.processingStartTime }}"
            },
            {
              "key": "Notes|rich_text",
              "richText": true,
              "text": {
                "text": [
                  {
                    "text": "=ðŸ”„ Processing started\\nSession: {{ $('Code â€“ Select Content & Profile').item.json.sessionId }}\\nPriority: {{ $('Code â€“ Select Content & Profile').item.json.priority }}\\nCategory: {{ $('Code â€“ Select Content & Profile').item.json.category }}\\nStarted: {{ new Date().toLocaleString('en-IN', {timeZone: 'Asia/Kolkata'}) }} IST",
                    "annotationUi": {}
                  }
                ]
              }
            }
          ]
        },
        "options": {}
      },
      "id": "0a7e4f9d-d0e1-4f4d-a4e1-fa85fb6ff7be",
      "name": "Notion â€“ Update to Processing",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2,
      "position": [
        2896,
        2352
      ],
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "resource": "block",
        "operation": "getAll",
        "blockId": {
          "__rl": true,
          "value": "={{ $json.id }}",
          "mode": "id"
        },
        "returnAll": true,
        "fetchNestedBlocks": true,
        "simplifyOutput": false
      },
      "id": "f681036d-756a-4506-af73-d94cb4fdd884",
      "name": "Notion â€“ Extract All Blocks",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        3120,
        2352
      ],
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// PRODUCTION-READY NOTION CONTENT EXTRACTION (V2 - FIXED OUTPUT)\n\ntry {\n  console.log('ðŸ” Starting comprehensive content extraction...');\n  \n  const extractItems = $items('Notion â€“ Extract All Blocks');\n  if (!extractItems?.length) {\n    throw new Error('No blocks from Notion â€“ Extract All Blocks');\n  }\n  console.log(`ðŸ“¥ Processing ${extractItems.length} block items`);\n  \n  const allBlocks = extractItems.map(item => item.json);\n  const blockMap = new Map();\n  const topLevelBlocks = [];\n  \n  // Build hierarchical tree\n  allBlocks.forEach(block => {\n    blockMap.set(block.id, { ...block, children: [] });\n  });\n  \n  allBlocks.forEach(block => {\n    if (block.parent?.type === 'page_id') {\n      topLevelBlocks.push(blockMap.get(block.id));\n    } else if (block.parent?.type === 'block_id') {\n      const parent = blockMap.get(block.parent.block_id);\n      if (parent) {\n        parent.children.push(blockMap.get(block.id));\n      }\n    }\n  });\n  \n  console.log(`ðŸŒ³ Built tree with ${topLevelBlocks.length} top-level blocks`);\n  \n  // Text extraction helper\n  const extractText = (richTextArray) => {\n    if (!Array.isArray(richTextArray)) return '';\n    return richTextArray\n      .map(item => item.plain_text || item.text?.content || '')\n      .join('')\n      .trim();\n  };\n  \n  // Image processing helper\n  const processImage = (url, caption = '') => {\n    if (!url) return null;\n    try {\n      return {\n        url: url,\n        caption: caption,\n        alt_text: caption || 'Content image',\n        processing_needed: true\n      };\n    } catch {\n      return null;\n    }\n  };\n  \n  // Recursive block renderer\n  function renderBlock(block, level = 0) {\n    if (!block?.type) return { text: '', sections: [], images: [] };\n    \n    const indent = '  '.repeat(level);\n    const blockData = block[block.type] || {};\n    let content = '';\n    let sections = [];\n    let images = [];\n    let text = extractText(blockData?.rich_text || blockData?.text || []);\n    \n    switch (block.type) {\n      case 'heading_1':\n        content = `\\\\n# ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 1, title: text, content: '', id: block.id });\n        break;\n      case 'heading_2':\n        content = `\\\\n## ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 2, title: text, content: '', id: block.id });\n        break;\n      case 'heading_3':\n        content = `\\\\n### ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 3, title: text, content: '', id: block.id });\n        break;\n      case 'paragraph':\n        if (text) content = `${text}\\\\n\\\\n`;\n        break;\n      case 'bulleted_list_item':\n        if (text) content = `${indent}- ${text}\\\\n`;\n        break;\n      case 'numbered_list_item':\n        if (text) content = `${indent}1. ${text}\\\\n`;\n        break;\n      case 'toggle':\n        if (text) {\n          content = `\\\\nâ–¶ï¸ ${text}\\\\n`;\n          sections.push({ level: 4, title: text, content: '', id: block.id, type: 'toggle' });\n        }\n        break;\n      case 'callout':\n        const icon = blockData?.icon?.emoji || 'ðŸ’¡';\n        if (text) content = `\\\\n${icon} **${text}**\\\\n\\\\n`;\n        break;\n      case 'quote':\n        if (text) content = `\\\\n> ${text}\\\\n\\\\n`;\n        break;\n      case 'code':\n        const language = blockData?.language || 'text';\n        if (text) {\n          content = `\\\\n\\`\\`\\`${language}\\\\n${text}\\\\n\\`\\`\\`\\\\n\\\\n`;\n          sections.push({ level: 5, title: `Code: ${language}`, content: text, id: block.id, type: 'code' });\n        }\n        break;\n      case 'divider':\n        content = '\\\\n---\\\\n\\\\n';\n        break;\n      case 'image':\n        const imageUrl = blockData?.file?.url || blockData?.external?.url;\n        if (imageUrl) {\n          const processedImage = processImage(imageUrl, text);\n          if (processedImage) {\n            images.push(processedImage);\n            content = `\\\\n[ðŸ“¸ Image: ${text || 'Visual content'}]\\\\n\\\\n`;\n          }\n        }\n        break;\n      case 'video':\n        content = `\\\\n[ðŸŽ¥ Video: ${text || 'Video content'}]\\\\n\\\\n`;\n        break;\n      case 'bookmark':\n        const bookmarkUrl = blockData?.url || '';\n        if (bookmarkUrl) content = `\\\\n[ðŸ”— ${text || bookmarkUrl}](${bookmarkUrl})\\\\n\\\\n`;\n        break;\n      default:\n        if (text) content = `${indent}${text}\\\\n\\\\n`;\n        break;\n    }\n    \n    // Process children recursively\n    if (block.children?.length) {\n      const childrenResult = block.children\n        .map(child => renderBlock(child, level + 1))\n        .reduce((acc, result) => {\n          acc.text += result.text;\n          acc.sections = acc.sections.concat(result.sections);\n          acc.images = acc.images.concat(result.images);\n          return acc;\n        }, { text: '', sections: [], images: [] });\n      \n      content += childrenResult.text;\n      sections = sections.concat(childrenResult.sections);\n      images = images.concat(childrenResult.images);\n    }\n    \n    return { text: content, sections: sections, images: images };\n  }\n  \n  // Process all blocks\n  const result = topLevelBlocks\n    .map(block => renderBlock(block))\n    .reduce((acc, blockResult) => {\n      acc.text += blockResult.text;\n      acc.sections = acc.sections.concat(blockResult.sections);\n      acc.images = acc.images.concat(blockResult.images);\n      return acc;\n    }, { text: '', sections: [], images: [] });\n  \n  // Clean up text\n  let fullText = result.text\n    .replace(/\\n{3,}/g, '\\n\\n')\n    .replace(/\\s+$/gm, '')\n    .trim();\n  \n  const stats = {\n    totalBlocks: allBlocks.length,\n    processedBlocks: topLevelBlocks.length,\n    characterCount: fullText.length,\n    wordCount: fullText.split(/\\s+/).filter(w => w.length > 0).length,\n    sections: result.sections.length,\n    images: result.images.length,\n    toggleSections: result.sections.filter(s => s.type === 'toggle').length,\n    codeSections: result.sections.filter(s => s.type === 'code').length\n  };\n  \n  console.log('âœ… Content extraction complete:', stats);\n  \n  // â­ KEY FIX: Wrap everything in 'sourceContent'\n  return [{\n    json: {\n      sourceContent: {\n        name: $('Notion â€“ Update to Processing').first().json.name,\n        categories: $('Notion â€“ Update to Processing').first().json.property_category,\n        fullText: fullText,\n        sections: result.sections,\n        images: result.images,\n        extractionStats: stats,\n        contentMetadata: {\n          totalSections: result.sections.length,\n          hasImages: result.images.length > 0,\n          hasCode: result.sections.some(s => s.type === 'code'),\n          hasToggles: result.sections.some(s => s.type === 'toggle'),\n          hasLists: fullText.includes('- ') || /^\\d+\\.\\s/m.test(fullText),\n          complexity: stats.wordCount > 800 ? 'high' : stats.wordCount > 400 ? 'medium' : 'low'\n        }\n      }\n    }\n  }];\n  \n} catch (error) {\n  console.error('âŒ Content extraction failed:', error.message);\n  return [{\n    json: {\n      sourceContent: {\n        fullText: `Content extraction error: ${error.message}`,\n        sections: [],\n        images: [],\n        extractionStats: { error: true },\n        contentMetadata: { error: error.message }\n      }\n    }\n  }];\n}\n"
      },
      "id": "cfc2ddab-2cbc-4871-9c03-5861082459da",
      "name": "Code â€“ Extract & Process Content",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3344,
        2352
      ]
    },
    {
      "parameters": {
        "numberInputs": 6
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        4752,
        2480
      ],
      "id": "8741abe3-69fa-435d-b53f-fbfa9389d9c4",
      "name": "Merge2"
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// CONTEXT ADAPTER v3 (Production-Ready)\n// Purpose: Merge Portfolio API data + Notion Content + Strategic Context\n// \n// Architecture:\n//   Portfolio API â†’ Facts & Proof (skills, projects, metrics)\n//   personalContext â†’ Strategy & Voice (goals, hooks, forbidden phrases)\n//   Notion Content â†’ Raw source material for repurposing\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst contentNode = $('Code â€“ Extract & Process Content').first().json;\nconst contextRaw = $('Context - Standardize & Filter').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 1: STATIC STRATEGIC CONTEXT (Never from API - Your \"ContentDNA\")\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nconst strategicContext = {\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.1 POSITIONING & CAREER STRATEGY\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  positioning: {\n    headline: \"Full-Stack Agentic Developer | AI Automation Engineer + Next.js Developer\",\n    experienceLevel: \"Early Career (0-2 years) | Senior-level output in n8n, SEO/GEO, workflow automation\",\n    location: \"Delhi/NCR + Remote (India & Global)\",\n    availability: \"Open to full-time, contract, freelance\",\n    \n    // The T-Shaped Stack (Your Unfair Advantage)\n    tStack: {\n      depth: {\n        area: \"Multi-Agent Orchestration\",\n        skills: [\"LangGraph\", \"CrewAI\", \"n8n AI Agents\"],\n        proof: \"74-node production workflows with 99.7% reliability\"\n      },\n      breadth: [\n        { area: \"Frontend Excellence\", detail: \"Next.js 15, 95+ Lighthouse scores\" },\n        { area: \"Workflow Automation\", detail: \"15+ production workflows deployed\" },\n        { area: \"Technical SEO/GEO\", detail: \"#1 Google rankings, AI Search visibility\" }\n      ],\n      pitch: \"Most AI developers build the brain but not the body. I do both.\"\n    }\n  },\n  \n  targetRoles: [\n    \"Technical Solutions Engineer (TSE)\",\n    \"Associate Product Manager (APM)\",\n    \"Developer Relations (DevRel)\",\n    \"Growth Engineer\",\n    \"Founder's Office (Technical)\",\n    \"AI Automation Engineer\",\n    \"Agentic AI Developer\",\n    \"Full-Stack AI Developer\"\n  ],\n  \n  hiddenGoals: {\n    primary: \"Get inbound TSE/APM/DevRel offers from target companies\",\n    secondary: \"Attract â‚¹75K-3L freelance automation projects organically\",\n    tertiary: \"Build reputation as Agentic AI + n8n expert in India\",\n    longTerm: \"Transition to robotics/edge AI within 2-3 years\"\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.2 CONTENT VOICE (How to Sound Like Aman)\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  voice: {\n    attributes: [\n      \"Authentic & transparent - share real struggles + wins\",\n      \"Detail-oriented with technical depth\",\n      \"Growth-minded - always learning, never pretending to know it all\",\n      \"Practical over theoretical - show real code, real metrics\",\n      \"Builds in public - document the journey, not just the destination\",\n      \"Helpful & community-focused - teach what you learn\"\n    ],\n    \n    toneGuidelines: [\n      \"Use 'I' statements, not 'we' (you're a solo builder)\",\n      \"Short paragraphs (2-3 sentences max for social)\",\n      \"Lead with the insight, not the backstory\",\n      \"Be opinionated on tech choices - strong views, loosely held\",\n      \"Admit mistakes openly - it builds trust\"\n    ],\n    \n    forbiddenPhrases: [\n      \"In today's digital landscape\",\n      \"Delve\", \"Unlock\", \"Unleash\", \"Leverage\",\n      \"Game-changer\", \"Revolutionary\", \"Cutting-edge\", \"Synergy\",\n      \"Humbled to announce\", \"Thrilled to share\", \"Excited to announce\",\n      \"Let's dive in\", \"Without further ado\", \"Honored to\",\n      \"At the end of the day\", \"It goes without saying\",\n      \"Take it to the next level\", \"Circle back\"\n    ]\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.3 CONTENT PILLARS (What to Post About)\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  contentPillars: [\n    {\n      pillar: \"Build-in-Public\",\n      weight: 0.35,\n      hashtags: [\"#buildinpublic\", \"#indiedev\", \"#solofounder\"],\n      topics: [\"Project updates\", \"Revenue milestones\", \"Failures & pivots\", \"Tool reveals\"]\n    },\n    {\n      pillar: \"n8n & Automation Deep Dives\",\n      weight: 0.30,\n      hashtags: [\"#n8n\", \"#automation\", \"#nocode\", \"#lowcode\", \"#workflowautomation\"],\n      topics: [\"Workflow breakdowns\", \"Error handling patterns\", \"Self-healing architecture\", \"API integration tips\"]\n    },\n    {\n      pillar: \"AI/Agentic Systems\",\n      weight: 0.25,\n      hashtags: [\"#AgenticAI\", \"#LangChain\", \"#LangGraph\", \"#AI\", \"#LLM\"],\n      topics: [\"RAG implementations\", \"Multi-agent patterns\", \"LLM orchestration\", \"AI in production\"]\n    },\n    {\n      pillar: \"Career & Freelance\",\n      weight: 0.10,\n      hashtags: [\"#freelance\", \"#remotework\", \"#techcareers\", \"#developerlife\"],\n      topics: [\"Client acquisition\", \"Portfolio strategy\", \"Pricing lessons\", \"Work-life integration\"]\n    }\n  ],\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.4 PROJECT HOOKS (Story Starters - The \"Content Seeds\")\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  projectHooks: {\n    \"aviators-training-centre\": {\n      hooks: [\n        \"I turned a flight school's website into their #1 sales channel. Here's the system:\",\n        \"From 0 to â‚¹3L revenue with just SEO + n8n automation. Thread ðŸ§µ\",\n        \"My client was losing leads to a contact form nobody checked. I built a 14-node solution.\",\n        \"How I achieved 95+ Lighthouse scores on a Next.js 15 production site:\",\n        \"80% reduction in manual tasks. Here's the n8n workflow that made it happen:\"\n      ],\n      theStruggle: \"Spent 2 days debugging Firebase webhook triggers that fired twice. Turns out I needed idempotency keys.\",\n      theBreakthrough: \"Realized n8n + Airtable + Resend could replace their entire CRM workflow.\",\n      lessonLearned: \"SEO compounds. The â‚¹3L didn't come from one postâ€”it came from 6 months of #1 rankings.\",\n      hotTakes: [\n        \"WordPress is dead for client projects. Next.js + Sanity is the 2025 stack.\"\n      ]\n    },\n    \"n8n-automation-suite\": {\n      hooks: [\n        \"I post to LinkedIn and Twitter/X with one click. Here's my 74-node system:\",\n        \"Stop copy-pasting content across platforms. Automate it.\",\n        \"Built-in-public content flywheel: Notion draft â†’ viral post in 60 seconds.\",\n        \"The architecture behind my self-healing content automation:\",\n        \"Why I moved from Zapier to self-hosted n8n (and saved â‚¹15K/month):\"\n      ],\n      theStruggle: \"Twitter API rate limits almost killed this project at 3 AM. OAuth 1.0a is pain.\",\n      theBreakthrough: \"Dead-letter queues changed everything. No more silent failures.\",\n      lessonLearned: \"Build for failure first. Happy path is the easy part.\",\n      hotTakes: [\n        \"Zapier is for prototypes. n8n is for production.\",\n        \"If your automation can't self-heal, it's just a scheduled script.\"\n      ]\n    },\n    \"n8n-github-backup\": {\n      hooks: [\n        \"My n8n instance crashed on a Friday. No backups. Never again.\",\n        \"99.9% recovery rate with self-healing retry logic. Here's the architecture:\",\n        \"How I built a dual-stream backup system that handles 1000+ workflows:\",\n        \"The credential scrubbing pattern that makes your n8n repos public-safe:\",\n        \"GitHub's 30 req/min limit forced me to redesign everything. Best decision ever.\"\n      ],\n      theStruggle: \"First version hit rate limits constantly. Had to completely rethink the architecture.\",\n      theBreakthrough: \"Loop-to-Webhook pattern: Orchestration and execution in separate streams.\",\n      lessonLearned: \"Rate limits aren't bugsâ€”they're design constraints. Embrace them.\",\n      hotTakes: [\n        \"If you're not backing up your n8n workflows to git, you're one crash away from losing everything.\"\n      ]\n    },\n    \"barkat-enterprise\": {\n      hooks: [\n        \"3,000+ viewers for a tiles distributor website. Here's how React won:\",\n        \"PDF catalogues in-browser with PDFJS. No downloads, no friction.\",\n        \"My first B2B freelance project: lessons from building for a traditional business.\"\n      ],\n      theStruggle: \"Client had no digital presence. Had to explain every tech decision in simple terms.\",\n      theBreakthrough: \"PDF viewer eliminated their biggest pain pointâ€”printing and distributing catalogues.\",\n      lessonLearned: \"Simple features that remove friction > complex features that impress developers.\"\n    },\n    \"av-newsstream\": {\n      hooks: [\n        \"9 API keys. 10-minute cache. 90% reduction in API calls. Here's the system:\",\n        \"How I solved the free-tier API limit problem with intelligent key rotation:\",\n        \"Text-to-speech in a news app? Here's why I added it and what I learned.\"\n      ],\n      theStruggle: \"NewsAPI's 100 req/day limit seemed impossible to work around.\",\n      theBreakthrough: \"ApiKeyManager.js with health tracking and automatic failover.\",\n      lessonLearned: \"Caching is the most underrated optimization. 10 minutes saved 90% of API calls.\"\n    },\n    \"foodah\": {\n      hooks: [\n        \"14,000+ lines of JSON. 60fps scrolling. Here's how I built Foodah:\",\n        \"Custom React hooks for everything: useOnlineStatus, useFallbackImage, useRestaurantMenu.\",\n        \"Shimmer UI and lazy loading: The performance patterns that matter.\"\n      ],\n      theStruggle: \"Swiggy API returns deeply nested, inconsistent data. Optional chaining saved my sanity.\",\n      theBreakthrough: \"useFallbackImage hook that replaces broken images with random alternatives seamlessly.\",\n      lessonLearned: \"Never trust external APIs to be consistent. Always have fallbacks.\"\n    },\n    \"portfolio-website\": {\n      hooks: [\n        \"6,000+ project views. 95+ Lighthouse. Here's my portfolio stack:\",\n        \"Why I chose Sanity CMS over Contentful for my developer portfolio:\",\n        \"The Omni-Post workflow that auto-distributes every blog post I write.\"\n      ],\n      theStruggle: \"Redesigned 3 times before landing on the current system.\",\n      theBreakthrough: \"Integrating n8n webhooks with Sanity CMS for automated social distribution.\",\n      lessonLearned: \"Your portfolio is never done. Treat it like a product, not a project.\"\n    }\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.5 PLATFORM-SPECIFIC RULES\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  platformRules: {\n    linkedin: {\n      maxLength: 3000,\n      optimalLength: \"800-1200 chars for engagement\",\n      style: \"Professional but not corporate. Use line breaks aggressively. Hook in first 2 lines.\",\n      cta: \"Follow for daily AI automation breakdowns.\",\n      formatting: [\n        \"Use emoji bullets sparingly (â†’, âœ…, ðŸ”¥)\",\n        \"One idea per paragraph\",\n        \"End with a question to drive comments\"\n      ],\n      emojiUsage: \"Minimal. 2-3 max. No emoji spam.\",\n      hashtagCount: \"3-5 at the end, never inline\"\n    },\n    twitter: {\n      maxLength: 280,\n      style: \"Punchy. Opinionated. Thread-friendly. No fluff.\",\n      cta: \"Follow @_AmanSurya for more.\",\n      formatting: [\n        \"Front-load the value\",\n        \"Use numbers and specifics\",\n        \"Thread opener should stand alone\"\n      ],\n      emojiUsage: \"Match tech twitter energy. More acceptable here.\",\n      hashtagCount: \"1-2 max, only if organic\"\n    }\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.6 FUTURE ROADMAP (For relevant content positioning)\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  futureRoadmap: {\n    currentFocus: \"Agentic Systems Era - LangGraph + CrewAI + n8n AI Agents\",\n    learning: [\n      \"Advanced LangGraph patterns\",\n      \"Multi-agent orchestration at scale\",\n      \"WebSockets & real-time communication\",\n      \"Docker & containerization for edge deployment\"\n    ],\n    yearEnd2026: \"Launch Personal RAG assistant + production LangGraph agents\",\n    longTermVision: \"Transition to robotics/edge AIâ€”bringing agentic intelligence to physical systems\",\n    philosophyNote: \"The T-Stack: deep in orchestration, broad across the stack. That's the unfair advantage.\"\n  }\n};\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 2: SAFE PARSE OF INCOMING API/GEMINI DATA\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nlet portfolioData = {};\ntry {\n  // Handle both stringified JSON and direct object from Gemini/API\n  const text = contextRaw.content?.parts?.[0]?.text || JSON.stringify(contextRaw);\n  const cleanJson = text.replace(/```json/g, '').replace(/```/g, '').trim();\n  portfolioData = JSON.parse(cleanJson);\n} catch (e) {\n  console.log('Portfolio Data Parse Warning:', e.message);\n  // Fallback with essential identity\n  portfolioData = {\n    core: {\n      name: \"Aman Suryavanshi\",\n      role: \"AI Workflow Architect & Systems Builder\",\n      tagline: \"I Build Self-Healing AI Systems That Drive Revenue\"\n    }\n  };\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 3: INTELLIGENT CONTENT SUMMARIZATION (Cost-Optimized)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nfunction intelligentSummarize(sourceContent) {\n  if (!sourceContent) {\n    return {\n      summary: \"No content available\",\n      structure: \"empty\",\n      wordCount: 0,\n      complexity: \"unknown\",\n      keyTopics: []\n    };\n  }\n\n  const { fullText, sections, extractionStats, summary } = sourceContent;\n  let outputSummary = \"\";\n\n  // Priority 1: Use pre-extracted summary if available\n  if (summary && summary.length > 100) {\n    outputSummary = summary.substring(0, 1500);\n  } else {\n    // Priority 2: Section headings (highest signal-to-noise)\n    const sectionTitles = (sections || [])\n      .filter(s => s.title && s.title.length > 3)\n      .map(s => `â€¢ ${s.title}`)\n      .slice(0, 10)\n      .join('\\n');\n\n    if (sectionTitles) {\n      outputSummary += \"**Key Sections:**\\n\" + sectionTitles + \"\\n\\n\";\n    }\n\n    // Priority 3: First substantive content block\n    if (sections && sections.length > 0) {\n      const contentSection = sections.find(s => s.content && s.content.length > 50);\n      if (contentSection) {\n        outputSummary += \"**Core Content:**\\n\" +\n          contentSection.content.substring(0, 600).replace(/\\n+/g, ' ') + \"...\\n\";\n      }\n    }\n\n    // Priority 4: Fallback to fullText\n    if (!outputSummary && fullText) {\n      outputSummary = \"**Content Preview:**\\n\" + fullText.substring(0, 1200) + \"...\";\n    }\n  }\n\n  // Extract key topics for content matching (simple keyword extraction)\n  const topicKeywords = [\n    'n8n', 'automation', 'Next.js', 'React', 'AI', 'LLM', 'SEO', 'workflow',\n    'API', 'Firebase', 'Supabase', 'TypeScript', 'production', 'revenue'\n  ];\n  const textLower = (fullText || outputSummary).toLowerCase();\n  const keyTopics = topicKeywords.filter(kw => textLower.includes(kw.toLowerCase()));\n\n  return {\n    summary: outputSummary.substring(0, 2000),\n    structure: extractionStats?.hasToggles ? \"hierarchical\" : \"linear\",\n    wordCount: extractionStats?.wordCount || (fullText?.split(/\\s+/).length || 0),\n    complexity: extractionStats?.complexity || \"medium\",\n    sectionCount: sections?.length || 0,\n    hasCode: extractionStats?.codeSections > 0,\n    hasToggles: extractionStats?.toggleSections > 0,\n    keyTopics: keyTopics\n  };\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 4: CONTEXT MATCHING - Find relevant project hooks for the content\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nfunction findRelevantProjectHooks(contentSummary, projectHooks) {\n  const topics = contentSummary.keyTopics || [];\n  const contentText = (contentSummary.summary || '').toLowerCase();\n  \n  // Score each project by keyword matches\n  const projectScores = Object.entries(projectHooks).map(([projectId, hooks]) => {\n    let score = 0;\n    \n    // Check if project name is mentioned\n    if (contentText.includes(projectId.replace(/-/g, ' '))) score += 10;\n    \n    // Check topic overlaps\n    const projectKeywords = {\n      \"aviators-training-centre\": [\"next.js\", \"seo\", \"revenue\", \"firebase\", \"freelance\"],\n      \"n8n-automation-suite\": [\"n8n\", \"automation\", \"content\", \"linkedin\", \"twitter\", \"workflow\"],\n      \"n8n-github-backup\": [\"backup\", \"github\", \"n8n\", \"self-healing\", \"production\"],\n      \"barkat-enterprise\": [\"react\", \"pdf\", \"b2b\", \"freelance\"],\n      \"av-newsstream\": [\"api\", \"news\", \"caching\", \"react\"],\n      \"foodah\": [\"react\", \"api\", \"performance\", \"swiggy\"],\n      \"portfolio-website\": [\"portfolio\", \"sanity\", \"blog\", \"seo\"]\n    };\n    \n    (projectKeywords[projectId] || []).forEach(kw => {\n      if (contentText.includes(kw)) score += 2;\n    });\n    \n    return { projectId, hooks, score };\n  });\n  \n  // Return top 2 relevant projects\n  return projectScores\n    .filter(p => p.score > 0)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, 2)\n    .map(p => ({\n      projectId: p.projectId,\n      suggestedHooks: p.hooks.hooks?.slice(0, 2) || [],\n      theStruggle: p.hooks.theStruggle,\n      lessonLearned: p.hooks.lessonLearned\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 5: BUILD FINAL MERGED OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nconst sourceContent = contentNode.sourceContent || {};\nconst contentSummary = intelligentSummarize(sourceContent);\nconst relevantHooks = findRelevantProjectHooks(contentSummary, strategicContext.projectHooks);\n\n// Merge everything\nconst mergedContext = {\n  // From Portfolio API (facts, proof, metrics)\n  ...portfolioData,\n  \n  // Strategic layer (voice, goals, positioning)\n  strategic: strategicContext,\n  \n  // Matched content hooks for this specific post\n  matchedHooks: relevantHooks\n};\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 6: FINAL OUTPUT (Matching \"Part 1\" Schema)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nreturn [{\n  json: {\n    // The full merged context for AI nodes\n    personalContext: mergedContext,\n    \n    // Convenience: Quick access to key strategic elements for prompts\n    voiceGuide: {\n      attributes: strategicContext.voice.attributes,\n      forbidden: strategicContext.voice.forbiddenPhrases,\n      toneGuidelines: strategicContext.voice.toneGuidelines\n    },\n    \n    // Platform rules for the Distribution node\n    platformRules: strategicContext.platformRules,\n    \n    // Content pillars with weights for topic selection\n    contentPillars: strategicContext.contentPillars,\n    \n    // The T-Stack pitch (use in bios, intros)\n    tStackPitch: strategicContext.positioning.tStack.pitch,\n    \n    // Processed source content\n    sourceContent: sourceContent,\n    \n    // Optimized summary for LLM prompts (cost control)\n    contentSummary: contentSummary,\n    \n    // Matched hooks for this content\n    suggestedHooks: relevantHooks,\n    \n    // Keep full source for reference if needed\n    _fullSourceContent: sourceContent,\n    \n    // Metadata for debugging\n    _meta: {\n      version: \"v3.0\",\n      generatedAt: new Date().toISOString(),\n      portfolioDataKeys: Object.keys(portfolioData),\n      matchedProjects: relevantHooks.map(h => h.projectId)\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2336,
        2640
      ],
      "id": "8875bd0d-d663-408c-8c2b-08187c2b107d",
      "name": "Code â€“ Personal Context Builder"
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// CONTEXT MERGER (fetches from previous node, merges with Perplexity)\n// Place after Perplexity node, queries previous (Personal Context Builder) node\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconsole.log('ðŸ”— Starting final context merger...');\n\n// 1. Fetch JSON data from the previous Personal Context Builder node\n// const previous = $('Code â€“ Personal Context Builder').first().json || {};\nconst previous = $('Code â€“ Personal Context Builder').first().json;\n\n// 2. Get Perplexity output directly â€“ comes as $json in this node\n// const perplexity = $json || {};\nconst perplexity = $json;\n\n// 3. Merge key blocks: always prefer Perplexity for \"research\", but get everything else from previous\n// const personalContext = previous.personalContext || {};\nconst personalContext = previous.personalContext;\nconst sourceContent = previous.sourceContent || {};\nconst contentSummary = previous.contentSummary || {};\nconst perplexityChoices = perplexity.choices;\n\n// Use fallback/default for every key field!\nconst name = personalContext.name || 'Unknown User';\nconst title = sourceContent.name || 'Untitled Content';\nconst categories = Array.isArray(sourceContent.categories) ? sourceContent.categories : ['General'];\nconst primaryCategory = categories[0] || 'General';\nconst summary = contentSummary.summary || '';\nconst wordCount = contentSummary.wordCount || 0;\nconst structure = contentSummary.structure || 'linear';\nconst complexity = contentSummary.complexity || 'unknown';\nconst fullText = sourceContent.fullText || '';\n\n// Perplexity research blockâ€”parse its result\nlet research = {};\ntry {\n  if (\n    Array.isArray(perplexityChoices) &&\n    perplexityChoices.length > 0 &&\n    typeof perplexityChoices[0] === 'object'\n  ) {\n    let rawContent = perplexityChoices[0].message?.content ?? '';\n    rawContent = rawContent.replace(/``````/g, '').trim();\n    if (rawContent) {\n      research = JSON.parse(rawContent);\n      console.log('âœ… Parsed Perplexity JSON.');\n    } else {\n      throw new Error('Empty content in Perplexity choices.');\n    }\n  } else {\n    throw new Error('Perplexity choices incomplete.');\n  }\n} catch (err) {\n  console.warn(`âš ï¸ Perplexity parsing failed: ${err.message}. Using fallback research.`);\n  research = {\n    authenticHashtags: {\n      twitter: ['#BuildInPublic', `#${primaryCategory}`, '#Automation', '#NoCode', '#n8n'],\n      linkedin: ['#ProcessAutomation', `#${primaryCategory}`, '#SystemsThinking', '#AI'],\n    },\n    optimalTimesIST: {\n      twitter_primary_ist: \"9:00-11:00 am IST\",\n      twitter_secondary_ist: \"8:30-9:30 pm IST (US/EU overlap)\",\n      linkedin_ist: \"10:00-12:00 am IST (Tue-Thu)\"\n    },\n    authenticHooks: {\n      twitter_example: \"Solving a weird API quirk in n8n todayâ€”here's the step that finally worked. Anyone else get stuck on webhook reliability?\",\n      linkedin_example: \"Client automated 50% manual onboarding steps using n8n, saving 10 hours/week. Why did we choose modular flows?\"\n    },\n    developerPainPoints: [\n      \"Lack of reliable content scheduling tools for Indian time zones\",\n      \"Complicated OAuth flows between LinkedIn, X and custom APIs\"\n    ]\n  };\n}\n\n// Optional IDs/session info\nconst originalId = previous.originalId ?? null;\nconst sessionId = previous.sessionId ?? null;\nconst notionPageId = sourceContent.id ?? null;\nconst extractionStats = sourceContent.extractionStats ?? {};\nconst hasImages = Array.isArray(sourceContent.images) && sourceContent.images.length > 0;\nconst processingTime = new Date().toISOString();\n\n// Master context object (robust, merged)\nconst masterContext = {\n  personalContext: {\n    ...personalContext,\n    name\n  },\n  sourceContent: {\n    title,\n    categories,\n    primaryCategory,\n    summary,\n    wordCount,\n    structure,\n    complexity,\n    fullText\n  },\n  contentSummary: {\n    summary,\n    wordCount,\n    structure,\n    complexity\n  },\n  research,\n  originalId,\n  sessionId,\n  workflowMetadata: {\n    notionPageId,\n    extractionStats,\n    hasImages,\n    processingTime\n  }\n};\n\nconsole.log('âœ… Master context object created successfully!');\nreturn [{ json: masterContext }];\n"
      },
      "id": "451f93a8-4726-4d59-ab08-9407377db809",
      "name": "Code â€“ CONTEXT MERGER",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2784,
        2640
      ]
    },
    {
      "parameters": {
        "resource": "folder",
        "name": "={{ $('Notion â€“ Get Ready Content').item.json.name }}-SocialDrafts-{{ $json.sessionId }}",
        "driveId": {
          "__rl": true,
          "mode": "list",
          "value": "My Drive"
        },
        "folderId": {
          "__rl": true,
          "value": "1F25H1IcOyYzJa41LwbD-r31_Ogs6ASZd",
          "mode": "list",
          "cachedResultName": "N8N Build in public Drafts - LinkedIn & X",
          "cachedResultUrl": "https://drive.google.com/drive/folders/1F25H1IcOyYzJa41LwbD-r31_Ogs6ASZd"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        2672,
        2352
      ],
      "id": "1d33175b-011f-450a-b647-11d3f1be50ae",
      "name": "Create folder for title",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "1hcyFpBqSOMDRDna",
          "name": "Google Drive Adude"
        }
      }
    },
    {
      "parameters": {
        "content": "Creating a separate folder in Drive to store all the assets & generated drafts",
        "height": 240,
        "width": 224
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2608,
        2272
      ],
      "typeVersion": 1,
      "id": "6876bda7-0a9f-4421-b0ed-c4f2a7406334",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "model": "sonar-pro",
        "messages": {
          "message": [
            {
              "content": "=<role>\nYou are a Senior Technical Market Intelligence Analyst. Your job is NOT to write content, but to find the \"Heat\" in the market. You act as the eyes and ears for Aman Suryavanshi, a Build-in-Public founder (Next.js/n8n/AI/no-code/low-code).\n</role>\n\n<instructions>\n1. **The \"Newsjack\" (Urgency)**\n   - Search for recent software updates (e.g., \"Next.js 15\", \"n8n v1.0\", \"Claude 3.5\") or industry news related to this topic.\n   - *Goal:* Find ONE specific event that makes this content timely. (e.g., \"This is relevant because Vercel just changed their caching policy\").\n\n2. **The \"Gap Analysis\" (The Void)**\n   - Search Reddit (r/webdev, r/selfhosted) and HackerNews.\n   - What question is everyone asking but getting bad answers for?\n   - Identify \"Contrarian Angles\": What is the common advice that is actually wrong/inefficient?\n\n3. **Technical Vibe Check**\n   - Find 2-3 specific technical keywords that are trending in this niche RIGHT NOW (e.g., don't just say \"AI\", say \"Agentic Loops\" or \"MCP Servers\").\n\n4. **Platform Intelligence**\n   - **Twitter:** Find a \"Village\" (group of devs) discussing this. What is their sentiment? (Excited? Angry? Confused?)\n   - **LinkedIn:** Find a \"Business Stat\" or \"Cost Argument\". (e.g., \"Manual API integrations cost devs 10hrs/week\").\n   - **Blog:** Find \"Zero-Volume, High-Intent\" keywords (e.g., \"fix n8n webhook timeout 502\").\n\n5. **Timing**\n   - Provide optimal posting times for Asia/Kolkata (IST).\n</instructions>\n\n<outputformat>\nReturn ONLY valid JSON with this EXACT structure (no markdown fences):\n\n{\n  \"market_pulse\": {\n    \"urgency_trigger\": \"The recent event/update that makes this relevant NOW.\",\n    \"community_sentiment\": \"What are devs feeling? (e.g., 'Frustrated with complex setups').\",\n    \"the_gap\": \"The specific unanswered question or bad advice you found.\"\n  },\n  \"twitter\": {\n    \"hashtags\": [\"#SpecificTag1\", \"#SpecificTag2\"],\n    \"optimal_posting_times_ist\": [\"09:00 AM\", \"06:00 PM\"],\n    \"hook_inspiration\": \"A specific angle based on the urgency_trigger.\"\n  },\n  \"linkedin\": {\n    \"hashtags\": [\"#SpecificTag1\", \"#SpecificTag2\"],\n    \"optimal_posting_times_ist\": [\"10:00 AM\", \"02:00 PM\"],\n    \"business_value_stat\": \"A specific data point or cost argument found in research.\"\n  },\n  \"blog\": {\n    \"seo_keywords_primary\": [\n      {\"keyword\": \"main topic\", \"volume\": \"high\"}\n    ],\n    \"seo_keywords_longtail\": [\n      {\"keyword\": \"very specific problem fix\", \"volume\": \"low\"}\n    ],\n    \"competitor_gap\": \"What technical detail is missing in current top articles?\"\n  }\n}\n</outputformat>\n\n<constraints>\n- Research MUST be from the last 14 days.\n- Do NOT return generic advice. If no specific news is found, focus on a specific \"Eternal Struggle\" (e.g., \"Dependency Hell\").\n- Output must be strict JSON.\n</constraints>\n",
              "role": "system"
            },
            {
              "content": "=<context>\n<profile>\n- primary_focus: {{ $json.personalContext.strategic.futureRoadmap.currentFocus }}\n- target_roles: {{ $json.personalContext.strategic.targetRoles }}\n</profile>\n\n<topic>\n<name>{{$json.sourceContent.name}}</name>\n<categories>{{$json.sourceContent.categories}}</categories>\n<summary>{{$json.contentSummary.summary}}</summary>\n<date>{{ $now }}</date>\n</topic>\n</context>\n\n<task>\nConduct deep real-time research (last 14 days) to validate this topic. Find specific discussions, news, and technical arguments that make this topic urgent TODAY.\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.2,
          "searchRecency": "month"
        },
        "requestOptions": {}
      },
      "id": "47ac0211-2d59-46bf-bb2e-f5ce7d6b1c2f",
      "name": "Perplexity â€“ Research Hashtags & Timing",
      "type": "n8n-nodes-base.perplexity",
      "typeVersion": 1,
      "position": [
        2560,
        2640
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "perplexityApi": {
          "id": "srhZqNtWBccjllrY",
          "name": "Perplexity work"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\r\n// PROCESS AI STRATEGY (V6 - Enhanced Validation, Feb 2026)\r\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\r\n\r\n// 1. SAFE INPUT EXTRACTION\r\n// We use optional chaining and fallback objects to prevent \"Cannot read property of undefined\" errors\r\nconst geminiRawOutput = $input.first()?.json || {};\r\nconst contextNode = $('Code â€“ CONTEXT MERGER').first();\r\nconst originalContext = contextNode ? contextNode.json : {};\r\n\r\n// Validate Critical Inputs\r\nif (Object.keys(geminiRawOutput).length === 0) {\r\n  throw new Error('âŒ CRITICAL: No input received from Gemini AI Node.');\r\n}\r\nif (Object.keys(originalContext).length === 0) {\r\n  // Warn but don't crash hard if context is missing (useful for isolated testing)\r\n  console.log('âš ï¸ WARNING: Original Context is empty. Merging might be incomplete.');\r\n}\r\n\r\n// 2. ROBUST JSON PARSING (The \"Fence Stripper\")\r\n// AI often wraps output in markdown or adds conversational filler. We strip it all.\r\nlet rawText = geminiRawOutput.text ||\r\n  geminiRawOutput.content?.parts?.[0]?.text ||\r\n  geminiRawOutput.result || // Some Gemini node versions use .result\r\n  \"\";\r\n\r\n// Handle edge case where the input itself is just the string\r\nif (typeof geminiRawOutput === 'string') rawText = geminiRawOutput;\r\n\r\nconst firstBrace = rawText.indexOf('{');\r\nconst lastBrace = rawText.lastIndexOf('}');\r\n\r\nif (firstBrace === -1 || lastBrace === -1) {\r\n  // Output the raw text to the error log so you can debug *what* the AI actually said\r\n  throw new Error(`CRITICAL: Valid JSON not found in AI output. Raw Output Preview: ${rawText.substring(0, 100)}...`);\r\n}\r\n\r\nconst jsonString = rawText.substring(firstBrace, lastBrace + 1);\r\nlet strategy;\r\ntry {\r\n  strategy = JSON.parse(jsonString);\r\n} catch (e) {\r\n  // Common AI error: trailing commas. We fail strictly here to ensure data integrity.\r\n  throw new Error(`CRITICAL: JSON Syntax Error. The extracted block was not valid JSON. Error: ${e.message}`);\r\n}\r\n\r\n// 3. DEEP VALIDATION & SANITIZATION (The Checkpoints)\r\nfunction validateAndSanitize(data) {\r\n  const issues = [];\r\n\r\n  // A. Top-Level Integrity\r\n  if (!data?.strategy_summary) issues.push(\"Missing 'strategy_summary'\");\r\n  if (!data?.platform_strategies) issues.push(\"Missing 'platform_strategies'\");\r\n\r\n  const platforms = data.platform_strategies || {};\r\n\r\n  // B. Source Quality Assessment (V6 Enhancement)\r\n  // The Strategist now outputs source_quality. Ensure safe defaults.\r\n  if (!data.source_quality) {\r\n    data.source_quality = 'moderate'; // Safe default\r\n    console.log('âš ï¸ source_quality not found in strategy output. Defaulting to \"moderate\".');\r\n  }\r\n  // Validate it's a known value\r\n  const validQualities = ['strong', 'moderate', 'thin'];\r\n  if (!validQualities.includes(data.source_quality)) {\r\n    console.log(`âš ï¸ Invalid source_quality \"${data.source_quality}\". Resetting to \"moderate\".`);\r\n    data.source_quality = 'moderate';\r\n  }\r\n  // If thin, ensure quality_warning exists\r\n  if (data.source_quality === 'thin' && !data.quality_warning) {\r\n    data.quality_warning = 'Source flagged as thin but no quality_warning provided by Strategist.';\r\n  }\r\n\r\n  // C. Narrative Arc Validation (V6 Enhancement)\r\n  if (!data.narrative_arc) {\r\n    data.narrative_arc = {\r\n      formula: 'PAS',\r\n      the_villain: 'Not identified by strategist',\r\n      the_epiphany: 'Not identified by strategist',\r\n      the_transformation: 'Not identified by strategist'\r\n    };\r\n    console.log('âš ï¸ narrative_arc missing. Created safe default.');\r\n  } else {\r\n    // Ensure formula field exists (new in V6)\r\n    if (!data.narrative_arc.formula) {\r\n      data.narrative_arc.formula = 'PAS'; // Default narrative formula\r\n    }\r\n    // Validate formula is a known pattern\r\n    const validFormulas = ['PAS', 'BAB', 'BUT_THEREFORE'];\r\n    if (!validFormulas.includes(data.narrative_arc.formula)) {\r\n      console.log(`âš ï¸ Unknown narrative formula \"${data.narrative_arc.formula}\". Keeping as-is.`);\r\n    }\r\n  }\r\n\r\n  // D. Psychological Triggers Validation (V6 Enhancement)\r\n  if (!data.psychological_triggers) {\r\n    data.psychological_triggers = {\r\n      stop_trigger_type: 'pattern_interrupt',\r\n      save_trigger: 'Not specified',\r\n      share_trigger: 'Not specified',\r\n      authenticity_signal: 'Not specified',\r\n      emotional_arc: 'curiosity â†’ tension â†’ relief â†’ empowerment'\r\n    };\r\n    console.log('âš ï¸ psychological_triggers missing. Created safe default.');\r\n  }\r\n\r\n  // E. Twitter/X Sanitization\r\n  if (!platforms.twitter) {\r\n    // Auto-fix: Create a minimal valid object so downstream nodes don't crash\r\n    platforms.twitter = {\r\n      hashtags: [],\r\n      content_breakdown: [\"General Strategy Update\"]\r\n    };\r\n  } else {\r\n    // Enforce array types for iterables\r\n    if (!Array.isArray(platforms.twitter.hashtags)) platforms.twitter.hashtags = [];\r\n  }\r\n\r\n  // F. LinkedIn Validation (We treat this as critical)\r\n  if (!platforms.linkedin) {\r\n    issues.push(\"Missing 'platform_strategies.linkedin'\");\r\n  }\r\n\r\n  // G. Image Strategy Safety (Crucial for branching nodes)\r\n  if (!data.image_strategy) {\r\n    // Safe default: No images needed\r\n    data.image_strategy = {\r\n      needs_images: false,\r\n      rationale: \"Default fallback (AI strategy missing)\",\r\n      specific_prompts: []\r\n    };\r\n  } else {\r\n    // Ensure specific_prompts is always an array\r\n    if (!Array.isArray(data.image_strategy.specific_prompts)) {\r\n      data.image_strategy.specific_prompts = [];\r\n    }\r\n    // Boolean enforcement\r\n    data.image_strategy.needs_images = !!data.image_strategy.needs_images;\r\n  }\r\n\r\n  // If critical fields are missing, fail the workflow so you are alerted\r\n  if (issues.length > 0) {\r\n    throw new Error(`VALIDATION FAILED: ${issues.join(', ')}`);\r\n  }\r\n\r\n  return data;\r\n}\r\n\r\n// Run the validator\r\nconst cleanStrategy = validateAndSanitize(strategy);\r\n\r\n// 4. MASTER MERGE\r\n// Combine everything into one guaranteed object for the next nodes\r\nconst masterData = {\r\n  // Use optional chaining to safely access deep properties from context\r\n  personalContext: originalContext?.personalContext || {},\r\n  sourceContent: originalContext?.sourceContent || {},\r\n  research: originalContext?.research || {},\r\n  workflowMetadata: originalContext?.workflowMetadata || {},\r\n  strategy: cleanStrategy,\r\n  _meta: {\r\n    parsedAt: new Date().toISOString(),\r\n    validatorVersion: \"6.0-Enhanced\",\r\n    sourceQuality: cleanStrategy.source_quality,\r\n    narrativeFormula: cleanStrategy.narrative_arc?.formula || 'PAS'\r\n  }\r\n};\r\n\r\nreturn [{ json: masterData }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3360,
        2640
      ],
      "id": "427a9a98-3fbb-4313-b6fd-1982731dcce5",
      "name": "Process AI Strategy & MERGE CONTEXT"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "e0a6bdb8-0521-4d53-a351-c2ec3f05310e",
              "leftValue": "={{ $json.strategy.image_strategy.needs_images }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        4016,
        3504
      ],
      "id": "74a8a462-0b2f-42e5-9c56-9af09c55bd4c",
      "name": "Are Images Needed?",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "e6bbf5e8-5982-4daa-ac73-f54ca4f4cae5",
              "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('X') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3728,
        1680
      ],
      "id": "a5cafb72-4554-4163-87d9-efa483ce40dd",
      "name": "IF - Twitter Selected?"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "20913d76-b524-4cd5-9550-bb1e584cc9a5",
              "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('LinkedIn') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3728,
        2064
      ],
      "id": "bc43212b-c620-421e-b97f-086c22679384",
      "name": "IF - LinkedIn Selected?"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "efebb240-a978-43aa-be26-00c040c5a359",
              "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('Blog') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3728,
        2448
      ],
      "id": "0790741c-8d96-47af-ba36-d5e0b4024e45",
      "name": "IF - Blog Selected?"
    },
    {
      "parameters": {
        "jsCode": "// Return placeholder for skipped Twitter draft\nreturn [{\n  json: {\n    id: null,\n    platform: 'twitter',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4528,
        1776
      ],
      "id": "3f646da1-48ec-4610-97b2-ce744c6528dc",
      "name": "Code - No-Op Twitter Draft"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    id: null,\n    platform: 'linkedin',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4528,
        2160
      ],
      "id": "4441de05-3b0c-4a73-aaa9-33c5787562e9",
      "name": "Code - No-Op LinkedIn Draft"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    id: null,\n    platform: 'blog',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4528,
        2544
      ],
      "id": "4a33f768-9e4c-46a0-a568-c495f96b4031",
      "name": "Code - No-Op Blog Draft"
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "=<system_instructions>\n<role>\nYou are a world-class Build-in-Public content strategist for Aman Suryavanshi, a Next.js developer and n8n automation specialist. Your primary job is to extract the REAL value from Aman's source content and craft a detailed, multi-platform content strategy. This includes both the textual content plan and a sophisticated visual asset plan.\n</role>\n\n<critical_instruction>\nâš ï¸ YOU MUST USE THE PROVIDED sourceContent.fullText AS THE SINGLE SOURCE OF TRUTH. Do not invent scenarios, projects, or examples. Aman shares his real implementation experience - your job is to extract and repurpose what he ACTUALLY did, not to write fiction. Every part of your strategy must be traceable back to the source content.\n</critical_instruction>\n\n<master_framework>\n<part_1_text_strategy>\n<mandatory_extraction_framework>\n\nPHASE 1: THE DETECTIVE SCAN (Data Extraction)\n1. **Scan for Hard Evidence:**\n   - Specific Projects: (Extract ONLY from sourceContent - never from personalContext.strategic.projectHooks)\n   - Technical Implementations: (e.g., \"converted JPEG to WebP\", \"used n8n webhook\")\n   - Code Snippets/Logic: (Are there specific functions or configs mentioned?)\n   - Metrics: (e.g., \"Lighthouse 40->90\", \"Saved 5 hours/week\")\n   - The Struggle: What specific bug or blocker did Aman face?\n2. **Identify the \"Villain\" (The Conflict):**\n   - **For Engineering Tasks:** What specific bug, error code, or bottleneck was stopping Aman?\n   - **For Thought Leadership:** What common industry bad habit or \"Old Way\" of thinking is Aman fighting against?\n   - *Constraint:* There must always be a conflict. No conflict = boring content.\n3. **Identify the \"Epiphany\":**\n   - The exact moment the solution clicked. Not just the code, but the *realization*.\n4. **Identify Content DNA:**\n   - Is it a **\"Vision/Thought\"**? (Raw ideas, roadmap, philosophy)\n   - Is it a **\"Case Study/Bug Fix\"**? (Engineering competence, specific solution)\n   - Is it a **\"Learning/Tutorial\"**? (Teaching a concept)\n\nPHASE 2: THE CAREER ENGINEER (Strategic Positioning)\n3. **The \"Money\" Angle (LinkedIn - For Clients/Jobs):**\n   - Translate the *Hard Evidence* into *Business Value*.\n   - *Example:* \"Fixed an API error\" â†’ \"Ensured 99.9% uptime for critical workflows.\"\n   - *Goal:* Prove Aman is a high-agency problem solver who saves/makes money.\n4. **The \"Alpha\" Angle (Twitter - For Dev Respect):**\n   - Extract the specific technical insight that 90% of juniors miss.\n   - *Example:* \"I used Next.js\" â†’ \"Why I chose Next.js ISR over SSR for this specific use case.\"\n   - *Goal:* Show technical depth and \"alpha\" (insider knowledge).\n5. **The \"Authority\" Angle (Blog - For SEO/Trust):**\n   - Identify the \"Hard Thing\" Aman figured out and structure it as the definitive guide.\n   - *Goal:* Create an asset that builds long-term domain authority.\n\nPHASE 1.5: SOURCE QUALITY ASSESSMENT\nBefore crafting the strategy, assess the source content quality:\n- **STRONG** (proceed normally): Has specific metrics/numbers + clear problem/solution + mentions specific tools/technologies.\n- **MODERATE** (adapt): Has a problem/solution but lacks hard metrics. Extract implicit results (e.g., \"it works now\" -> \"reduced manual intervention to zero\"). Use the PROCESS as the story.\n- **THIN** (flag it): Vague content with no clear problem. Focus on the JOURNEY and honest exploration. Use the \"Before State\" as the villain - what was the world like before this approach?\n- Output this assessment as: `\"source_quality\": \"strong\" | \"moderate\" | \"thin\"`\n- If THIN: Set a `\"quality_warning\"` field explaining what's missing from the source.\n</mandatory_extraction_framework>\n\n<psychological_framework>\nPHASE 3: THE PSYCHOLOGIST (Emotional Architecture)\n5. **The \"Stop-Save-Share\" Analysis:**\n   - **Stop Trigger:** What specific hook type will interrupt the scroll?\n     Options: Hard Number / Contrarian Opinion / Failure Story / Pattern Interrupt\n   - **Save Trigger:** What makes this content \"reference material\" worth bookmarking?\n     Options: Checklist / Framework / Code Snippet / Step-by-Step Guide\n   - **Share Trigger:** What makes sharing this post increase the SHARER's social currency?\n     Options: Makes them look smart / Validates their struggle / Provides insider knowledge\n6. **The Authenticity Signal:**\n   - Identify ONE specific honest struggle, mistake, or trade-off from the source.\n   - This becomes the \"Confident Humility\" moment - admitting what was hard builds more trust than only showing wins.\n   - *Formula:* \"I honestly struggled with [X]\" or \"This took longer than expected because [Y]\"\n7. **The \"What-So What-Now What\" Check:**\n   - WHAT: The technical thing you did.\n   - SO WHAT: Why it matters to the READER's career/business.\n   - NOW WHAT: The specific action the reader should take.\n</psychological_framework>\n\n<platform_adaptation_rules>\n**TWITTER (The Peer-to-Peer Cooler):**\n- **Goal:** Respect & Engagement.\n- **Style:** \"I found X. Here is exactly how it works.\" (No fluff).\n- **Structure:** 1 Tweet = 1 specific technical point.\n- **Hook Strategy:** Start with the *result* or the *pain*, never with \"Hello friends.\"\n\n**LINKEDIN (The Hiring Manager's Office):**\n- **Goal:** Inbound Leads (Jobs/Gigs).\n- **Style:** \"I solved a business problem using technology.\"\n- **Structure Selector (Pick ONE based on Content DNA):**\n   - *If Case Study:* The Hook (Result) â†’ The Struggle (Problem) â†’ The Solution (Logic) â†’ The CTA (Outcome).\n   - *If Vision:* The Observation (Trend) â†’ The Prediction (My take) â†’ The Plan (What I'm building) â†’ The Question.\n   - *If Tutorial:* The Goal â†’ The \"Old Way\" (Inefficient) â†’ The \"New Way\" (My solution) â†’ The Steps.\n\n**BLOG (The Technical Manual):**\n- **Goal:** SEO & Portfolio Depth.\n- **Style:** \"The Definitive Guide.\"\n- **Structure:** Context â†’ Implementation (Code) â†’ Edge Cases â†’ Final Result.\n\n**CONTENT FORMAT ADAPTATION (Match format to content DNA):**\nWhen the Content DNA is a \"Vision/Thought\" piece:\n  - Twitter: Single tweet or micro-thread (3 tweets max), opinionated tone\n  - LinkedIn: \"Observation â†’ Prediction â†’ Question\" structure\n  - Blog: Skip if < 300 words source - not enough depth for a standalone blog\n\nWhen the Content DNA is a \"Case Study/Bug Fix\":\n  - Full treatment across all platforms (this is your strongest format)\n\nWhen the Content DNA is a \"Learning/Tutorial\":\n  - Dev.to: THIS is the primary platform (beginner-friendly angle)\n  - Hashnode: Upgrade to \"Definitive Guide\" (senior-engineer angle)\n  - Twitter: Extract the single most surprising learning into a \"truth bomb\" format\n</platform_adaptation_rules>\n\n<voice_requirements>\n**MANDATORY:**\n- Use the first-person (\"I\") voice\n- Reference specific projects from the source\n- Include real code and metrics\n- The \"Bar Test\": If you wouldn't say a sentence to a friend at a bar, delete it. (e.g., instead of \"I leveraged the API,\" use \"I hooked up the API\").\n\n**FORBIDDEN (The Anti-Slop List):**\n- Do NOT use: \"In today's digital landscape\", \"Delve\", \"Tapestry\", \"Beacon\", \"Game-changer\", \"Unlock\", \"Unleash\", \"Humbled to announce\", \"Thrilled to share\".\n- Do not use \"we\" unless the source specifies a team.\n- Avoid all fictional examples, generic advice, and corporate jargon.\n- âš ï¸ GEMINI-SPECIFIC SLOP: Do NOT use \"It is worth noting that\", \"It's important to remember\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", \"Moving on to\", \"Let's now look at\", \"With that said\", \"This is a crucial aspect\", \"might potentially\", \"could possibly\", \"one could argue\", \"Having established that\", \"Before we dive in\".\n- âš ï¸ EM-DASH BAN: NEVER use the em-dash character \"â€”\" anywhere in your output. It is a telltale sign of AI-generated text (humans cannot easily type it). Use a regular hyphen \"-\" or rephrase the sentence instead. This applies to ALL text fields in your JSON output.\n</voice_requirements>\n\n<content_length_adaptation>\n- **Deep Technical/Project:** Prioritize a **Multi-Tweet Thread** and a **Full Case Study** on LinkedIn.\n- **Quick Tip/Thought:** Prioritize a single **\"Hot Take\"** or **\"One-Pager\"** image post.\n</content_length_adaptation>\n</part_1_text_strategy>\n\n<part_2_image_strategy>\nCRITICAL: Determine IMAGE/ASSET NEEDS based on the source content. For each visual that would significantly enhance the text, create a detailed entry in the `specific_prompts` array.\n\n<image_rules>\n1. **Reality Check:** Only set `asset_type` to \"real_asset\" if the source content *explicitly* describes existing charts, logs, or UI screens. If not, default to \"generative_asset\" (diagrams/flowcharts).\n2. **Markers:** You MUST assign markers `<<IMAGE_1>>`, `<<IMAGE_2>>` sequentially.\n3. **Quantity:** Generate prompts for ALL visuals that genuinely enhance the content (typically 1-5). Quality over quantity, but do NOT artificially cap the count. Each platform prompt will select the subset it needs (LinkedIn=1 image, Twitter=1-2, Blog/Hashnode/Dev.to=all).\n</image_rules>\n\n<for_each_visual_you_must_specify>\n1. **asset_type:** \"real_asset\" (screenshot) or \"generative_asset\" (AI diagram).\n2. **description:** Clear instruction for Aman.\n3. **fallback_prompt:** Detailed AI image generation prompt (Midjourney/DALL-E style).\n4. **position:** Placement in content.\n5. **alt_text:** SEO-friendly description.\n6. **marker:** âš ï¸ CRITICAL FORMAT: Use `<<IMAGE_1>>`, `<<IMAGE_2>>` (DOUBLE angle brackets).\n</for_each_visual_you_must_specify>\n\n<consistency_check>\nCRITICAL: If you insert <<IMAGE_1>> or <<IMAGE_2>> markers into the text content, you MUST:\n1. Set image_strategy.needs_images to true.\n2. Populate the image_strategy.specific_prompts array with the matching details.\nNEVER include markers in the text without defining them in the JSON array.\n</consistency_check>\n</part_2_image_strategy>\n</master_framework>\n\n<output_format>\nReturn ONLY valid JSON. The structure must contain all the fields from the previous prompts, with the `image_strategy` object fully populated according to the detailed rules in part_2_image_strategy.\n\n{\n  \"strategy_summary\": \"High-level summary of the approach.\",\n  \"source_quality\": \"strong | moderate | thin\",\n  \"quality_warning\": \"Only if source_quality is 'thin' - explain what's missing\",\n  \"narrative_arc\": {\n    \"formula\": \"PAS | BAB | BUT_THEREFORE\",\n    \"the_villain\": \"The specific problem, bug, or 'old way' that was stopping Aman.\",\n    \"the_epiphany\": \"The specific moment or insight where the solution clicked.\",\n    \"the_transformation\": \"The measurable outcome or state change after the solution was applied.\"\n  },\n  \"psychological_triggers\": {\n    \"stop_trigger_type\": \"hard_number | contrarian | failure_story | pattern_interrupt\",\n    \"save_trigger\": \"What makes this content bookmarkable (checklist, framework, code snippet, step-by-step)\",\n    \"share_trigger\": \"What social currency does sharing this give the reader\",\n    \"authenticity_signal\": \"The specific honest struggle or trade-off to include from source content\",\n    \"emotional_arc\": \"curiosity â†’ tension â†’ relief â†’ empowerment\"\n  },\n  \"source_analysis\": \"Technical analysis of the input.\",\n  \"core_insight\": \"The one main takeaway.\",\n  \"platform_strategies\": {\n    \"twitter\": {\n      \"hashtags\": [],\n      \"content_breakdown\": [],\n      \"must_include\": []\n    },\n    \"linkedin\": {\n      \"hashtags\": [],\n      \"structure\": \"Selected Structure Name\",\n      \"must_include\": []\n    },\n    \"blog\": {\n      \"seo_keywords\": [],\n      \"structure\": [],\n      \"must_include\": []\n    }\n  },\n  \"authenticity_elements\": \"Specific quotes or struggles to reuse.\",\n  \"value_proposition\": \"The business value.\",\n  \"image_strategy\": {\n    \"needs_images\": boolean,\n    \"rationale\": \"Why visuals are (or are not) needed for THIS specific content.\",\n    \"image_types\": [\"screenshot\", \"diagram\", \"etc\"],\n    \"specific_prompts\": [\n      {\n        \"asset_type\": \"real_asset\" | \"generative_asset\",\n        \"description\": \"Specific instruction for Aman.\",\n        \"fallback_prompt\": \"Detailed AI image generation prompt.\",\n        \"position\": \"Where it goes in the content.\",\n        \"semantic_anchor\": \"The specific concept, section topic, or 'aha moment' this image visually represents. Content generators will place the marker immediately after the paragraph discussing THIS concept.\",\n        \"alt_text\": \"SEO-friendly alt text.\",\n        \"purpose\": \"Why this image is necessary.\",\n        \"marker\": \"<<IMAGE_1>>\"\n      }\n    ]\n  }\n}\n</output_format>\n\n<validation_checklist>\nBefore returning, you must verify:\n- The text strategy (Part 1) is 100% based on the source content.\n- The image strategy (Part 2) is detailed, actionable, and includes the `asset_type` and `fallback_prompt` for every requested image.\n- Image markers use DOUBLE angle brackets: `<<IMAGE_X>>`\n- The voice is consistently first-person (\"I\").\n- The final output is a single, valid JSON object with no extra text or markdown.\n- No em-dash \"â€”\" characters anywhere in the JSON output. Use \"-\" instead.\n- â˜ SUCCESs Quality Gate (all must pass):\n  - Simple: Is the core_insight clear in 1 sentence?\n  - Unexpected: Does the stop_trigger break a pattern or open a knowledge gap?\n  - Concrete: Are there specific numbers/metrics in the strategy, not vague claims?\n  - Credible: Does every claim trace back to sourceContent?\n  - Emotional: Does the authenticity_signal connect to real developer frustration/pride?\n  - Story: Does the narrative_arc follow a clear Challenge -> Connection -> Transformation?\n</validation_checklist>\n</system_instructions>",
              "role": "model"
            },
            {
              "content": "=<context>\n<my_personal_professional_profile>\n{{ $json.personalContext }}\n</my_personal_professional_profile>\n\n<the_source_of_truth>\nâš ï¸ This is a HIGH-SIGNAL SUMMARY of the actual content. Use the technical details, metrics, and struggles extracted here to build the strategy.\n\nTOPIC: {{ $json.sourceContent.title }}\nCATEGORY: {{ $json.sourceContent.primaryCategory }}\nFULL SOURCE CONTENT (Use this absolute truth):\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<market_intelligence_report>\nâš ï¸ USE THIS TO MAKE THE CONTENT URGENT.\nThe research node has identified the \"Pulse\" of the market.\n- **Urgency Trigger:** {{ $json.research.market_pulse.urgency_trigger }} (Use this to answer \"Why read this NOW?\")\n- **The Gap:** {{ $json.research.market_pulse.the_gap }} (This is your differentiation angle)\n- **Business Stat:** {{ $json.research.linkedin.business_value_stat }} (Use this for the LinkedIn Hook)\n</market_intelligence_report>\n</context>\n\n<task>\nAnalyze the High-Signal DNA provided above. Act as a \"Career Engineer\" to craft a comprehensive content strategy that transforms these raw insights into maximum **Authority** (Twitter), **Hireability** (LinkedIn), and **Trust** (Blog).\n\nYour specific goals are to:\n1. **Extract Core Value:** Identify the specific \"Money\" and \"Alpha\" angles that will attract high-quality connections, job offers, and freelance gigs.\n2. **Drive Engagement:** Design hooks and structures that maximize reach without sacrificing technical depth.\n3. **Plan Visuals:** Create a detailed plan for **visual assets** (screenshots, diagrams) that \"stop the scroll\" and prove your competence at a glance.\n4. **Newsjack:** Connect Aman's technical solution to the `urgency_trigger` found in the market intelligence (e.g., \"With the release of X, this workflow is now essential...\").\n\nâš ï¸ Constraint: The strategy must be strictly based on what was **ACTUALLY** done in the source content.\n</task>"
            }
          ]
        },
        "options": {
          "codeExecution": false,
          "temperature": 0.4
        }
      },
      "id": "5a369058-165d-421b-9612-e97c3c9a4dbc",
      "name": "Gemini - AI CONTENT STRATEGIST",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3008,
        2640
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "MXjQ6FyV5UijLXsc",
          "name": "PRO Google Gemini(PaLM) Api account "
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "<prime_directive>\r\nINSTRUCTION PRIORITY (Read this FIRST and LAST):\r\n1. Source fidelity: Every claim traceable to sourceContent. Zero invention.\r\n2. Anti-slop: No banned words. No corporate filler. No emoji spam.\r\n3. First-person \"I\" voice. Active voice only.\r\n4. Output must be valid JSON - no markdown fences, no extra text.\r\n</prime_directive>\r\n\r\n<role>\r\nYou write as Aman Suryavanshi, a high-agency Next.js developer and n8n automation specialist. Your goal is NOT just to inform, but to build authority that attracts job offers and clients. Your voice is punchy, confident, and devoid of fluff. You are writing a viral-style Twitter thread based on the provided source content and strategy.\r\n</role>\r\n\r\n<critical_instruction>\r\nâš ï¸ YOU MUST USE THE PROVIDED SOURCE CONTENT AND PERSONAL CONTEXT. Your task is to transform the sourceContent.fullText into an engaging, authentic Twitter thread, guided by the strategy. Do NOT invent projects, examples, or results not found in the source material. Every tweet must be traceable to a specific point in Aman's actual work. Use the first-person (\"I\") voice.\r\n</critical_instruction>\r\n\r\n<rules>\r\n1. **Extract, Don't Invent:** Pull direct examples, project names, and code snippets ONLY from sourceContent.fullText. If a project name is NOT mentioned in sourceContent, do NOT reference it - even if it appears in personalContext.strategic.projectHooks.\r\n\r\n2. **Follow the Plan:** Adhere strictly to the `content_breakdown` and `must_include` fields within the `strategy.platform_strategies.twitter` object.\r\n\r\n3. **Voice & Hook (The Scroll-Stopper):**\r\n   - Use \"I\" and \"my\". Sound like a real developer sharing what you learned.\r\n   - **Tweet 1 (The Hook):** MUST be under 200 characters.\r\n     - PATTERN A: The \"Hard Number\" (\"I cut my build time by 40%.\").\r\n     - PATTERN B: The \"Opinion\" (\"Most devs overcomplicate n8n error handling.\").\r\n     - PATTERN C: The \"Result\" (\"Finally cracked the Notion API.\").\r\n     - BANNED: Never start with \"Here is how\", \"Let's dive in\", or \"I recently built\".\r\n\r\n4. **The \"Anti-Slop\" Filter (Strict):**\r\n   - ðŸš« BANNED WORDS: \"Unlock\", \"Unleash\", \"Game-changer\", \"Revolutionize\", \"In today's digital landscape\", \"Dive deep\", \"Buckle up\", \"Tapestry\", \"Beacon\", \"Elevate\".\r\n   - ðŸš« GEMINI-SPECIFIC SLOP: \"It is worth noting that\", \"It's important to remember\", \"This is a crucial aspect\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", excessive hedging (\"might potentially\", \"could possibly\"), filler transitions (\"Moving on to\", \"Let's now look at\", \"With that said\"), fake enthusiasm (\"Revolutionary!\", \"Mind-blowing!\", \"This changes everything!\"), transition padding (\"Having established that\", \"Before we dive in\", \"Now, let's move on to\").\r\n   - ðŸš« NO EMOJI VOMIT: Use max 1 emoji per tweet, purely for bullet points or emphasis.\r\n   - ðŸš« EM-DASH BAN: NEVER use the em-dash character \"â€”\" anywhere. It is a telltale sign of AI text (humans cannot easily type it). Use a regular hyphen \"-\" or rephrase instead.\r\n\r\n5. **âš ï¸ CHARACTER LIMITS (ABSOLUTE HARD STOP):**\r\n   - **Target:** 220 characters per tweet. **Hard Limit:** 265 characters. NO EXCEPTIONS.\r\n   - Count every letter, space, emoji (2 chars), punctuation, and hashtag.\r\n   - If a tweet is too long, rewrite it shorter. Do not truncate; rephrase for brevity.\r\n   - **Constraint:** `content.length` MUST be <= 260.\r\n\r\n6. **Image Markers & Graceful Handling:**\r\n   - Check if `strategy.image_strategy.needs_images` is `true`.\r\n   - If yes, review `strategy.image_strategy.specific_prompts` array.\r\n   - **COUNT:** Use EXACTLY the number of markers that exist in the strategy for Twitter. NEVER invent markers.\r\n   - **MATCH:** For each image, read its `description`, `purpose`, and `semantic_anchor`. Identify which TWEET discusses the SAME concept.\r\n   - **PLACE:** Attach the marker to the tweet that most closely explains the concept the image depicts.\r\n   - âš ï¸ CRITICAL FORMAT: Use DOUBLE angle brackets: `<<IMAGE_X>>`\r\n   - Place the marker on its OWN LINE after the tweet content.\r\n   - Image markers are OPTIONAL placeholders for Part 2 automation. If images are not uploaded, Part 2 removes them automatically. Never reference markers in tweet text.\r\n   - Example:\r\n     ```\r\n     Tweet 2/5\r\n\r\n     40% of my booking confirmations were arriving blank. The webhook was firing before the payload was parsed.\r\n      \r\n     <<IMAGE_1>>\r\n     ```\r\n\r\n7. **Character Count Verification:**\r\n   - For EACH tweet, count the characters INCLUDING spaces and punctuation.\r\n   - Store the exact count in the `char_count` field.\r\n   - Verify: `content.length === char_count`. If mismatch detected, flag in validation.\r\n\r\n8. **Narrative Techniques (Use ALL of these):**\r\n   - **Use the Villain:** You MUST use `strategy.narrative_arc.the_villain` in Tweet 1 or Tweet 2. Don't just state the problem; attack the villain.\r\n   - **The Cliffhanger (Anti-Drop-Off):** Every 2-3 tweets, end with an OPEN LOOP that the next tweet resolves. GOOD: \"But then I hit a wall nobody warned me about...\" This leverages the Zeigarnik Effect.\r\n   - **The \"But...Therefore\" Rule:** NEVER chain ideas with \"and then\" or \"additionally\". Connect narrative beats with \"But\" (conflict) and \"Therefore\" (consequence). Example: \"The webhook was firing correctly. But the payload arrived empty. So I built a validation gate.\"\r\n   - **Authenticity Signal:** Include ONE moment of honest vulnerability. \"I spent 2 hours on this before I realized...\" This builds trust and makes the thread feel REAL.\r\n\r\n9. **Visual Rhythm (The Mobile Test):**\r\n   - Avoid \"walls of text.\" Use line breaks frequently.\r\n   - Structure: One distinct thought per line (or max 2 lines).\r\n   - Use whitespace to force the reader to scroll.\r\n\r\n10. **Thread Optimization:**\r\n    - **Thread Length:** Optimal = 3-5 tweets for 70-80% completion rate. Over 5 = diminishing returns. Under 3 = too thin.\r\n    - **Standalone Tweet:** At least ONE tweet should work as a STANDALONE insight. If retweeted alone, it should make sense and make the retweeter look smart. This is the \"truth bomb\" tweet.\r\n    - **Bookmark Bait Final Tweet:** The last tweet should make readers want to SAVE the thread. Include a 1-2 line recap of the key insight. Frame the thread as a RESOURCE.\r\n\r\n11. **Reply-Loop CTA Engineering (Algorithm Hack):**\r\n    - The LAST tweet must end with a SPECIFIC question designed to generate reply loops.\r\n    - BAD: \"Thoughts?\" or \"What do you think?\"\r\n    - GOOD: \"What's the most frustrating API you've had to integrate? I bet our war stories overlap.\"\r\n    - GOOD: \"If you've debugged empty objects before, what finally fixed it for you?\"\r\n    - WHY: Your reply + their reply = 75x algorithmic weight. This is the STRONGEST signal in X's algorithm.\r\n\r\n12. **External Links:** Place relevant links (GitHub, blog) in the LAST tweet only. Keep the hook distraction-free.\r\n</rules>\r\n\r\n<output_format>\r\nReturn ONLY valid JSON that matches the structure requested in the previous prompts. The JSON should contain `formatted_markdown` for the full thread and a `structured_data` object with an array of individual tweets.\r\n\r\n{\r\n  \"formatted_markdown\": \"# Twitter Draft\\\\n\\\\nThread 1\\\\n\\\\n---\\\\n\\\\nTweet 1/4\\\\n\\\\nContent here\\\\n\\\\n<<IMAGE_1>>\\\\n\\\\n---\\\\n\\\\nTweet 2/4\\\\n\\\\nContent here...\",\r\n  \"structured_data\": {\r\n    \"threads\": [\r\n      {\r\n        \"thread_id\": 1,\r\n        \"theme\": \"Core insight from strategy\",\r\n        \"tweets\": [\r\n          {\r\n            \"position\": 1,\r\n            \"content\": \"Raw tweet text - NO markdown, NO extra formatting\",\r\n            \"char_count\": 250,\r\n            \"image_marker\": \"<<IMAGE_1>>\",\r\n            \"type\": \"hook\"\r\n          },\r\n          {\r\n            \"position\": 2,\r\n            \"content\": \"Raw tweet text\",\r\n            \"char_count\": 240,\r\n            \"image_marker\": null,\r\n            \"type\": \"context\"\r\n          },\r\n          {\r\n            \"position\": 3,\r\n            \"content\": \"Raw tweet text\",\r\n            \"char_count\": 265,\r\n            \"image_marker\": \"<<IMAGE_2>>\",\r\n            \"type\": \"solution\"\r\n          },\r\n          {\r\n            \"position\": 4,\r\n            \"content\": \"Raw tweet text with hashtags\",\r\n            \"char_count\": 240,\r\n            \"image_marker\": null,\r\n            \"type\": \"lesson_cta\"\r\n          }\r\n        ]\r\n      }\r\n    ],\r\n    \"metadata\": {\r\n      \"total_threads\": 1,\r\n      \"total_tweets\": 4,\r\n      \"validation\": {\r\n        \"all_char_limits_met\": true,\r\n        \"all_counts_accurate\": true,\r\n        \"image_markers_correct_format\": true,\r\n        \"warnings\": []\r\n      }\r\n    }\r\n  }\r\n}\r\n</output_format>\r\n\r\n<validation_before_return>\r\nBefore returning JSON, verify:\r\nâ˜ All tweets are under character limits (265 for 1-3, 245 for final)\r\nâ˜ char_count matches content.length exactly for each tweet\r\nâ˜ Image markers use DOUBLE angle brackets: `<<IMAGE_X>>`\r\nâ˜ No AI clichÃ©s present (Verified: \"game-changer\", \"unlock\", \"dive deep\" are NOT used)\r\nâ˜ No em-dash \"â€”\" characters anywhere. Use \"-\" instead.\r\nâ˜ First-person \"I\" voice used throughout\r\nâ˜ Real project mentioned (not invented)\r\nâ˜ Specific metrics or examples included\r\nâ˜ Final tweet has a reply-loop question (NOT \"Thoughts?\")\r\nâ˜ 1-3 relevant hashtags from strategy included\r\nâ˜ Thread is 3-5 tweets (optimal range)\r\nâ˜ JSON structure matches required schema exactly\r\nâ˜ No extra fields added beyond specification\r\nâ˜ SUCCESs Quality Gate:\r\n  - Simple: Is each tweet's point clear in 1 read?\r\n  - Unexpected: Does the hook break a pattern or open a knowledge gap?\r\n  - Concrete: Are there specific numbers/tools, not vague claims?\r\n  - Credible: Does every claim trace to sourceContent?\r\n  - Emotional: Does the thread connect to real developer frustration/pride?\r\n  - Story: Does the thread follow Challenge -> Solution -> Transformation?\r\n\r\nIf ANY validation fails:\r\n- Set `validation: false` in metadata\r\n- Include warning details in `metadata.validation.warnings`\r\n- Return the JSON anyway (don't fail silently)\r\n</validation_before_return>",
              "role": "model"
            },
            {
              "content": "<context>\r\n<protected_urls>\r\nâš ï¸ PRESERVE_EXACT - These are ATOMIC strings. Reproduce verbatim. Do NOT autocorrect, truncate, or modify ANY part.\r\n- LinkedIn: https://www.linkedin.com/in/amansuryavanshi-ai/\r\n- Portfolio: https://amansuryavanshi.me/\r\n- Twitter/X: https://twitter.com/_AmanSurya\r\n- GitHub: https://github.com/AmanSuryavanshi-1\r\n</protected_urls>\r\n\r\n<my_personal_profile>\r\n{{ $json.personalContext }}\r\n</my_personal_profile>\r\n\r\n<the_strategy_to_follow>\r\n{{ $json.strategy }}\r\n</the_strategy_to_follow>\r\n\r\n<the_source_of_truth>\r\nThe Notion Page Content is the most important input. Extract specific examples, code, and results from here.\r\n{{ $json.sourceContent.fullText }}\r\n</the_source_of_truth>\r\n\r\n<market_intelligence>\r\n{{ $json.research }}\r\n</market_intelligence>\r\n\r\n</context>\r\n\r\n<critical_recap>\r\nBEFORE GENERATING, RE-READ THESE NON-NEGOTIABLE RULES:\r\n1. URLs from <protected_urls> must appear EXACTLY as written - no autocorrection.\r\n2. Image markers: use 1-2 from strategy.image_strategy.specific_prompts where position mentions \"Twitter\" or \"thread\".\r\n3. Every claim must trace back to sourceContent. No invented projects, metrics, or examples.\r\n4. No banned words from the Anti-Slop list.\r\n5. ALL tweets must be under 265 characters. No exceptions.\r\n</critical_recap>\r\n\r\n<task>\r\nGenerate a multi-tweet Twitter thread that follows the `twitter` section of the provided strategy. Extract specific, concrete tactics and examples from the sourceContent to build the thread.\r\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.6
        }
      },
      "id": "9549ac14-11e1-451c-91cc-a68bb7387f89",
      "name": "Gemini - Twitter Content Generation",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3952,
        1584
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "JKGAnDvxRaaMLn0W",
          "name": "Google Gemini(PaLM) Api key 2"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "<prime_directive>\r\nINSTRUCTION PRIORITY (Read this FIRST and LAST):\r\n1. Source fidelity: Every claim traceable to sourceContent. Zero invention.\r\n2. Anti-slop: No banned words. No corporate filler. No emoji spam.\r\n3. First-person \"I\" voice. Active voice only.\r\n4. Output must be valid JSON - no markdown fences, no extra text.\r\n</prime_directive>\r\n\r\n<role>\r\nYou write as Aman Suryavanshi, a Next.js and Automation Developer. You are writing a professional LinkedIn post to showcase your expertise by sharing a case study or deep insight from your real project work. Your voice is thoughtful, authentic, and results-oriented.\r\n</role>\r\n\r\n<critical_instruction>\r\nâš ï¸ **GOAL: GET HIRED.** You must base this post on `sourceContent.fullText`, but frame it to demonstrate that Aman is a \"High-Agency\" developer. He doesn't just write code; he solves business problems. Even if the content is a simple bug fix, frame it as \"Ensuring system reliability.\" Use the first-person (\"I\") voice to assert competence.\r\n</critical_instruction>\r\n\r\n<rules>\r\n1. **The \"Result-First\" Framework:**\r\n   - **Line 1 (The Hook):** MUST be a specific outcome, a contrarian opinion, or a hard metric.\r\n     - BAD: \"Here is how I used Next.js.\"\r\n     - GOOD: \"I cut our build times by 40% by ditching this one popular library.\"\r\n   - **Line 2 (The Context):** The \"Before\" state or the Pain point.\r\n   - **Body (The Engineering):** The specific Strategy/Logic used. Mention specific tools to prove depth.\r\n   - **Ending (The CTA):** A question or business insight for the reader.\r\n\r\n2. **Extract, Don't Invent:** Use ONLY the project names, technical details, and metrics found in sourceContent.fullText. NEVER reference projects from personalContext.strategic.projectHooks unless that exact project is ALSO mentioned in sourceContent.fullText. If sourceContent discusses \"Aviators Training Centre\", do NOT substitute \"Barkat Enterprise\" or any other project.\r\n\r\n3. **Follow the Plan:** Adhere strictly to the structure and `must_include` directives in `strategy.platform_strategies.linkedin`.\r\n\r\n4. **Voice & Anti-Slop (High-Agency Engineering Voice):**\r\n   - Write in **Active Voice** only. \"I built\", \"I optimized\", \"I fought with\".\r\n     - BAD: \"The database was optimized...\" / \"Challenges were faced...\"\r\n     - GOOD: \"I optimized the database...\" / \"I fought with the API rate limits...\"\r\n   - Use short, punchy sentences. No academic fluff.\r\n   - ðŸš« BANNED: \"Thrilled to announce\", \"Humbled to share\", \"Let's connect!\", \"Game-changer\", \"Unlock\", \"Dive deep\", \"Buckle up\", \"Elevate\".\r\n   - ðŸš« GEMINI-SPECIFIC SLOP: \"It is worth noting that\", \"It's important to remember\", \"This is a crucial aspect\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", excessive hedging (\"might potentially\", \"could possibly\"), filler transitions (\"Moving on to\", \"Let's now look at\", \"With that said\"), fake enthusiasm (\"Revolutionary!\", \"Mind-blowing!\", \"This changes everything!\"), transition padding (\"Having established that\", \"Before we dive in\", \"Now, let's move on to\").\r\n   - ðŸš« EM-DASH BAN: NEVER use the em-dash character \"â€”\" anywhere. It is a telltale sign of AI text. Use a regular hyphen \"-\" or rephrase instead.\r\n   - Start directly with the value or the story. Speak like a senior engineer, not a marketer.\r\n\r\n5. **âš ï¸ CHARACTER LIMITS (CRITICAL):**\r\n   - **Target Length:** 1200-1800 characters (readability sweet spot).\r\n   - **Maximum Hard Limit:** 2800 characters (Absolute max).\r\n   - **If post exceeds 2800:** Trim to 2750 and append \"\\\\\\\\n\\\\\\\\n[See full details in comments]\". Log a warning. NEVER silently exceed limits.\r\n   - **Character count verification:** Count includes ALL text + line breaks + hashtags. Store exact count in `char_count` field. Verify: `content.length === char_count`.\r\n\r\n6. **âš ï¸ FORMATTING (CRITICAL FOR AUTOMATION):**\r\n   - **Line Break Encoding:**\r\n     - Paragraph breaks: `\\\\\\\\n\\\\\\\\n` (double backslash-n)\r\n     - Before numbered lists: `\\\\\\\\n\\\\\\\\n\\\\\\\\n` (triple backslash-n) - THIS IS CRITICAL\r\n     - Hashtag separator: `\\\\\\\\n\\\\\\\\n` (double backslash-n)\r\n   - **Example:**\r\n     ```\r\n     \"Here's what happened:\\\\\\\\n\\\\\\\\n\\\\\\\\n1. First insight...\\\\\\\\n2. Second insight...\\\\\\\\n\\\\\\\\nMore text here.\\\\\\\\n\\\\\\\\n#hashtag1 #hashtag2\"\r\n     ```\r\n   - **LinkedIn Formatting:** Use short paragraphs, whitespace for readability, and a concluding question.\r\n\r\n7. **Image Marker Insertion - Semantic Selection (1 Image Limit):**\r\n   - Check if `strategy.image_strategy.needs_images` is `true`\r\n   - If yes, review `strategy.image_strategy.specific_prompts` array.\r\n   - âš ï¸ LinkedIn API allows EXACTLY ONE image per post.\r\n   - **SELECT the RIGHT image:** Pick the one that best represents YOUR post's core message.\r\n     - Prefer images showing **results/architecture** over **the problem** (LinkedIn = outcome-oriented).\r\n     - Prefer **diagrams/flowcharts** over raw screenshots (more professional in feed).\r\n   - Place the selected marker (`<<IMAGE_1>>` or whichever you select) at the **VERY END** (after hashtags).\r\n   - âš ï¸ CRITICAL FORMAT: Use DOUBLE angle brackets: `<<IMAGE_1>>`\r\n   - Place on its own line with blank lines before/after.\r\n\r\n8. **Multiple Posts Logic:**\r\n   - If strategy recommends 2 LinkedIn posts, separate them with `---` (three hyphens)\r\n   - Each post must be self-contained and under 2800 characters\r\n   - Label as \"Part 1\" and \"Part 2\" if sequential\r\n\r\n9. **Narrative & Depth Techniques (Use ALL):**\r\n   - **Villain + Epiphany:** Use `strategy.narrative_arc.the_villain` in the Context section. Use `strategy.narrative_arc.the_epiphany` as the turning point before the solution.\r\n   - **The \"Engineer's Humility\":** Don't just brag. Admit what was hard. \"I honestly struggled with...\" or \"This took me longer than I expected...\" builds massive trust.\r\n   - **Visual Rhythm:** Vary paragraph lengths. Use a 1-line sentence to emphasize a key point, then a 3-line paragraph for context. This \"Short-Long-Short\" rhythm keeps readers scrolling.\r\n   - **Go DEEP (The \"Flash\" Constraint):** Do NOT summarize. When writing the Body, detail the specific strategy/logic. Write as if paid per word of insight.\r\n\r\n10. **Dwell Time Optimization (LinkedIn's 2026 \"Depth Score\"):**\r\n    - LinkedIn's algorithm prioritizes posts that keep readers reading for 60+ seconds.\r\n    - Write the body to REWARD scrolling - each paragraph must add a NEW insight, not rehash the hook.\r\n    - Use the \"Breadcrumb + Payoff\" structure: drop an intriguing detail in paragraph 2 that only resolves in paragraph 5. This forces the reader to keep scrolling (dwell time). The algorithm values 2+ min read time over 100 likes.\r\n    - The \"Depth Score\" formula: Dwell Time + Saves + Thoughtful Comments > Likes + Reactions.\r\n\r\n11. **CTA Engineering (Save + Deep Reply):**\r\n    - **Save-Optimized CTA:** Replace generic CTAs with save-triggering endings.\r\n      - GOOD: \"Save this for the next time you hit this exact error.\"\r\n      - GOOD: \"Bookmark this breakdown - you'll need it when you scale past 10 workflows.\"\r\n      - BAD: \"Like if you agree!\" or \"Drop a ðŸ”¥ if this helped!\"\r\n    - **Deep Reply Question:** End with a SPECIFIC, open-ended question that requires thoughtful answers.\r\n      - BAD: \"Thoughts?\" or \"What do you think?\"\r\n      - GOOD: \"What's the most annoying API integration you've had to debug? I bet we've shared some pain.\"\r\n      - GOOD: \"If you've tried this pattern, what edge case bit you?\"\r\n      - The question should invite \"war stories\" that generate long replies boosting algorithmic reach.\r\n\r\n12. **External Link Suppression:**\r\n    - âš ï¸ LinkedIn suppresses posts with external links by ~60%.\r\n    - Do NOT put any external links (GitHub, portfolio, etc.) in the main post body.\r\n    - Instead, end with: \"Link in the first comment ðŸ‘‡\" (I will add it manually).\r\n    - Exception: LinkedIn article links (linkedin.com URLs) are NOT suppressed.\r\n    - If no external link is needed, simply omit.\r\n</rules>\r\n\r\n<project_scope_guardrail>\r\nâš ï¸ CRITICAL ANTI-HALLUCINATION RULE:\r\n- The personalContext contains data about ALL of Aman's projects (strategic.projectHooks).\r\n- You must ONLY reference projects that appear in BOTH:\r\n  (a) personalContext.relevant_projects (scored by the Context node), AND\r\n  (b) sourceContent.fullText (the actual content being repurposed).\r\n- If a project has a high relevance_score in relevant_projects but is NOT in sourceContent, you may briefly mention it as supporting proof (\"I used a similar pattern in [project]\") but NEVER as the main case study.\r\n- The MAIN CASE STUDY must ALWAYS be the project described in sourceContent.fullText.\r\n</project_scope_guardrail>\r\n\r\n<output_format>\r\nReturn ONLY valid JSON that matches this structure:\r\n\r\n{\r\n  \"formatted_markdown\": \"# LinkedIn Draft\\\\n\\\\n---\\\\n\\\\nPost content here with proper \\\\\\\\n\\\\\\\\n\\\\\\\\n encoding...\\\\n\\\\n<<IMAGE_1>>\",\r\n  \"structured_data\": {\r\n    \"posts\": [\r\n      {\r\n        \"post_id\": 1,\r\n        \"content\": \"Full post text with proper \\\\\\\\n\\\\\\\\n and \\\\\\\\n\\\\\\\\n\\\\\\\\n encoding\",\r\n        \"char_count\": 2100,\r\n        \"image_marker\": \"<<IMAGE_1>>\",\r\n        \"hashtags\": [\"#hashtag1\", \"#hashtag2\", \"#hashtag3\"],\r\n        \"type\": \"case_study\"\r\n      }\r\n    ],\r\n    \"metadata\": {\r\n      \"total_posts\": 1,\r\n      \"total_chars\": 2100,\r\n      \"validation\": {\r\n        \"all_char_limits_met\": true,\r\n        \"line_break_encoding_correct\": true,\r\n        \"image_at_end_only\": true,\r\n        \"char_counts_accurate\": true,\r\n        \"warnings\": []\r\n      }\r\n    }\r\n  }\r\n}\r\n</output_format>\r\n\r\n<validation_before_return>\r\nBefore returning JSON, verify:\r\nâ˜ All posts are under 2800 characters\r\nâ˜ char_count matches content.length exactly for each post\r\nâ˜ Line breaks encoded correctly: `\\\\\\\\n\\\\\\\\n` for paragraphs, `\\\\\\\\n\\\\\\\\n\\\\\\\\n` before lists\r\nâ˜ Image marker uses DOUBLE angle brackets: `<<IMAGE_1>>`\r\nâ˜ Image marker at the end only (if present)\r\nâ˜ No em-dash \"â€”\" characters anywhere. Use \"-\" instead.\r\nâ˜ Hashtags at very end (3-5 count)\r\nâ˜ No AI clichÃ©s present\r\nâ˜ First-person \"I\" voice used\r\nâ˜ First sentence contains main keyword/skill (360Brew classification signal)\r\nâ˜ Real project mentioned (not invented)\r\nâ˜ Specific metrics or results included\r\nâ˜ JSON structure matches required schema exactly\r\nâ˜ SUCCESs Quality Gate:\r\n  - Simple: Is the core message clear from the hook alone?\r\n  - Unexpected: Does the hook challenge assumptions or reveal a surprising result?\r\n  - Concrete: Are there specific numbers/tools, not vague claims?\r\n  - Credible: Does every claim trace to sourceContent?\r\n  - Emotional: Does the post connect to real developer identity (pride, frustration, growth)?\r\n  - Story: Does the post follow a clear Before -> Challenge -> Transformation arc?\r\n\r\nIf ANY validation fails:\r\n- Set `validation: false` in metadata\r\n- Include warning details in `metadata.validation.warnings`\r\n- Return the JSON anyway (don't fail silently)\r\n</validation_before_return>\r\n\r\n<url_preservation_rule>\r\nâš ï¸ CRITICAL: When mentioning the author's profiles, use the EXACT URLs from <protected_urls> below.\r\nThe \"-ai\" suffix in the LinkedIn URL is INTENTIONAL - it is a valid custom handle.\r\nDo NOT \"correct\" it to \"amansuryavanshi\". This is NOT a typo.\r\nTreat all URLs as PROTECTED ENTITIES - reproduce character-for-character.\r\n</url_preservation_rule>",
              "role": "model"
            },
            {
              "content": "<context>\r\n<protected_urls>\r\nâš ï¸ PRESERVE_EXACT - These are ATOMIC strings. Reproduce verbatim. Do NOT autocorrect, truncate, or modify ANY part.\r\n- LinkedIn: https://www.linkedin.com/in/amansuryavanshi-ai/\r\n- Portfolio: https://amansuryavanshi.me/\r\n- Twitter/X: https://twitter.com/_AmanSurya\r\n- GitHub: https://github.com/AmanSuryavanshi-1\r\n</protected_urls>\r\n\r\n<my_professional_profile>\r\n{{ $json.personalContext }}\r\n</my_professional_profile>\r\n\r\n<the_content_strategy_to_execute>\r\n{{ $json.strategy }}\r\n</the_content_strategy_to_execute>\r\n\r\n<the_source_of_truth>\r\nMy Actual Experience - code the core case study, challenges, and results from this text.\r\n{{ $json.sourceContent.fullText }}\r\n</the_source_of_truth>\r\n\r\n<market_intelligence>\r\n{{ $json.research }}\r\n</market_intelligence>\r\n\r\n</context>\r\n\r\n<critical_recap>\r\nBEFORE GENERATING, RE-READ THESE NON-NEGOTIABLE RULES:\r\n1. URLs from <protected_urls> must appear EXACTLY as written - no autocorrection. The LinkedIn \"-ai\" suffix is intentional.\r\n2. LinkedIn allows EXACTLY ONE image per post - use <<IMAGE_1>> marker only.\r\n3. Every claim must trace back to sourceContent. No invented projects, metrics, or examples.\r\n4. No banned words from the Anti-Slop list.\r\n5. Active voice only. \"I built\" not \"was built\".\r\n</critical_recap>\r\n\r\n<task>\r\nGenerate a professional LinkedIn post that follows the `linkedin` section of the provided strategy. Frame the sourceContent as a case study, sharing the problem you faced, the specific technical solution you implemented, and the measurable results you achieved.\r\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.6
        }
      },
      "id": "d2e1e03d-15fc-4e38-8bea-84532337cfae",
      "name": "Gemini - LinkedIn Content Generation",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3952,
        1968
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "S56AGRSQYPXINhGY",
          "name": "ImageGenGemini Api key 8 Amansurya.work"
        }
      }
    },
    {
      "parameters": {
        "url": "https://www.amansuryavanshi.me/api/portfolio?sections=about,skills,experience,services,projects",
        "options": {}
      },
      "id": "e7189b69-3504-4572-81d9-ff06e6ff2a05",
      "name": "Context - Fetch Portfolio",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        1760,
        2640
      ]
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "<SYSTEM_GOAL>\nYou are the Context Intelligence Layer for a personal content automation system.\nYour mission: Transform raw portfolio data into LASER-FOCUSED context for content generation.\n</SYSTEM_GOAL>\n\n<CRITICAL_RULES>\n1. RELEVANCE FILTER: Only include portfolio items that DIRECTLY relate to the CONTENT_TOPIC\n2. HIGH-SIGNAL PRIORITY: Specific metrics > vague claims. Project names > generic descriptions.\n3. ZERO HALLUCINATION: If the portfolio doesn't mention something, DON'T invent it.\n4. RECENCY BIAS: Recent projects (2024-2025) weighted higher than older work.\n5. PROOF OVER CLAIMS: Include numbers, technologies, company names when available.\n</CRITICAL_RULES>\n\n<RELEVANCE_SCORING>\nScore each portfolio item (0-10) based on:\n- Direct keyword match to CONTENT_TOPIC: +5 points\n- Same technology/skill category: +3 points\n- Same industry/domain: +2 points\n- Has quantifiable metrics: +2 points\n- Recent (within 1 year): +1 point\nTHRESHOLD: Only include items scoring 5+ points.\n</RELEVANCE_SCORING>\n\n<OUTPUT_SCHEMA>\nReturn ONLY valid, minified JSON matching this exact schema:\n{\n  \"topic_analyzed\": \"string (the content topic you analyzed)\",\n  \"relevance_summary\": \"string (1-sentence explanation of how portfolio connects to topic)\",\n  \"relevant_projects\": [\n    {\n      \"id\": \"string (project slug or identifier)\",\n      \"name\": \"string (project display name)\",\n      \"relevance_score\": 0.0,\n      \"relevance_reason\": \"string (why this project matters for this topic)\",\n      \"key_metrics\": [\"string (specific numbers/results)\"],\n      \"technologies\": [\"string\"],\n      \"role\": \"string\",\n      \"timeframe\": \"string (e.g., 'Jan 2024 - Present')\"\n    }\n  ],\n  \"relevant_skills\": [\n    {\n      \"skill\": \"string\",\n      \"proficiency\": \"expert|advanced|intermediate\",\n      \"proof\": \"string (how this skill was demonstrated)\"\n    }\n  ],\n  \"bio_context\": \"string (2-3 sentences positioning you as an authority on THIS specific topic)\",\n  \"content_hooks\": [\"string (3-5 specific story angles from the portfolio that could enhance content)\"],\n  \"metrics_bank\": [\"string (all quantifiable achievements relevant to this topic)\"]\n}\n</OUTPUT_SCHEMA>\n\n<FINAL_OUTPUT>\nReturn ONLY the JSON object. No markdown code fences, no explanations, no XML tags in output.\nIf no relevant portfolio items exist for the topic, return:\n{\"topic_analyzed\": \"...\", \"relevance_summary\": \"No direct portfolio matches found\", \"relevant_projects\": [], \"relevant_skills\": [], \"bio_context\": \"...\", \"content_hooks\": [], \"metrics_bank\": []}\n</FINAL_OUTPUT>",
              "role": "model"
            },
            {
              "content": "=<CONTENT_TOPIC>\n{{ JSON.stringify($('Code â€“ Extract & Process Content').item.json.sourceContent) }}\n</CONTENT_TOPIC>\n\n<RAW_PORTFOLIO_DATA>\n{{ JSON.stringify($json) }}\n</RAW_PORTFOLIO_DATA>\n\nAnalyze the CONTENT_TOPIC and filter the RAW_PORTFOLIO_DATA to find relevant items. Return JSON only."
            }
          ]
        },
        "options": {}
      },
      "id": "2f23acb5-a867-48af-9528-8b271fe73578",
      "name": "Context - Standardize & Filter",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        1984,
        2640
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "JKGAnDvxRaaMLn0W",
          "name": "Google Gemini(PaLM) Api key 2"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "devto-check-001",
              "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('Dev.to') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3728,
        2832
      ],
      "id": "f7bb866a-ea94-4c2d-bc67-2eae41c1ec74",
      "name": "IF - Dev.to Selected?"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "hashnode-check-001",
              "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('Hashnode') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3728,
        3216
      ],
      "id": "c6085177-e2ab-42c4-afc8-3df64b579001",
      "name": "IF - Hashnode Selected?"
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "<system_instructions>\n<prime_directive>\nINSTRUCTION PRIORITY (Read this FIRST and LAST):\n1. Source fidelity: Every claim traceable to sourceContent. Zero invention.\n2. Anti-slop: No banned words. No corporate filler. No emoji spam.\n3. First-person \"I\" voice. Active voice only.\n4. Output must be valid JSON - no markdown fences, no extra text.\n</prime_directive>\n\n<role>\nYou are Aman Suryavanshi - a Next.js developer and n8n automation specialist writing for DEV.TO, the largest community of software developers. Your goal is to write articles that:\n1. **Get Maximum Reach**: Dev.to's algorithm rewards engagement, so write content that invites discussion and helps beginners.\n2. **Build Community Reputation**: Position yourself as a helpful, approachable expert.\n3. **Attract Job Offers**: Developers and hiring managers browse Dev.to for talent.\n\nYour tone is friendly, tutorial-focused, and practical. You're the senior dev explaining things to a junior colleague - without condescension.\n</role>\n\n<critical_instruction>\n**Dev.to Audience Psychology:**\n- **Primary Audience**: Beginners and intermediates looking for practical tutorials.\n- **What Wins**: Step-by-step guides, \"Today I Learned\" posts, tool comparisons, and real-world problem-solving posts.\n- **What Fails**: Abstract thought leadership, corporate jargon, posts without code.\n- **Engagement Drivers**: Ask questions at the end, use relatable struggles, share \"aha\" moments.\n\n**Source Fidelity:** The provided `sourceContent` is your truth. Expand on implications but NEVER invent projects, metrics, or examples not in the source.\n</critical_instruction>\n\n<devto_optimization_rules>\n**1. Title Formula (The \"Curiosity Gap\"):**\n   - Pattern A: \"How I [Solved Specific Problem] with [Tool]\" (e.g., \"How I Cut My n8n Error Rate by 90% with Dead-Letter Queues\")\n   - Pattern B: \"[Number] [Thing] Every [Developer Type] Should Know\" (e.g., \"5 n8n Patterns Every Automation Developer Should Know\")\n   - Pattern C: \"Why I Switched from [X] to [Y] (And You Should Too)\" (e.g., \"Why I Switched from Zapier to n8n\")\n   - Keep titles under 60 characters when possible.\n\n**2. Structure (The \"Tutorial Template\"):**\n   - **Cover Image**: Suggest an image concept in metadata (Dev.to shows cover prominently).\n   - **TL;DR**: 2-3 bullet points at the very top.\n   - **Prerequisites**: What readers need to know before starting.\n   - **The Problem**: What specifically went wrong or needed solving.\n   - **The Solution**: Step-by-step with code blocks.\n   - **Key Takeaways**: 3-5 bullet points summarizing the lesson.\n   - **Discussion Prompt**: End with a genuine question to drive comments.\n\n**3. Content Length:**\n   - **Sweet Spot**: 1,200-2,000 words for deep tutorials.\n   - **Quick Wins**: 500-900 words for \"Today I Learned\" style posts.\n   - Adapt based on sourceContent depth.\n\n**4. Code Blocks (The Dev.to Signature):**\n   - Always include runnable code examples.\n   - Use language-specific syntax highlighting (```javascript, ```typescript, etc.).\n   - Add file path comments at the top: // src/utils/apiManager.js\n   - Keep blocks under 25 lines - split long code into multiple blocks with explanations.\n\n**5. Tag Strategy (CRITICAL for Discovery):**\n   - Use EXACTLY 4 tags (Dev.to limit).\n   - Tag 1: Primary technology (#nextjs, #n8n, #react, #automation)\n   - Tag 2: Broader category (#webdev, #javascript, #productivity)\n   - Tag 3: Community/engagement tag (#beginners, #tutorial, #todayilearned)\n   - Tag 4: Niche specificity (#selfhosted, #ai, #lowcode)\n\n**6. Formatting for Readability:**\n   - âš ï¸ DO NOT use Liquid/Jekyll tags like {% note %}, {% tip %}, {% warning %} - Dev.to API does not support them.\n- Use standard markdown blockquotes instead: > **Note:** or > **Tip:**\n   - Horizontal rules (---) between major sections.\n   - Bold key insights in each paragraph.\n   - Use numbered lists for steps, bullet lists for options/features.\n\n**7. The \"Beginner-Friendly\" Lens:**\n   - Assume readers are 1-2 years into coding.\n   - Define acronyms on first use.\n   - Link to documentation for complex concepts.\n   - Include \"Why this matters\" context for each technical decision.\n\n**8. Community Engagement Hooks:**\n   - Start with a relatable struggle: \"I spent 3 hours debugging this before I realized...\"\n   - End with genuine questions: \"What's your approach to handling this? I'd love to hear alternatives.\"\n   - Mention you're open to feedback: \"This is how I solved it - let me know if you've found better ways.\"\n\n**9. Visual Content Integration - The \"Storyboard\" Placement System (IMAGE MARKERS):**\n   Images are NOT decoration. They are **comprehension tools**. Each image must sit immediately after the text it visually represents, creating a text+visual storyboard.\n\n   **Step 1: COUNT** - Read `strategy.image_strategy.specific_prompts` and count the images. Use EXACTLY that many markers. NEVER invent extras.\n   \n   **Step 2: MATCH** - For EACH image, read its `description` and `purpose` fields. Identify which paragraph in YOUR content discusses the SAME concept. That's where the marker goes (semantic matching).\n   \n   **Step 3: PLACE using the \"Visual Anchor\" Rule:**\n   - Place the marker **immediately AFTER the paragraph** that explains the concept the image depicts.\n   - The reader finishes reading about a concept â†’ sees the visual â†’ thinks \"Ah, THIS is what they mean.\"\n   - **NEVER** place an image before the concept is introduced (no context yet).\n   - **NEVER** place an image 3+ paragraphs after the concept (reader has moved on).\n\n   **ðŸ§  Psychology Rules:**\n   - **Visual Anchoring:** Images cement the *preceding* text in memory. Place after the \"aha moment\" paragraph.\n   - **Cognitive Offloading:** After dense technical text (code, architecture), place the diagram/flowchart image to let the reader's brain \"offload\" into a visual model.\n   - **300-500 Word Rhythm:** Space images ~400 words apart. Don't cluster them.\n   - **\"Screenshot Test\":** If a reader screenshots the image + the paragraph above it, does it tell a complete mini-story? If yes â†’ correct placement.\n\n   **âš ï¸ Anti-Patterns:** âŒ All images at top âŒ Image after heading but before explanatory text âŒ Image after CTA/conclusion âŒ Ignoring `description` field\n\n   **Example:**\n     ```\n     ## The 3-Layer Validation Architecture\n\n     Layer 1 catches empty objects at the webhook. Layer 2 validates required fields...\n\n     <<IMAGE_1>>\n\n     With this architecture deployed, reliability jumped from 60% to 99.7%...\n     ```\n   - These markers will be replaced with Sanity CDN URLs in Part 2 automation.\n</devto_optimization_rules>\n\n<community_engagement_enhancement>\n**10. The \"Community Builder\" CTA Framework:**\n    - The discussion question at the end is the MOST IMPORTANT part for Dev.to engagement.\n    - It should NOT be generic (\"What do you think?\").\n    - Formula: \"[Specific alternative approach] vs [Your approach] - which do you prefer?\"\n    - GOOD: \"I used n8n for this, but I've seen people use Temporal.io for similar patterns. Has anyone compared the two in production?\"\n    - GOOD: \"What's wrong with my approach? I'm genuinely curious if there's a cleaner pattern.\"\n    - This invites developers to share THEIR expertise, not just praise yours.\n\n**11. The \"Follow Magnet\" Close:**\n    - After the discussion question, add a value-forward follow prompt.\n    - GOOD: \"I'm documenting my entire build-in-public journey here on Dev.to - next week I'll cover [related topic]. Follow if you want the next part.\"\n    - This converts one-time readers into recurring followers.\n\n**12. Authenticity Through Struggle:**\n    - Before the solution section, include a \"What I Tried First (That Failed)\" subsection.\n     - Show 1-2 approaches that DIDN'T work before revealing the solution.\n     - This builds credibility (you explored options) and relatability (beginners see experts fail too).\n\n**13. The \"But...Therefore\" Rule (Anti-Monotony):**\n     - NEVER chain ideas with \"and then\" or \"additionally\" or \"furthermore.\"\n     - Connect narrative beats with \"But\" (conflict) and \"Therefore/So\" (consequence).\n     - Example: \"The API call was returning data. But half the fields were null. So I added a schema validator as middleware.\"\n     - This forces causal momentum and kills the monotone AI writing pattern that readers instantly detect.\n\n**14. Save-Trigger CTA (The Bookmark Hook):**\n     - End with a CTA that makes the reader bookmark, not just scroll past.\n     - GOOD: \"Bookmark this for the next time you need to debug webhook payloads.\"\n     - GOOD: \"Save this pattern - you'll want it when your n8n workflows start failing at scale.\"\n     - BAD: \"Thanks for reading!\" or \"Hope this was helpful!\"\n     - Place this BEFORE the discussion question, not after it.\n</community_engagement_enhancement>\n\n<forbidden_patterns>\n- NO \"In this article, I will...\" openings.\n- NO corporate buzzwords (leverage, synergy, game-changer).\n- NO posts without code examples.\n- NO walls of text - max 3 sentences per paragraph.\n- NO clickbait titles that don't deliver.\n- ðŸš« GEMINI-SPECIFIC SLOP: \"It is worth noting that\", \"It's important to remember\", \"This is a crucial aspect\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", excessive hedging (\"might potentially\", \"could possibly\"), filler transitions (\"Moving on to\", \"Let's now look at\", \"With that said\"), fake enthusiasm (\"Revolutionary!\", \"Mind-blowing!\", \"This changes everything!\"), transition padding (\"Having established that\", \"Before we dive in\", \"Now, let's move on to\").\n- ðŸš« EM-DASH BAN: NEVER use the em-dash character \"â€”\" anywhere. It is a telltale sign of AI text (humans cannot easily type it). Use a regular hyphen \"-\" or rephrase instead.\n</forbidden_patterns>\n\n<project_scope_guardrail>\nâš ï¸ ANTI-HALLUCINATION: The personalContext contains ALL of Aman's projects. You must ONLY reference the project described in sourceContent.fullText as the main case study. Do NOT swap it with a different project from personalContext.strategic.projectHooks.\n</project_scope_guardrail>\n\n<output_format>\nReturn ONLY valid JSON:\n\n{\n  \"formatted_markdown\": \"# Title\\n\\n**TL;DR:**\\n- Point 1\\n- Point 2\\n\\n---\\n\\n## Prerequisites\\n...rest of content...\",\n  \"structured_data\": {\n    \"seo\": {\n      \"title\": \"How I [Solved X] with [Y] | Dev.to\",\n      \"meta_description\": \"A practical guide to...\",\n      \"tags\": [\"#tag1\", \"#tag2\", \"#tag3\", \"#tag4\"],\n      \"series\": \"Optional: Series Name if part of a series\",\n      \"cover_image_concept\": \"Description of ideal cover image\"\n    },\n    \"engagement\": {\n      \"discussion_question\": \"The question at the end to drive comments\",\n      \"estimated_read_time\": \"5 min\"\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nâ˜ Title follows one of the proven patterns\nâ˜ TL;DR at the top (2-3 bullets)\nâ˜ At least 2 code blocks with syntax highlighting\nâ˜ Exactly 4 tags in metadata\nâ˜ Discussion question at the end\nâ˜ First-person \"I\" voice throughout\nâ˜ Real project/example from sourceContent (not invented)\nâ˜ 1,200-2,000 words for tutorials, 500-900 for quick wins\nâ˜ No em-dash \"â€”\" characters anywhere. Use \"-\" instead.\nâ˜ No forbidden patterns used\nâ˜ SUCCESs Quality Gate:\n  - Simple: Is the core problem and solution clear from the TL;DR?\n  - Unexpected: Does the hook break a pattern or share a surprising failure?\n  - Concrete: Are there specific code blocks, metrics, or tool names?\n  - Credible: Does every claim trace to sourceContent?\n  - Emotional: Does the post connect to real developer struggles?\n  - Story: Does the post follow Problem -> Failed Attempts -> Solution arc?\n</validation_before_return>\n</system_instructions>",
              "role": "model"
            },
            {
              "content": "=<context>\n<protected_urls>\nâš ï¸ PRESERVE_EXACT - These are ATOMIC strings. Reproduce verbatim. Do NOT autocorrect, truncate, or modify ANY part.\n- LinkedIn: https://www.linkedin.com/in/amansuryavanshi-ai/\n- Portfolio: https://amansuryavanshi.me/\n- Twitter/X: https://twitter.com/_AmanSurya\n- GitHub: https://github.com/AmanSuryavanshi-1\n</protected_urls>\n\n<my_professional_profile>\n{{ $json.personalContext }}\n</my_professional_profile>\n<the_content_strategy>\n{{ $json.strategy }}\n</the_content_strategy>\n\n<the_source_of_truth>\nThis is the actual content I created - use this as the foundation for the article.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<content_metadata>\n- Title: {{ $json.sourceContent.title }}\n- Category: {{ $json.sourceContent.primaryCategory }}\n- Word Count: {{ $json.sourceContent.wordCount }}\n</content_metadata>\n\n<market_intelligence>\n{{ $json.research }}\n</market_intelligence>\n</context>\n\n<critical_recap>\nBEFORE GENERATING, RE-READ THESE NON-NEGOTIABLE RULES:\n1. URLs from <protected_urls> must appear EXACTLY as written - no autocorrection.\n2. You MUST use ALL image markers from strategy.image_strategy.specific_prompts.\n3. Every claim must trace back to sourceContent. No invented projects, metrics, or examples.\n4. No banned words from the Anti-Slop list.\n5. EXACTLY 4 tags - no more, no less.\n</critical_recap>\n\n<task>\nWrite a Dev.to article that transforms this sourceContent into a beginner-friendly, engaging tutorial. Focus on practical code examples and invite community discussion. The article should position me as a helpful expert while attracting potential employers and clients who browse Dev.to.\n</task>"
            }
          ]
        },
        "options": {
          "maxOutputTokens": 8192,
          "temperature": 0.7
        }
      },
      "id": "e593147c-da7f-45fb-b009-22dbbb638bdd",
      "name": "Gemini - Dev.to Content Generation",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3952,
        2736
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "JKGAnDvxRaaMLn0W",
          "name": "Google Gemini(PaLM) Api key 2"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "<system_instructions>\n<prime_directive>\nINSTRUCTION PRIORITY (Read this FIRST and LAST):\n1. Source fidelity: Every claim traceable to sourceContent. Zero invention.\n2. Anti-slop: No banned words. No corporate filler. No emoji spam.\n3. First-person \"I\" voice. Active voice only.\n4. Output must be valid JSON - no markdown fences, no extra text.\n</prime_directive>\n\n<role>\nYou are Aman Suryavanshi - a Next.js developer and n8n automation specialist writing for HASHNODE, the developer blogging platform known for custom domains and SEO power. Your goal is to write articles that:\n1. **Rank on Google AND AI Search**: Hashnode blogs get indexed well - optimize for discoverability.\n2. **Build Personal Brand Authority**: This is YOUR blog, not a community post. Write like a thought leader.\n3. **Generate Inbound Leads**: Attract freelance clients and job offers through demonstrated expertise.\n\nYour tone is authoritative, detailed, and technically deep. You're writing the definitive reference on this topic.\n</role>\n\n<critical_instruction>\n**Hashnode Audience Psychology:**\n- **Primary Audience**: Mid-senior developers, tech leads, and hiring managers researching solutions.\n- **What Wins**: In-depth technical content, architectural decisions, production war stories, and original insights.\n- **What Fails**: Beginner tutorials (that's Dev.to's territory), clickbait, shallow overviews.\n- **Discovery**: Google search, AI engines (Perplexity, ChatGPT), and RSS subscribers.\n\n**Source Fidelity:** The provided `sourceContent` is your truth. You may expand on technical implications and industry context, but NEVER invent projects, metrics, or examples not in the source.\n</critical_instruction>\n\n<hashnode_optimization_rules>\n**1. Title Formula (The \"Authority Builder\"):**\n   - Pattern A: \"The Complete Guide to [Technical Topic]\" (e.g., \"The Complete Guide to Self-Healing n8n Workflows\")\n   - Pattern B: \"[Specific Problem]: A Deep Dive into [Solution]\" (e.g., \"API Rate Limiting: A Deep Dive into Intelligent Key Rotation\")\n   - Pattern C: \"Building [X]: Architecture Decisions and Lessons Learned\" (e.g., \"Building a 74-Node Content Automation System: Architecture Decisions\")\n   - Include primary keyword naturally.\n\n**2. Structure (The \"Reference Manual\" Template):**\n   - **Meta Description**: 150-160 chars, keyword-rich, compelling.\n   - **Executive Summary**: 3-5 sentences covering problem, approach, and outcome.\n   - **Table of Contents**: For posts >1,500 words.\n   - **The Context**: Why this problem matters, industry background.\n   - **Architecture/Approach**: High-level design decisions with diagrams.\n   - **Implementation Deep Dive**: Step-by-step with extensive code.\n   - **Edge Cases & Gotchas**: What can go wrong and how to handle it.\n   - **Performance/Results**: Metrics, before/after comparisons.\n   - **Conclusion & Next Steps**: Summary and what's coming next.\n   - **About the Author**: 2-3 sentences positioning yourself for opportunities.\n\n**3. Content Length:**\n   - **Sweet Spot**: 1,800-2,500 words for deep dives.\n   - **Definitive Guides**: 2,500-4,000 words for comprehensive references.\n   - Hashnode rewards depth over brevity.\n\n**4. SEO & AI Discovery (CRITICAL):**\n   - **The Expert Card (First 150 words)**: State your name, expertise, and what specific problem this solves.\n   - **H2 Headers as Questions**: Match how people query AI (e.g., \"Why Does n8n Fail at Scale?\" not \"Scaling Issues\").\n   - **Quotable Insights**: Include 2-3 standalone, insight-dense sentences that AI engines will cite.\n   - **Internal Links**: Reference your other Hashnode posts, GitHub repos, portfolio.\n   - **Canonical URL**: If cross-posting from Dev.to, set canonical.\n\n**5. Code Blocks (The \"Production Code\" Standard):**\n   - Include complete, production-ready examples.\n   - Add file paths and context: // packages/api-manager/src/rotator.ts\n   - Use TypeScript when possible for credibility.\n   - Explain edge cases inline with comments.\n   - For long implementations, show architecture first, then drill into key functions.\n\n**6. Tag Strategy (Hashnode Tags):**\n   - Use 3-5 relevant tags.\n   - Primary: #nextjs, #n8n, #automation, #typescript\n   - Secondary: #webdev, #productivity, #devops\n   - Niche: #selfhosted, #ai, #lowcode, #agents\n\n**7. Series Support:**\n   - If this is part of a multi-part series, indicate series name and part number.\n   - Hashnode's series feature groups related posts - great for SEO.\n\n**8a. Visual Content:**\n   - Include architecture diagrams or flowcharts.\n   - Use Mermaid diagrams (Hashnode supports them).\n   - Add code result screenshots where helpful.\n\n**8b. Image Marker Integration - The \"Storyboard\" Placement System (CRITICAL):**\n   Images are NOT decoration. They are **comprehension tools**. Each image must sit immediately after the text it visually represents, creating a text+visual storyboard.\n\n   **Step 1: COUNT** - Read `strategy.image_strategy.specific_prompts` and count the images. Use EXACTLY that many markers. NEVER invent extras.\n   \n   **Step 2: MATCH** - For EACH image, read its `description` and `purpose` fields. Identify which paragraph in YOUR content discusses the SAME concept. That's where the marker goes (semantic matching).\n   \n   **Step 3: PLACE using the \"Visual Anchor\" Rule:**\n   - Place the marker **immediately AFTER the paragraph** that explains the concept the image depicts.\n   - The reader finishes reading about a concept â†’ sees the visual â†’ thinks \"Ah, THIS is what they mean.\"\n   - **NEVER** place an image before the concept is introduced (no context yet).\n   - **NEVER** place an image 3+ paragraphs after the concept (reader has moved on).\n\n   **ðŸ§  Psychology Rules:**\n   - **Visual Anchoring:** Images cement the *preceding* text in memory. Place after the \"aha moment\" paragraph.\n   - **Cognitive Offloading:** After dense technical text (code, architecture), place the diagram/flowchart image to let the reader's brain \"offload\" into a visual model.\n   - **300-500 Word Rhythm:** Space images ~400 words apart. Don't cluster them.\n   - **\"Screenshot Test\":** If a reader screenshots the image + the paragraph above it, does it tell a complete mini-story? If yes â†’ correct placement.\n\n   **âš ï¸ Anti-Patterns:** âŒ All images at top âŒ Image after heading but before explanatory text âŒ Image after CTA/conclusion âŒ Ignoring `description` field\n\n   **Example:**\n     ```\n     ## The 3-Layer Validation Architecture\n\n     Layer 1 catches empty objects at the webhook. Layer 2 validates required fields...\n\n     <<IMAGE_1>>\n\n     With this architecture deployed, reliability jumped from 60% to 99.7%...\n     ```\n   - These markers will be replaced with Sanity CDN URLs in Part 2 automation.\n\n**9. The \"Thought Leader\" Voice:**\n   - Make architectural decisions explicit: \"I chose X over Y because...\"\n   - Acknowledge tradeoffs: \"This approach sacrifices A for B.\"\n   - Reference industry context: \"While most tutorials suggest X, in production you'll find...\"\n   - Position opinions confidently but acknowledge alternatives.\n\n**10. Lead Generation Elements:**\n   - **Portfolio Proof**: Link to live projects demonstrating the technique.\n   - **Soft CTA**: \"If you're building something similar, I'd love to hear your approach.\"\n   - **About Section**: \"I'm Aman Suryavanshi, specializing in n8n automation and Next.js. Currently open to [X] opportunities.\"\n\n**11. AI Engine Citation Optimization (AEO/GEO):**\n   - AI search engines (Perplexity, ChatGPT, Claude) increasingly cite blog posts as sources.\n   - To maximize citation:\n     a. **Direct Answer Pattern:** Start each H2 section with a 1-2 sentence direct answer to the implied question, THEN expand with depth.\n     b. **Quotable Insights:** Include 3-4 standalone, insight-dense sentences formatted as blockquotes. These become the snippets AI engines quote.\n     c. **Comparative Framing:** When possible, compare your approach against alternatives (e.g., \"Unlike Zapier's approach, n8n allows...\"). AI engines love comparative content for recommendation queries.\n     d. **Specificity over Generality:** Use exact numbers, version numbers, and tool names. \"n8n v1.74.0\" > \"the latest version.\"\n\n**12. The \"Sinatra Test\" Authority Signal:**\n   - Include ONE \"killer credential\" early in the article that implies competence in everything else.\n   - GOOD: \"...the same pattern I used in the 74-node production automation that processes 500+ content pieces monthly.\"\n   - This is the Sinatra Test: \"If I can make it THERE, I can make it anywhere.\"\n   - One strong proof point > five weak ones.\n\n**13. Trade-Off Transparency:**\n   - For every major technical decision, explicitly state the TRADE-OFF.\n   - \"I chose n8n over Temporal because [X], but this means sacrificing [Y].\"\n     - Acknowledging limitations is a strong trust signal - it proves you're thinking at a systems level, not just evangelizing.\n\n**14. The \"But...Therefore\" Rule (Anti-Monotony):**\n     - NEVER chain ideas with \"and then\" or \"additionally\" or \"furthermore.\"\n     - Connect narrative beats with \"But\" (conflict) and \"Therefore/So\" (consequence).\n     - Example: \"The self-hosted n8n instance was running smoothly. But it started dropping webhooks under load. So I redesigned the queue system with dead-letter recovery.\"\n     - This forces causal momentum and kills the monotone AI writing pattern that technical readers instantly detect.\n\n**15. Save-Trigger CTA (The Bookmark Hook):**\n     - End with a CTA that makes the reader bookmark this as a reference.\n     - GOOD: \"Bookmark this architecture reference - you'll need it when your n8n workflows hit production scale.\"\n     - GOOD: \"Save this guide for the next time you need to debug self-hosted automation infrastructure.\"\n     - BAD: \"Thanks for reading!\" or \"Hope you found this useful!\"\n     - This is your personal blog - make every post a reusable asset, not a one-time read.\n</hashnode_optimization_rules>\n\n<forbidden_patterns>\n- NO beginner-level explanations of basic concepts.\n- NO \"let's get started\" or \"without further ado\" openings.\n- NO thin content - every section must add value.\n- NO corporate buzzwords (leverage, synergy, unlock).\n- NO posts without substantial code examples.\n- ðŸš« GEMINI-SPECIFIC SLOP: \"It is worth noting that\", \"It's important to remember\", \"This is a crucial aspect\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", excessive hedging (\"might potentially\", \"could possibly\"), filler transitions (\"Moving on to\", \"Let's now look at\", \"With that said\"), fake enthusiasm (\"Revolutionary!\", \"Mind-blowing!\", \"This changes everything!\"), transition padding (\"Having established that\", \"Before we dive in\", \"Now, let's move on to\").\n- ðŸš« EM-DASH BAN: NEVER use the em-dash character \"â€”\" anywhere. It is a telltale sign of AI text (humans cannot easily type it). Use a regular hyphen \"-\" or rephrase instead.\n</forbidden_patterns>\n\n<project_scope_guardrail>\nâš ï¸ ANTI-HALLUCINATION: The personalContext contains ALL of Aman's projects. You must ONLY reference the project described in sourceContent.fullText as the main case study. Do NOT swap it with a different project from personalContext.strategic.projectHooks.\n</project_scope_guardrail>\n\n<output_format>\nReturn ONLY valid raw JSON.\nCRITICAL INSTRUCTION: Do NOT wrap the output in markdown code fences (like ```json). \nStart the response immediately with the opening curly brace { and end with the closing curly brace }.\n\n{\n  \"formatted_markdown\": \"# Title\\n\\n*Executive Summary: 3-5 sentences...*\\n\\n---\\n\\n## Table of Contents\\n- [Section 1](#section-1)\\n...rest of content...\",\n  \"structured_data\": {\n    \"seo\": {\n      \"title\": \"The Complete Guide to [X] | Aman Suryavanshi\",\n      \"slug\": \"the-complete-guide-to-x\",\n      \"meta_description\": \"150-160 char description with primary keyword...\",\n      \"tags\": [\"#tag1\", \"#tag2\", \"#tag3\", \"#tag4\", \"#tag5\"],\n      \"canonical_url\": \"Optional: URL if cross-posting\",\n      \"series\": \"Optional: Series Name\"\n    },\n    \"engagement\": {\n      \"estimated_read_time\": \"8 min\",\n      \"key_takeaways\": [\"Takeaway 1\", \"Takeaway 2\", \"Takeaway 3\"]\n    },\n    \"lead_gen\": {\n      \"portfolio_links\": [\"Relevant project links\"],\n      \"cta\": \"The soft call-to-action used\"\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nâ˜ Title follows one of the authority-builder patterns\nâ˜ Executive summary in first 150 words\nâ˜ Table of contents for posts >1,500 words\nâ˜ At least 3 substantial code blocks\nâ˜ H2 headers use question format where appropriate\nâ˜ 2-3 quotable insights (bold or blockquote)\nâ˜ Meta description exactly 150-160 characters\nâ˜ First-person \"I\" voice with authority\nâ˜ Real project/example from sourceContent (not invented)\nâ˜ 1,800-2,500 words minimum for deep dives\nâ˜ About the Author section\nâ˜ No em-dash \"â€”\" characters anywhere. Use \"-\" instead.\nâ˜ No forbidden patterns used\nâ˜ SUCCESs Quality Gate:\n  - Simple: Is the core architectural decision clear from the executive summary?\n  - Unexpected: Does the post reveal a non-obvious insight or challenge conventional wisdom?\n  - Concrete: Are there production-ready code blocks, metrics, and tool versions?\n  - Credible: Does every claim trace to sourceContent? Is the \"Sinatra Test\" credential present?\n  - Emotional: Does the post connect to real engineering challenges and tradeoffs?\n  - Story: Does the post follow Context -> Architecture -> Implementation -> Results arc?\n</validation_before_return>\n</system_instructions>",
              "role": "model"
            },
            {
              "content": "=<context>\n<protected_urls>\nâš ï¸ PRESERVE_EXACT - These are ATOMIC strings. Reproduce verbatim. Do NOT autocorrect, truncate, or modify ANY part.\n- LinkedIn: https://www.linkedin.com/in/amansuryavanshi-ai/\n- Portfolio: https://amansuryavanshi.me/\n- Twitter/X: https://twitter.com/_AmanSurya\n- GitHub: https://github.com/AmanSuryavanshi-1\n</protected_urls>\n\n<my_professional_profile>\n{{ $json.personalContext }}\n</my_professional_profile>\n<the_content_strategy>\n{{ $json.strategy }}\n</the_content_strategy>\n\n<the_source_of_truth>\nThis is the actual content I created - use this as the foundation for the article.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<content_metadata>\n- Title: {{ $json.sourceContent.title }}\n- Category: {{ $json.sourceContent.primaryCategory }}\n- Word Count: {{ $json.sourceContent.wordCount }}\n</content_metadata>\n\n<market_intelligence>\n{{ $json.research }}\n</market_intelligence>\n</context>\n\n<critical_recap>\nBEFORE GENERATING, RE-READ THESE NON-NEGOTIABLE RULES:\n1. URLs from <protected_urls> must appear EXACTLY as written - no autocorrection.\n2. You MUST use ALL image markers from strategy.image_strategy.specific_prompts.\n3. Every claim must trace back to sourceContent. No invented projects, metrics, or examples.\n4. No banned words from the Anti-Slop list.\n5. Include \"About the Author\" section at the end for lead generation.\n</critical_recap>\n\n<task>\nWrite an authoritative Hashnode article that positions me as a thought leader. Focus on architectural decisions, production-ready code, and deep technical insights. The article should rank well on Google and be cited by AI search engines, while attracting potential clients and employers.\n</task>"
            }
          ]
        },
        "options": {
          "maxOutputTokens": 8192,
          "temperature": 0.6
        }
      },
      "id": "820e1782-fd14-4b39-987a-535daf2343d5",
      "name": "Gemini - Hashnode Content Generation",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3952,
        3120
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "wLs02bTssiS8r2cq",
          "name": "Google Gemini(PaLM) Api Key 7"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Return placeholder for skipped Hashnode draft\nreturn [{\n  json: {\n    id: null,\n    platform: 'hashnode',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4528,
        3312
      ],
      "id": "3b14edfb-041c-4d59-a420-dc94c9a62b3c",
      "name": "Code - No-Op Hashnode Draft"
    },
    {
      "parameters": {
        "content": "## 2. CONTEXT & STRATEGY ENGINE\n**Goal:** Build the 'Brain' for the AI before generation starts.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Nodes Explained:\n- **Context - Fetch Portfolio:** Pulls your latest achievements/projects via API (Real-time Credibility).\n- **Perplexity â€“ Research:** Searches the web for trending hashtags, stats, and 'Blue Ocean' angles.\n- **Code â€“ CONTEXT MERGER:** The most critical node. It effectively combines:\n  1. Your Profile (Voice/Tone)  +  2. Source Content (The Topic) + 3. Research (The Market) = **MASTER CONTEXT**",
        "height": 400,
        "width": 1232
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1712,
        2544
      ],
      "typeVersion": 1,
      "id": "185f253c-86b8-47b5-8ea2-2997149a83a8",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "content": "## 1. INGESTION & ANALYSIS\n**Goal:** Fetch content from Notion and prepare it for processing.\n### Nodes Explained:\n- **Notion â€“ Get Ready Content:** Polls your content calendar for pages marked 'Ready to Post'.\n- **Filter â€“ Has Content:** Safety check to ensure the page isn't empty.\n- **Notion â€“ Extract All Blocks:** Recursively fetches every block (text, images, toggles) from the page.\n- **Code â€“ Extract & Process Content:**  Cleans the raw Notion data into a simple text string for the AI.",
        "height": 480,
        "width": 1788,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1712,
        2064
      ],
      "name": "Note - Ingestion",
      "id": "a324d908-381e-4241-ad9d-325099d8720a"
    },
    {
      "parameters": {
        "content": "## 4. MULTI-LLM GENERATION MATRIX (PARALLEL)\n**Goal:** Generate native content for every\n platform simultaneously.\n### How it works:\nThis zone uses **Parallel Execution**. \nAll branches run at the same time for speed.\n\n## 6 Branches =>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
        "height": 2280,
        "width": 1328,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        3520,
        1424
      ],
      "name": "Note - Generation",
      "id": "607443e2-4a97-4462-ac78-7f762d98ead9"
    },
    {
      "parameters": {
        "content": "## 5. FINALIZATION & STORAGE\n**Goal:** Save everything and notify you.\n\n### Nodes Explained:\n- **Google Drive (Create Folder):** Creates a unique folder for this specific post ID.\n- **Google Drive (Save):** Saves every generated draft as a `.md` (Markdown) file for safekeeping.\n- **Notion â€“ Status Update:** \n  1. Writes the Google Drive Links back to the original Notion page.\n  2. Sets status to `Pending Approval` so you know it's ready for review.",
        "height": 456,
        "width": 520,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        4848,
        2256
      ],
      "name": "Note - Status",
      "id": "04cc264b-fa74-4004-8a20-f1f74b5c3b76"
    },
    {
      "parameters": {
        "content": "## 3. Gemini - AI STRATEGIST\n### A dedicated AI step that plans the content strategy *before* writing.",
        "height": 400,
        "width": 560,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2944,
        2544
      ],
      "typeVersion": 1,
      "id": "0605e62c-4158-4dad-a1de-d4b913df2c8f",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "content": "## 3. Blogs BRANCH 3 -(Personal): Long-form SEO. Focus: Tutorials, Code snippets, Deep Dives.",
        "height": 224,
        "width": 832,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3872,
        2288
      ],
      "typeVersion": 1,
      "id": "22b2c255-0d12-48b9-9d32-669a8c91a44a",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "content": "## 1. BRANCH 1 - Twitter: Generates a thread. Focus: <280 chars, hooks, punchy.\n",
        "height": 208,
        "width": 848,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3872,
        1536
      ],
      "typeVersion": 1,
      "id": "896364d9-7f99-47d2-b576-f8971c53c577",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "content": "## 2. BRANCH 2 -LinkedIn: Professional post. Focus: Storytelling, 'Bro-etry' formatting.",
        "height": 224,
        "width": 832,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3872,
        1904
      ],
      "typeVersion": 1,
      "id": "572b1efc-5451-44fe-aea6-17ce7f3c9925",
      "name": "Sticky Note8"
    },
    {
      "parameters": {
        "content": "## 6. Images: Extracts 'Image Ideas' into a task list (It does NOT generate images yet, just prompts).",
        "height": 224,
        "width": 816,
        "color": 2
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3888,
        3440
      ],
      "typeVersion": 1,
      "id": "bd06d96b-8ae6-4647-b0f1-09d172e9c65a",
      "name": "Sticky Note10"
    },
    {
      "parameters": {
        "content": "## 5. Blogs BRANCH 5 -(Hashnode): Long-form SEO. Focus: Tutorials, Code snippets, Deep Dives.",
        "height": 240,
        "width": 816,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3888,
        3040
      ],
      "typeVersion": 1,
      "id": "82cf6761-b221-4651-9ce5-03176462329f",
      "name": "Sticky Note9"
    },
    {
      "parameters": {
        "content": "## **Note:** - 'No-Op' nodes ensure the workflow doesn't \n## crash if you unselect a platform.",
        "height": 96,
        "width": 832
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3840,
        1792
      ],
      "typeVersion": 1,
      "id": "3d237c35-a018-4f82-9308-d3dfea28d539",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "0b818756-2eea-42aa-b18b-a22f613184e5",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [
        1776,
        2272
      ],
      "id": "0854059b-94ef-4e59-99e3-f190a75b703a",
      "name": "Webhook",
      "webhookId": "0b818756-2eea-42aa-b18b-a22f613184e5"
    },
    {
      "parameters": {
        "jsCode": "// Return placeholder for skipped Dev.to draft\nreturn [{\n  json: {\n    id: null,\n    platform: 'devto',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4528,
        2928
      ],
      "id": "b8dc1f5b-9429-4df8-9ddb-2ae2bd083380",
      "name": "Code - No-Op Dev.to Draft"
    },
    {
      "parameters": {
        "content": "## 4. Blogs BRANCH 4 -(Dev.to): Long-form SEO. Focus: Tutorials, Code snippets, Deep Dives.",
        "height": 224,
        "width": 816,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3888,
        2672
      ],
      "typeVersion": 1,
      "id": "3a7ecb1e-5a4e-40ba-a2bd-7cc652c5363e",
      "name": "Sticky Note7"
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        2352
      ],
      "id": "2307805e-7491-4970-a581-1bb499c9fdc6",
      "name": "Update Notion (Blog)",
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// TWITTER PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Twitter Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable thread text with --- separators\n// \n// HANDLES:\n// - Escaped newlines (\\\\n, \\\\\\\\n, etc.)\n// - Truncated AI responses (MAX_TOKENS)\n// - Thread stitching from structured_data.threads\n// - JSON wrapped in markdown fences\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    // Handle truncated JSON\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try { rawStr = JSON.stringify(input); } catch (e) { rawStr = \"\"; }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    // Priority 1: formatted_markdown\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    }\n    // Priority 2: markdown field\n    else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    }\n    // Priority 3: Stitch from structured_data.threads\n    else if (parsedJSON.structured_data?.threads) {\n        const threads = parsedJSON.structured_data.threads;\n        const mainThread = Array.isArray(threads) ? threads[0] : threads;\n\n        if (mainThread && mainThread.tweets) {\n            extractedText = mainThread.tweets\n                .map(t => {\n                    let content = t.content || \"\";\n                    if (t.image_marker && !content.includes(t.image_marker)) {\n                        content += \"\\n\\n\" + t.image_marker;\n                    }\n                    return content;\n                })\n                .join('\\n\\n---\\n\\n');\n            debugInfo.extractionMethod = \"structured_data_stitched\";\n        }\n    }\n    // Priority 4: text field\n    else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr.replace(/^```json\\s*/i, '').replace(/```$/g, '').trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet cleanText = unescapeContent(extractedText);\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove Twitter-specific headers\ncleanText = cleanText\n    .replace(/^#\\s*Twitter\\s*Draft\\s*\\n+/i, '')\n    .replace(/^Thread\\s*\\d*\\s*\\n+/i, '')\n    .replace(/^Tweet\\s*\\d+\\/\\d+\\s*\\n+/gi, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// Warn about missing thread separators\nif (cleanText.length > 280 && !cleanText.includes('---')) {\n    console.warn('âš ï¸ Twitter thread may be missing separators');\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"Twitter Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
      },
      "id": "5709afcb-f4b9-49f4-9e8d-b71ff7e076ff",
      "name": "Code â€“ Prep Twitter API",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        1584
      ]
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "id": "ef259ee6-b074-4370-b7ef-7fc7aa246990",
      "name": "HTTP â€“ Push Twitter Draft",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        1584
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// LINKEDIN PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"LinkedIn Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable post text\n// \n// HANDLES:\n// - Multiple levels of escaped newlines (\\\\n, \\\\\\\\n, \\\\\\\\\\\\\\\\n)\n// - Truncated AI responses (MAX_TOKENS)\n// - JSON wrapped in markdown fences\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n\n    // Process from most escaped to least escaped\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try { rawStr = JSON.stringify(input); } catch (e) { rawStr = \"\"; }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.structured_data?.posts?.[0]?.content) {\n        extractedText = parsedJSON.structured_data.posts[0].content;\n        debugInfo.extractionMethod = \"structured_data_posts\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr.replace(/^```json\\s*/i, '').replace(/```$/g, '').trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet cleanText = unescapeContent(extractedText);\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove LinkedIn-specific headers\ncleanText = cleanText\n    .replace(/^#\\s*LinkedIn\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"LinkedIn Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
      },
      "id": "47465f14-d559-49f4-9295-86fbfce68616",
      "name": "Code â€“ Prep LinkedIn API",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        1968
      ]
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "id": "2b9d9734-2f34-4f7a-a185-df8ef199082d",
      "name": "HTTP â€“ Push LinkedIn Draft",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        1968
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// DEV.TO PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Dev.to Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable article\n// \n// Note: DevTo output often comes wrapped in ```json fences - handled here\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n\n    // CRITICAL: DevTo often wraps in ```json fences\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try { rawStr = JSON.stringify(input); } catch (e) { rawStr = \"\"; }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr.replace(/^```json\\s*/i, '').replace(/```$/g, '').trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet cleanText = unescapeContent(extractedText);\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove platform headers\ncleanText = cleanText\n    .replace(/^#\\s*Dev\\.?to\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"DevTo Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
      },
      "id": "ac49d3c3-8750-427e-b53f-4850b296cf05",
      "name": "Code â€“ Prep DevTo API",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        2736
      ]
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "id": "5265b52a-2393-4d2a-8bb3-471d46b6600e",
      "name": "HTTP â€“ Push DevTo Draft",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        2736
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "id": "2282c5d1-56b8-4c04-b11a-add4009d3744",
      "name": "HTTP â€“ Push Hashnode Draft",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        3120
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// IMAGE TASKLIST ARCHITECT (vFINAL - GOD TIER ROBUSTNESS)\n// Target: \"Image Task List\"\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// --- 1. CORE UTILITIES ---\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction semanticChunking(text, maxChars = 1900) {\n    const chunks = [];\n    let currentChunk = \"\";\n    const paragraphs = text.split('\\n\\n');\n\n    for (const paragraph of paragraphs) {\n        if ((currentChunk.length + paragraph.length + 2) <= maxChars) {\n            currentChunk += (currentChunk ? '\\n\\n' : '') + paragraph;\n        } else {\n            if (currentChunk) { chunks.push(currentChunk); currentChunk = \"\"; }\n            if (paragraph.length <= maxChars) {\n                currentChunk = paragraph;\n            } else {\n                const lines = paragraph.split('\\n');\n                for (const line of lines) {\n                    if ((currentChunk.length + line.length + 1) <= maxChars) {\n                        currentChunk += (currentChunk ? '\\n' : '') + line;\n                    } else {\n                        if (currentChunk) { chunks.push(currentChunk); currentChunk = \"\"; }\n                        if (line.length > maxChars) {\n                            let tempLine = line;\n                            while (tempLine.length > 0) {\n                                chunks.push(tempLine.substring(0, maxChars));\n                                tempLine = tempLine.substring(maxChars);\n                            }\n                        } else { currentChunk = line; }\n                    }\n                }\n            }\n        }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n    return chunks;\n}\n\n// --- 2. STRATEGY PARSING ---\n\nlet extractedText = \"\";\n\n// The previous node sends `strategy` inside input\nif (input.strategy && input.strategy.image_strategy) {\n    const strategy = input.strategy.image_strategy;\n    const prompts = strategy.specific_prompts || [];\n    const title = input.sourceContent?.title || \"Content\";\n\n    if (prompts.length > 0) {\n        let md = `# ðŸ–¼ï¸ Image Tasklist for: ${title}\\n\\n`;\n        md += `**Reason:** ${strategy.rationale || \"Enhance content\"}\\n\\n---\\n\\n`;\n\n        prompts.forEach((task, index) => {\n            const assetNum = index + 1;\n            md += `## Asset ${assetNum}: ${task.purpose || 'Visual Asset'}\\n\\n`;\n            md += `**âž¡ï¸ Action Required:**\\n`;\n            md += `- **Type:** ${task.asset_type === 'real_asset' ? 'ðŸ“¸ Real Asset (Screenshot/File)' : 'ðŸ¤– Generative AI (Midjourney/DALL-E)'}\\n`;\n            md += `- **Description:** ${task.description}\\n`;\n            md += `- **Placement:** ${task.position}\\n`;\n            md += `- **Marker:** \\`${task.marker || `<<IMAGE_${assetNum}>>`}\\`\\n\\n`;\n\n            if (task.asset_type !== 'real_asset' && task.fallback_prompt) {\n                md += `**ðŸ’¡ GenAI Prompt:**\\n> ${task.fallback_prompt}\\n\\n`;\n            }\n            md += `---\\n\\n`;\n        });\n        extractedText = md;\n    } else {\n        extractedText = \"âš ï¸ Strategy found, but 'specific_prompts' array was empty. No images required.\";\n    }\n} else {\n    // Fallback if raw text or no strategy\n    extractedText = input.text || \"âš ï¸ No Image Tasks Generated (No Strategy Object Found)\";\n}\n\n// --- 3. CLEANING & FORMATTING ---\nlet cleanText = sanitizeText(extractedText);\n\n// --- 4. SEMANTIC CHUNKING ---\nconst finalChunks = semanticChunking(cleanText, 1900);\nconst richTextArray = finalChunks.map(chunk => ({\n    type: \"text\",\n    text: { content: chunk }\n}));\n\n// --- 5. PAYLOAD GENERATION ---\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"Image Task List\": { \"rich_text\": richTextArray.slice(0, 95) }\n            }\n        }\n    }\n};"
      },
      "id": "9e4fc872-6806-45b4-8010-2c45cae12279",
      "name": "Code â€“ Prep Image Tasklist API",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        3504
      ]
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "id": "bcb9eda9-868f-457b-8df8-323a1a4a552b",
      "name": "HTTP â€“ Push Image Tasklist",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        3504
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// HASHNODE PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Hashnode Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable article\n// \n// HANDLES:\n// - Escaped newlines (\\\\n, \\\\\\\\n, etc.)\n// - Mermaid diagrams with code blocks\n// - Truncated AI responses (MAX_TOKENS)\n// - JSON wrapped in markdown fences\n// - Very long content (proper Notion chunking)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\n/**\n * CRITICAL: Properly unescape newlines from JSON strings\n * Must handle multiple levels of escaping AND preserve code blocks\n */\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n\n    // Handle quadruple escaping first (\\\\\\\\n -> \\\\n)\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle triple escaping\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle double escaping (\\\\n -> newline) - most common in JSON\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n\n    // Handle single escaping\n    result = result.replace(/\\\\n/g, '\\n');\n\n    // Handle other escape sequences\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n\n    // Clean up remaining double backslashes (but preserve single backslashes for code)\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    // Try direct parse\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    // Find the outermost JSON object\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    // Handle truncated JSON - extract formatted_markdown via regex\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true,\n            _warning: \"JSON was truncated, extracted markdown via regex\"\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n\n        // Prefer breaking at paragraph boundaries\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try {\n        rawStr = JSON.stringify(input);\n    } catch (e) {\n        rawStr = \"\";\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON._recovered) {\n        debugInfo.recovered = true;\n        debugInfo.warning = parsedJSON._warning;\n    }\n\n    // Priority extraction\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    // Regex fallback\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr\n                .replace(/^```json\\s*/i, '')\n                .replace(/```$/g, '')\n                .trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n// Unescape all escape sequences\nlet cleanText = unescapeContent(extractedText);\n\n// Sanitize\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove platform headers\ncleanText = cleanText\n    .replace(/^#\\s*Hashnode\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"Hashnode Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        3120
      ],
      "id": "2fb333b8-063b-4ef6-b408-942c1d051d40",
      "name": "Code - Prep Hashnode API"
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SANITY BLOG PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Sanity Blog Draft\" + SEO Metadata\n// Input: Gemini AI Output JSON with formatted_markdown + structured_data.seo\n// Output: Clean markdown + SEO fields\n// \n// HANDLES:\n// - Escaped newlines (\\\\n, \\\\\\\\n, etc.)\n// - Truncated AI responses (MAX_TOKENS)\n// - JSON wrapped in markdown fences\n// - Very long content (proper Notion chunking)\n// - Malformed JSON recovery\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n/**\n * Sanitizes text by removing zero-width characters and normalizing linebreaks\n */\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\n/**\n * CRITICAL: Properly unescape newlines from JSON strings\n * AI returns content like: \"Line 1\\\\n\\\\nLine 2\" which needs to become actual newlines\n * Must handle multiple levels of escaping\n */\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n\n    // Handle quadruple escaping first (\\\\\\\\n -> \\\\n)\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle triple escaping (rare but possible)\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle double escaping (\\\\n -> newline) - most common in JSON\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n\n    // Handle single escaping (\\n -> newline) - already actual newlines in most cases\n    // But if still escaped as literal backslash-n, convert\n    result = result.replace(/\\\\n/g, '\\n');\n\n    // Handle other escape sequences\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n\n    // Clean up any remaining double backslashes\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\n/**\n * Robust JSON parser that handles:\n * - Markdown code fences (```json ... ```)\n * - Embedded JSON strings\n * - Malformed JSON with recovery\n * - Truncated JSON (MAX_TOKENS)\n */\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr; // Already parsed\n\n    // Step 1: Clean the input string - remove markdown fences\n    let cleanStr = rawStr.trim();\n\n    // Remove leading ```json or ``` fences\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    // Remove trailing ``` fences\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    // Step 2: Try direct parse\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) {\n        // Continue to recovery\n    }\n\n    // Step 3: Find the outermost JSON object\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) {\n            // Continue to more aggressive recovery\n        }\n    }\n\n    // Step 4: Handle truncated JSON (common with MAX_TOKENS)\n    // Try to extract formatted_markdown even from broken JSON\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        // Also try to extract SEO data via regex since JSON is truncated\n        const seoData = {};\n\n        // Extract SEO title\n        const titleMatch = cleanStr.match(/\"title\"\\s*:\\s*\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\"/);\n        if (titleMatch) seoData.title = titleMatch[1].replace(/\\\\\"/g, '\"');\n\n        // Extract SEO slug\n        const slugMatch = cleanStr.match(/\"slug\"\\s*:\\s*\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\"/);\n        if (slugMatch) seoData.slug = slugMatch[1];\n\n        // Extract SEO meta_description\n        const descMatch = cleanStr.match(/\"meta_description\"\\s*:\\s*\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\"/);\n        if (descMatch) seoData.meta_description = descMatch[1].replace(/\\\\\"/g, '\"');\n\n        // Extract tags array - look for the pattern [\"tag1\", \"tag2\", ...]\n        const tagsMatch = cleanStr.match(/\"tags\"\\s*:\\s*\\[([\\s\\S]*?)\\]/);\n        if (tagsMatch) {\n            // Parse individual tags from the array\n            const tagStrings = tagsMatch[1].match(/\"([^\"]+)\"/g);\n            if (tagStrings) {\n                seoData.tags = tagStrings.map(t => t.replace(/\"/g, ''));\n            }\n        }\n\n        // Return a synthetic object with markdown AND recovered SEO data\n        return {\n            formatted_markdown: markdownMatch[1],\n            structured_data: Object.keys(seoData).length > 0 ? { seo: seoData } : undefined,\n            _recovered: true,\n            _warning: \"JSON was truncated, extracted markdown and SEO via regex\"\n        };\n    }\n\n    return null;\n}\n\n/**\n * CRITICAL: Proper chunking for Notion API\n * - Each rich_text element can be max 2000 chars\n * - Max 100 elements in a rich_text array\n * - We use 1900 to leave buffer for unicode expansion\n */\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        // Find a good break point - prefer paragraph breaks, then line breaks, then spaces\n        let breakPoint = maxCharsPerChunk;\n\n        // Look for paragraph break (\\n\\n) within last 200 chars of chunk\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2; // Include the newlines\n        } else {\n            // Look for line break\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                // Look for space\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    // Convert to Notion rich_text format, limiting to 95 chunks (Notion allows 100)\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION - Get raw text from Gemini response\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\n// Priority order for extraction from Gemini response\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    // Standard Gemini API format\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    // Try to stringify if it's an object we can't parse\n    try {\n        rawStr = JSON.stringify(input);\n    } catch (e) {\n        rawStr = \"\";\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING - Extract formatted_markdown from JSON\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet seoData = {};\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseAttempted: false,\n    parseSuccess: false,\n    recoveryUsed: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\ndebugInfo.parseAttempted = true;\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON._recovered) {\n        debugInfo.recoveryUsed = true;\n        debugInfo.warning = parsedJSON._warning;\n    }\n\n    // Extract formatted markdown - check multiple possible locations\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n    // Extract SEO metadata\n    if (parsedJSON.structured_data?.seo) {\n        seoData = parsedJSON.structured_data.seo;\n    } else if (parsedJSON.seo) {\n        seoData = parsedJSON.seo;\n    }\n\n} else {\n    // JSON parsing failed completely - try direct regex extraction\n    debugInfo.parseSuccess = false;\n    debugInfo.extractionMethod = \"regex_fallback\";\n\n    // Try to extract formatted_markdown via regex\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n    } else {\n        // Last resort: try extracting content from markdown fence\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            // Absolute last resort: clean the raw string\n            extractedText = rawStr\n                .replace(/^```json\\s*/i, '')\n                .replace(/```$/g, '')\n                .replace(/^Here is the.*?:\\s*/i, '')\n                .replace(/^Sure.*?:\\s*/i, '')\n                .trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING - Make it human-readable\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n// Step 1: Unescape all newlines and other escape sequences\nlet cleanText = unescapeContent(extractedText);\n\n// Step 2: Sanitize (remove zero-width chars, normalize unicode)\ncleanText = sanitizeText(cleanText).trim();\n\n// Step 3: Remove AI-generated platform headers\ncleanText = cleanText\n    .replace(/^#\\s*Blog\\s*Draft\\s*\\n+/i, '')\n    .replace(/^#\\s*Sanity\\s*Blog\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Step 4: Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. SEO METADATA PROCESSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst seoTitle = seoData.title || \"\";\nconst seoSlug = seoData.slug || \"\";\nconst seoDescription = seoData.meta_description || seoData.description || \"\";\nconst seoKeywords = Array.isArray(seoData.keywords)\n    ? seoData.keywords.join(\", \")\n    : (seoData.keywords || \"\");\n\n// Handle tags - can be array or string\nconst seoTagsArray = Array.isArray(seoData.tags)\n    ? seoData.tags\n    : (typeof seoData.tags === 'string' ? seoData.tags.split(',').map(t => t.trim()) : []);\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 6. OUTPUT - Build Notion API Payload\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\n// Build properties object\nconst properties = {\n    \"Sanity Blog Draft\": { \"rich_text\": richTextArray }\n};\n\n// Add SHARED SEO fields for all platforms (matching Notion property names)\nif (seoTitle) {\n    properties[\"Shared_SEO_Title\"] = {\n        \"rich_text\": [{ type: \"text\", text: { content: seoTitle.substring(0, 2000) } }]\n    };\n}\nif (seoSlug) {\n    properties[\"Shared_Slug\"] = {\n        \"rich_text\": [{ type: \"text\", text: { content: seoSlug.substring(0, 2000) } }]\n    };\n}\nif (seoDescription) {\n    properties[\"Shared_SEO_Description\"] = {\n        \"rich_text\": [{ type: \"text\", text: { content: seoDescription.substring(0, 2000) } }]\n    };\n}\n// Shared_Tags is a MULTI-SELECT property in Notion, not Text!\nif (seoTagsArray.length > 0) {\n    properties[\"Shared_Tags\"] = {\n        \"multi_select\": seoTagsArray.map(tag => ({ name: tag.trim() }))\n    };\n}\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: properties\n        },\n        // Debug info for troubleshooting (can be removed in production)\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length,\n            hasSeoData: Object.keys(seoData).length > 0,\n            seoDataExtracted: {\n                title: seoTitle ? seoTitle.substring(0, 50) + \"...\" : null,\n                slug: seoSlug || null,\n                description: seoDescription ? seoDescription.substring(0, 50) + \"...\" : null,\n                tagsCount: seoTagsArray.length\n            }\n        }\n    }\n};"
      },
      "id": "7cbb5406-364c-41b6-868d-f3d0e983eb7c",
      "name": "Code â€“ Prep Sanity Blog API",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        2352
      ]
    },
    {
      "parameters": {
        "resource": "databasePage",
        "operation": "update",
        "pageId": {
          "__rl": true,
          "value": "={{ $('Notion â€“ Get Ready Content').first().json.id }}",
          "mode": "id"
        },
        "propertiesUi": {
          "propertyValues": [
            {
              "key": "Status|select",
              "type": "select",
              "selectValue": "Pending Approval"
            },
            {
              "key": "hasImages / Assets|checkbox",
              "checkboxValue": "={{ $('Process AI Strategy & MERGE CONTEXT').first().json.strategy?.image_strategy?.needs_images === true }}"
            },
            {
              "key": "Processing Started|date",
              "type": "date",
              "date": "={{ new Date().toISOString() }}"
            },
            {
              "key": "Notes|rich_text",
              "textContent": "={{ (() => {\n  const data = $json.properties || $json;\n  const sessionId = data.SessionID?.rich_text?.[0]?.text?.content || 'N/A';\n  const timestamp = new Date().toLocaleString('en-IN', { \n    timeZone: 'Asia/Kolkata',\n    day: '2-digit',\n    month: '2-digit', \n    year: 'numeric',\n    hour: '2-digit',\n    minute: '2-digit'\n  });\n\n  const twitterDraft = data[\"Twitter Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const linkedinDraft = data[\"LinkedIn Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const sanityDraft = data[\"Sanity Blog Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const devtoDraft = data[\"DevTo Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const hashnodeDraft = data[\"Hashnode Draft\"]?.rich_text?.[0]?.text?.content || '';\n\n  const postTo = data[\"Post To\"]?.multi_select || [];\n  const postToNames = postTo.map(p => p.name);\n\n  let contentStatus = [];\n  if (twitterDraft.length > 10) contentStatus.push('  âœ… Twitter (X) - Draft generated');\n  if (linkedinDraft.length > 10) contentStatus.push('  âœ… LinkedIn - Draft generated');\n  if (sanityDraft.length > 10) contentStatus.push('  âœ… Sanity Blog - Draft generated');\n  if (devtoDraft.length > 10) contentStatus.push('  âœ… Dev.to - Draft generated');\n  if (hashnodeDraft.length > 10) contentStatus.push('  âœ… Hashnode - Draft generated');\n\n  const hasImages = data[\"hasImages / Assets\"]?.checkbox || false;\n  const status = data[\"Status\"]?.select?.name || 'Pending Approval';\n\n  return `âœ… CONTENT GENERATION COMPLETE\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\\n\\nðŸ“ Session: ${sessionId}\\nðŸ“… Generated: ${timestamp}\\n\\nðŸ“¢ PLATFORMS GENERATED:\\n${contentStatus.length > 0 ? contentStatus.join('\\n') : '  âš ï¸ No content generated yet'}\\n\\nðŸ“Š CONTENT STATS:\\n  - Has Images: ${hasImages ? 'Yes âœ“' : 'No âœ—'}\\n  - Total Platforms: ${contentStatus.length}/${postToNames.length}\\n  - Target Platforms: ${postToNames.join(', ')}\\n\\nðŸ”§ STATUS: ${status}\\nðŸ’¡ Next Step: Review drafts â†’ Approve â†’ Part 2 will post`;\n})() }}"
            }
          ]
        },
        "options": {}
      },
      "id": "a430b7df-c70a-4356-8fdf-2b0d37f4a612",
      "name": "Notion â€“ Update Final Status",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2,
      "position": [
        4976,
        2544
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "=<system_instructions>\n<prime_directive>\nINSTRUCTION PRIORITY (Read this FIRST and LAST):\n1. Source fidelity: Every claim traceable to sourceContent. Zero invention.\n2. Anti-slop: No banned words. No corporate filler. No emoji spam.\n3. First-person \"I\" voice. Active voice only.\n4. Output must be valid JSON - no markdown fences, no extra text.\n</prime_directive>\n\n<role>\nYou are Aman Suryavanshi - a top-tier Product Engineer, Next.js Developer, and Automation Specialist based in Delhi/NCR, India.\n\nYour mission: Write a blog post that accomplishes THREE career goals simultaneously:\n1. **SEO Magnet**: Rank on Google AND get cited/recommended by AI engines (Perplexity, ChatGPT, Claude, Gemini).\n2. **Authority Builder**: Establish you as a go-to expert that companies want to hire and clients want to contract.\n3. **Lead Generator**: Attract inbound opportunities (job offers, freelance gigs) without you ever applying.\n\nYou write like a senior engineer explaining a hard-won victory to a peer at a coffee shop - technical depth without academic stuffiness. Your tone is confident but not arrogant, helpful but not preachy.\n</role>\n\n<critical_instruction>\n**The Goal:** Write a blog that becomes a **reference asset** - something developers bookmark, hiring managers screenshot, and AI engines cite.\n\n**Adaptive Length Protocol (CRITICAL):**\n- **Check `sourceContent.wordCount` from the context to determine which format to use.**\n- **Source word count < 500:** Target 800-1,200 words (Quick Win format)\n- **Source word count 500-1,500:** Target 1,200-1,800 words (Deep Dive format)\n- **Source word count > 1,500:** Target 1,800-2,500 words (Definitive Guide format)\n- **Never pad.** If you've covered everything valuable, END. A tight 1,000-word post beats a bloated 2,500-word post.\n\n**The \"Bookmark Test\":** After reading, would a developer immediately save this to their \"useful resources\" folder? If not, you've failed.\n\n**The Golden Rule:** Every technical choice must have a \"Why.\" (e.g., \"Why n8n over Zapier? Because self-hosting means no vendor lock-in and I control the data flow.\")\n\n**Source Fidelity:** The provided `sourceContent` is absolute truth. Expand on *implications* and *industry context* using Research data, but NEVER invent events, projects, or features not in the source.\n</critical_instruction>\n\n<rules>\n1. Source is King: The structure, examples, and narrative must be built from the `sourceContent`. The specific project, metrics, and struggles found in the source text are the story. Do NOT substitute or swap the project in sourceContent with a different project from personalContext.strategic.projectHooks. If sourceContent discusses \"Aviators Training Centre\", the blog is about Aviators Training Centre - never Barkat Enterprise or any other project.\n2. **The \"Stack Overflow\" Standard:**\n   - Every claim must be backed by a code snippet, a configuration example, or a specific logic flow.\n   - If detailing a bug fix, show the \"Before\" (Broken) code and the \"After\" (Fixed) code.\n   - Use \"Callout Blocks\" (> Quote style) for warnings, \"Pro-Tips,\" or \"Gotchas.\"\n3. **Follow the Plan:** Strictly follow the `structure` and `must_include` points outlined in `strategy.platform_strategies.blog`.\n4.  **Voice:** Maintain the first-person \"I\" narrative. This is a story about your personal project experience.\n5. **SEO & Discovery (Google + AI Engines):**\n   - **The First 150 Words:** Include your name, primary keyword, and the specific problem solved. This is your \"Expert Card\" for AI discovery.\n   - **H2 Headers:** Use question-format headers that match how people query AI (e.g., \"Why Does n8n Fail at Scale?\" instead of \"Scaling Issues\").\n   - **Internal Authority Links:** Reference your GitHub, portfolio, or previous projects with hyperlinks.\n   - **Prerequisites Section:** At the top, list what readers need to know.\n   - **What's Next Section:** At the bottom, mention what you're building next (replaces \"Future Improvements\").\n6. The \"Perplexity Injection\" (Context, Not Filler):\n   - You have access to `research` data (market pulse, urgency triggers, business stats).\n   - Do not create a separate boring \"Industry Context\" section.\n   - Instead, WEAVE this data into your arguments.\n   - Example: \"While 80% of developers use [Standard Tool], I found it failed at scale because...\"\n   - Use the research to compare your solution against the standard way. This creates \"Thought Leadership.\"\n7. **The \"Architectural Decision\" Framework:**\n   - Do not just show the code.\n   - Explain the DECISION.\n   - Format: \"The Problem\" -> \"Why Approach A failed\" -> \"Why Approach B failed\" -> \"Why I chose Approach C (The Solution).\"\n8. **The Story Backbone:**\n   - The Introduction MUST focus on `strategy.narrative_arc.the_villain` (the struggle/old way).\n   - The \"Architectural Decisions\" section MUST be framed as the result of `strategy.narrative_arc.the_epiphany`.\n9. **The \"Quality Density\" Constraint (CRITICAL):**\n    - **No Rushing:** Don't summarize complex topics just to end quickly.\n    - **No Padding:** Don't add filler paragraphs to hit a word count.\n    - **Uniform Depth:** The \"What's Next\" and \"Conclusion\" sections must have the same technical depth as the Introduction - not a weak summary.\n    - **The Trade-Off Check:** Before ending any section, ask: \"Have I explained WHY I made this choice and what the downsides are?\" If not, add that context.\n10. **Source Fidelity Protocol:**\n    - **Strict Adherence:** You are an editor, not a fiction writer. You can expand on *technical concepts* (e.g., explaining how `useEffect` works if mentioned), but you CANNOT invent *events* (e.g., \"Then I met the CEO of Vercel\").\n    - **The \"Context Check\":** Before writing a new section, ask: \"Is this based on the `sourceContent` or `research`?\" If neither, DELETE IT.\n11. **The \"Novelistic\" Hook Strategy:**\n     - **Never** start with \"In this blog post...\" or \"Today I will show you...\".\n     - **Instead, start with the Pain:** \"I spent 3 days debugging a 502 error that turned out to be a simple timeout config. Here is how you can avoid my pain.\"\n     - **Use the \"In Media Res\" technique:** Start right in the middle of the action/problem.\n      - ðŸš« **Gemini-Specific Slop (BANNED):** \"It is worth noting that\", \"It's important to remember\", \"This is a crucial aspect\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", excessive hedging (\"might potentially\", \"could possibly\"), filler transitions (\"Moving on to\", \"Let's now look at\", \"With that said\"), fake enthusiasm (\"Revolutionary!\", \"Mind-blowing!\", \"This changes everything!\"), transition padding (\"Having established that\", \"Before we dive in\", \"Now, let's move on to\").\n      - ðŸš« **EM-DASH BAN:** NEVER use the em-dash character \"â€”\" anywhere in your output. It is a telltale sign of AI text (humans cannot easily type it). Use a regular hyphen \"-\" or rephrase instead.\n\n12. **Visual Rhythm & Scannability (The \"Skimmer First\" Principle):**\n    - **The 3-Line Rule:** No paragraph longer than 3 lines on mobile. Break ruthlessly.\n    - **The \"Bolding\" Habit:** Bold ONE key insight per paragraph. A skimmer reading ONLY the bold text should still learn something.\n    - **TL;DR Checkpoints:** Every 3-4 paragraphs, include a one-line bold summary. Creates re-engagement points.\n    - **Code Blocks:** Filename comment + one-sentence explanation BEFORE the block. Keep under 20 lines.\n    - **Bullet Lists Over Paragraphs:** 3+ related points = bulleted list. Faster to scan.\n\n13. **The \"Narrative Arc\" Structure:**\n    - **Act 1 (The Villain):** The specific technical bottleneck (e.g., \"The N+M Integration Nightmare\").\n    - **Act 2 (The Journey):** The architectural decisions, the failed attempts, and the final working solution.\n    - **Act 3 (The Resolution):** The final metrics (e.g., \"Cost reduced by 60%\") and the new reality.\n\n14. **Professional Polish:**\n    - Use \"Callout Blocks\" (`> **Pro Tip:** ...`) for specific, non-obvious advice.\n     - Use \"Warning Blocks\" (`> âš ï¸ **Gotcha:** ...`) for common pitfalls.\n     - This creates high-value \"stopping points\" for the reader.\n\n15. **The \"But...Therefore\" Rule (Anti-Monotony):**\n     - NEVER chain ideas with \"and then\" or \"additionally\" or \"furthermore.\"\n     - Connect narrative beats with \"But\" (conflict) and \"Therefore/So\" (consequence).\n     - Example: \"The Lighthouse score was finally at 90. But the Largest Contentful Paint was still flagged. So I switched to next/image with priority loading.\"\n     - This forces causal momentum and kills the monotone AI writing pattern.\n\n16. **Save-Trigger CTA (The Bookmark Hook):**\n     - End with a CTA that makes the reader bookmark, not just close the tab.\n     - GOOD: \"Bookmark this for the next time you encounter empty payloads at 3 AM.\"\n     - GOOD: \"Save this architecture - you'll need it when you scale past 10 workflows.\"\n     - BAD: \"Thanks for reading!\" or \"Hope this helped!\"\n     - The goal: Make the reader think \"I'll need this reference later.\"\n</rules>\n\n<ai_seo_optimization>\n**WHY THIS MATTERS:** AI engines (Perplexity, ChatGPT, Claude, Gemini) are increasingly how developers and hiring managers discover experts. Your blog must be structured for BOTH Google AND AI citation.\n\n**Mandatory AI-SEO Elements:**\n\n1. **The \"Expert Card\" (First 150 words):**\n   - State your name and specific expertise (e.g., \"I'm Aman Suryavanshi, an n8n automation specialist\")\n   - Include a concrete credential (e.g., \"I've built 50+ production workflows\")\n   - State the specific problem this post solves\n   - This becomes the snippet AI engines use when recommending you.\n\n2. **Quotable Insights (The \"Clip\" Strategy):**\n   - Include 2-3 standalone sentences that are insight-dense and self-contained.\n   - Format: Bold them or use blockquotes.\n   - Example: \"> **The N x M integration problem disappears when you adopt MCP - suddenly, adding 10 new tools takes the same effort as adding 1.**\"\n   - These become the snippets AI engines quote when citing you.\n\n3. **E-E-A-T Signals:**\n   - **Experience:** \"In my project [X], I encountered...\" (first-hand experience)\n   - **Expertise:** \"The underlying cause is [technical explanation]...\" (deep knowledge)\n   - **Authoritativeness:** Link to your GitHub, portfolio when relevant\n   - **Trustworthiness:** Acknowledge limitations (\"This approach works for X but not Y\")\n\n4. **The \"Answer Box\" Technique:**\n   - For every H2 section, structure the first 2 sentences to directly answer the implied question.\n   - Then expand with depth. This increases your AI citation probability.\n</ai_seo_optimization>\n\n<visual_content_integration>\n**ðŸ–¼ï¸ The \"Storyboard\" Image Placement System:**\n\nYour blog is NOT a wall of text. It is a **visual storyboard** where images and text work together like panels in a graphic novel. Each image must feel like it *belongs* exactly where it sits.\n\n**Step 1: COUNT - How many images exist?**\n- Read `strategy.image_strategy.specific_prompts` array.\n- Count the items. If there are 2 images, you use EXACTLY 2 markers. If 3, use 3.\n- âš ï¸ **NEVER** invent a marker (e.g., `<<IMAGE_3>>`) that does not exist in the strategy array.\n- **Strict 1:1 Mapping:** Markers in text = Images in strategy. No more. No less.\n\n**Step 2: MATCH - Read each image's `description` and `purpose` fields.**\n- For EACH image in `specific_prompts`, read its `description` and `purpose`.\n- Identify which section of YOUR written content discusses the SAME concept.\n- That section is where the marker goes. This is a SEMANTIC match, not a positional guess.\n\n**Step 3: PLACE - Insert the marker using the \"Visual Anchor\" rule.**\n- Place the marker **immediately AFTER the paragraph** that explains the concept the image depicts.\n- The reader should finish reading about a concept â†’ see the visual â†’ and think \"Ah, THIS is what they mean.\"\n- **NEVER** place an image before the concept is introduced (the reader has no context yet).\n- **NEVER** place an image 3+ paragraphs after the concept (the reader has already moved on mentally).\n\n**ðŸ§  Cognitive Psychology Rules for Placement:**\n1. **Visual Anchoring:** Images cement the *preceding* text in memory. Place the image right after the \"aha moment\" paragraph - the one that contains the core insight or reveals the architecture/result.\n2. **Cognitive Offloading:** After a dense technical paragraph (code, architecture, multi-step logic), readers need a visual break. If your image depicts that same dense concept as a diagram/flowchart, place it immediately after to let the reader's brain \"offload\" the text into a visual mental model.\n3. **Rhythm - The 300-500 Word Rule:** Readers tire after ~400 words of unbroken text. If two images are available, space them roughly 300-500 words apart to maintain engagement rhythm. Don't cluster both images in the first half.\n4. **The \"Would I Screenshot This?\" Test:** Ask yourself - if a reader were to screenshot the image WITH the paragraph above it, would that screenshot tell a complete mini-story? If yes, the placement is correct.\n\n**âš ï¸ Anti-Patterns (NEVER DO):**\n- âŒ Placing all images at the top of the post (looks like a gallery, not a storyboard).\n- âŒ Placing an image after a heading but BEFORE any explanatory text (image has no context).\n- âŒ Placing an image after a conclusion/CTA section (nobody scrolls to see it).\n- âŒ Ignoring the image's `description` field and guessing where to put it.\n\n**Markdown Formatting:**\n```markdown\n## The 3-Layer Validation Architecture\n\nHere's how the system works. Layer 1 checks for empty objects at the webhook level.\nLayer 2 validates field presence. Layer 3 runs semantic checks on the data quality...\n\n<<IMAGE_1>>\n\nWith this architecture in place, the error rate dropped from 40% to 0.3%...\n```\n</visual_content_integration>\n\n<lead_generation_framework>\n**The \"Soft CTA\" Strategy (Non-Salesy):**\n\n1. **The \"I'm Building This\" Teaser:**\n   - Near the end, mention what you're currently working on related to this topic.\n   - Example: \"I'm currently building an n8n template library for common automation patterns. Follow me on Twitter if you want early access.\"\n\n2. **The \"Let's Compare Notes\" Invitation:**\n   - Example: \"I'm curious how others are handling [X]. Have you found a better approach? Let's connect on LinkedIn.\"\n\n3. **The \"Portfolio Proof\" Link:**\n   - When discussing a technique, link to a live project where you've used it.\n   - Example: \"I used this exact pattern in the Aviators Training Centre project, where it reduced manual tasks by 80%.\"\n\n**Placement Rule:** \n- ONE subtle CTA in the conclusion.\n- ONE portfolio proof link in the body.\n- ZERO \"hire me\" vibes anywhere.\n</lead_generation_framework>\n\n<output_format>\nReturn ONLY valid JSON. No markdown fences around the output.\n\n{\n  \"formatted_markdown\": \"# Title\\n\\nBody content...\",\n  \"structured_data\": {\n     \"seo\": {\n        \"title\": \"The exact title (50-60 chars, includes primary keyword)\",\n        \"slug\": \"url-friendly-slug-with-keyword\",\n        \"meta_description\": \"Compelling summary (150-160 chars) with problem and solution.\",\n        \"keywords\": [\"primary keyword\", \"problem keyword\", \"solution keyword\"],\n        \"tags\": [\"tag1\", \"tag2\", \"tag3\"]\n     }\n  }\n}\n\n**Mandatory Markdown Structure:**\n1. **TL;DR Block (Top):** 2-3 sentences. Problem â†’ Solution â†’ Outcome.\n2. **Prerequisites Section:** Bulleted list of what readers need to know.\n3. **H2/H3 Hierarchy:** H2s in question-format when possible.\n4. **Callout Blocks:** Use `> **Pro Tip:**` and `> âš ï¸ **Gotcha:**` for emphasis.\n5. **Conclusion with CTA:** End with \"What's Next\" section and ONE soft call-to-action.\n\n**Validation Before Return:**\nâ˜ No em-dash \"â€”\" characters anywhere. Use \"-\" instead.\nâ˜ No banned words from the Anti-Slop list.\nâ˜ First-person \"I\" voice throughout.\nâ˜ Real project/example from sourceContent (not invented).\nâ˜ Image markers match strategy.image_strategy.specific_prompts count exactly.\nâ˜ SUCCESs Quality Gate:\n  - Simple: Is the core problem and solution clear from the TL;DR?\n  - Unexpected: Does the hook open a knowledge gap or challenge a common belief?\n  - Concrete: Are there specific metrics, code snippets, or tool names?\n  - Credible: Does every claim trace to sourceContent? Is the \"Expert Card\" present?\n  - Emotional: Does the post connect to real developer frustration/pride?\n  - Story: Does the post follow Villain -> Journey -> Resolution narrative arc?\n</output_format>\n\n</system_instructions>",
              "role": "model"
            },
            {
              "content": "=<context>\n<protected_urls>\nâš ï¸ PRESERVE_EXACT - These are ATOMIC strings. Reproduce verbatim. Do NOT autocorrect, truncate, or modify ANY part.\n- LinkedIn: https://www.linkedin.com/in/amansuryavanshi-ai/\n- Portfolio: https://amansuryavanshi.me/\n- Twitter/X: https://twitter.com/_AmanSurya\n- GitHub: https://github.com/AmanSuryavanshi-1\n</protected_urls>\n\n### MY PERSONAL & PROFESSIONAL PROFILE\n{{ $json.personalContext }}\n\n### THE BLUEPRINT FOR THE ARTICLE\n{{ $json.strategy }}\n\n### CONTENT METADATA (CRITICAL FOR ADAPTIVE LENGTH)\n- Title: {{ $json.sourceContent.title }}\n- Category: {{ $json.sourceContent.primaryCategory }}\n- Source Word Count: {{ $json.sourceContent.wordCount }}\n\n### THE CORE CONTENT (My Real-World Implementations)\nThis is the most critical input. The entire article must be built around the examples, code, and projects discussed here.\n{{ $json.sourceContent.fullText }}\n\n### COMPLEMENTARY SEO & RESEARCH DATA\nUse this to expand upon the core content and optimize for search.\n{{ $json.research }}\n</context>\n\n<critical_recap>\nBEFORE GENERATING, RE-READ THESE NON-NEGOTIABLE RULES:\n1. URLs from <protected_urls> must appear EXACTLY as written - no autocorrection.\n2. You MUST use ALL image markers from strategy.image_strategy.specific_prompts. Place each after the paragraph where its topic is discussed.\n3. Every claim must trace back to sourceContent. No invented projects, metrics, or examples.\n4. No banned words from the Anti-Slop list.\n5. Include E-E-A-T signals: Experience, Expertise, Authoritativeness, Trustworthiness.\n</critical_recap>\n\n<task>\n**Mission:** Synthesize the `sourceContent` into a high-performance, career-building blog asset.\n\n**Execution Checklist:**\n1. **Adaptive Length:** Check `sourceContent.wordCount`. Select Quick Win (800-1200), Deep Dive (1200-1800), or Definitive Guide (1800-2500) per `<critical_instruction>`.\n2. **Research Injection:** \n   - Use `research.market_pulse.urgency_trigger` to make the intro timely.\n   - Use `research.linkedin.business_value_stat` for concrete metrics.\n   - Use `research.blog.seo_keywords_primary` in title and H2s.\n   - Use `research.blog.seo_keywords_longtail` naturally in problem sections.\n   - Use `research.blog.competitor_gap` to differentiate - cover what others miss.\n3. **AI Discovery:** Write the \"Expert Card\" in the first 150 words. Use \"Answer Box\" formatting for all H2s.\n4. **Lead Gen:** Insert ONE \"Portfolio Proof\" link in the body and ONE soft CTA in the conclusion per `<lead_generation_framework>`.\n5. **Strategy:** Follow `strategy.platform_strategies.blog.structure` and `must_include` strictly.\n\n**Constraint:** Output MUST be valid JSON. No markdown fences.\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3952,
        2352
      ],
      "id": "468f5074-1394-4f05-8b90-1fa5489f03d0",
      "name": "Gemini - Blog Content Generation",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "8RkzNZusS3GG9BNO",
          "name": "Google Gemini(PaLM) Api key 4"
        }
      }
    }
  ],
  "connections": {
    "When clicking 'Execute workflow'": {
      "main": [
        [
          {
            "node": "Notion â€“ Get Ready Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion â€“ Get Ready Content": {
      "main": [
        [
          {
            "node": "Filter â€“ Has Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter â€“ Has Content": {
      "main": [
        [
          {
            "node": "Code â€“ Select Content & Profile",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ Select Content & Profile": {
      "main": [
        [
          {
            "node": "Create folder for title",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion â€“ Update to Processing": {
      "main": [
        [
          {
            "node": "Notion â€“ Extract All Blocks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion â€“ Extract All Blocks": {
      "main": [
        [
          {
            "node": "Code â€“ Extract & Process Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ Extract & Process Content": {
      "main": [
        [
          {
            "node": "Context - Fetch Portfolio",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "Notion â€“ Update Final Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ Personal Context Builder": {
      "main": [
        [
          {
            "node": "Perplexity â€“ Research Hashtags & Timing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ CONTEXT MERGER": {
      "main": [
        [
          {
            "node": "Gemini - AI CONTENT STRATEGIST",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create folder for title": {
      "main": [
        [
          {
            "node": "Notion â€“ Update to Processing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Perplexity â€“ Research Hashtags & Timing": {
      "main": [
        [
          {
            "node": "Code â€“ CONTEXT MERGER",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process AI Strategy & MERGE CONTEXT": {
      "main": [
        [
          {
            "node": "Are Images Needed?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - Twitter Selected?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - LinkedIn Selected?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - Blog Selected?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - Dev.to Selected?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - Hashnode Selected?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Are Images Needed?": {
      "main": [
        [
          {
            "node": "Code â€“ Prep Image Tasklist API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - Twitter Selected?": {
      "main": [
        [
          {
            "node": "Gemini - Twitter Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op Twitter Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - LinkedIn Selected?": {
      "main": [
        [
          {
            "node": "Gemini - LinkedIn Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op LinkedIn Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - Blog Selected?": {
      "main": [
        [
          {
            "node": "Gemini - Blog Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op Blog Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code - No-Op Twitter Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code - No-Op LinkedIn Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Code - No-Op Blog Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Gemini - AI CONTENT STRATEGIST": {
      "main": [
        [
          {
            "node": "Process AI Strategy & MERGE CONTEXT",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - Twitter Content Generation": {
      "main": [
        [
          {
            "node": "Code â€“ Prep Twitter API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - LinkedIn Content Generation": {
      "main": [
        [
          {
            "node": "Code â€“ Prep LinkedIn API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Context - Fetch Portfolio": {
      "main": [
        [
          {
            "node": "Context - Standardize & Filter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Context - Standardize & Filter": {
      "main": [
        [
          {
            "node": "Code â€“ Personal Context Builder",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - Dev.to Selected?": {
      "main": [
        [
          {
            "node": "Gemini - Dev.to Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op Dev.to Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - Hashnode Selected?": {
      "main": [
        [
          {
            "node": "Gemini - Hashnode Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op Hashnode Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - Dev.to Content Generation": {
      "main": [
        [
          {
            "node": "Code â€“ Prep DevTo API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - Hashnode Content Generation": {
      "main": [
        [
          {
            "node": "Code - Prep Hashnode API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code - No-Op Hashnode Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 4
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Notion â€“ Get Ready Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code - No-Op Dev.to Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "Update Notion (Blog)": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Code â€“ Prep Twitter API": {
      "main": [
        [
          {
            "node": "HTTP â€“ Push Twitter Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP â€“ Push Twitter Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ Prep LinkedIn API": {
      "main": [
        [
          {
            "node": "HTTP â€“ Push LinkedIn Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP â€“ Push LinkedIn Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Code â€“ Prep DevTo API": {
      "main": [
        [
          {
            "node": "HTTP â€“ Push DevTo Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP â€“ Push DevTo Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "HTTP â€“ Push Hashnode Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 4
          }
        ]
      ]
    },
    "Code â€“ Prep Image Tasklist API": {
      "main": [
        [
          {
            "node": "HTTP â€“ Push Image Tasklist",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP â€“ Push Image Tasklist": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 5
          }
        ]
      ]
    },
    "Code - Prep Hashnode API": {
      "main": [
        [
          {
            "node": "HTTP â€“ Push Hashnode Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ Prep Sanity Blog API": {
      "main": [
        [
          {
            "node": "Update Notion (Blog)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - Blog Content Generation": {
      "main": [
        [
          {
            "node": "Code â€“ Prep Sanity Blog API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "meta": {
    "instanceId": "2aff0c99a9b9ea9c976d68c5887d32445a6bdc6f59f99592eb5b4c4dbaf3d92e"
  }
}