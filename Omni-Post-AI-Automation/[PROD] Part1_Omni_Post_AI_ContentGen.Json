{
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        1776,
        2400
      ],
      "id": "bb99d5df-32b5-4484-b7a2-1ba8a2abbe26",
      "name": "When clicking 'Execute workflow'"
    },
    {
      "parameters": {
        "resource": "databasePage",
        "operation": "getAll",
        "databaseId": {
          "__rl": true,
          "value": "21a34bf1-f7e5-8035-b16f-d5ebf63a86a9",
          "mode": "list"
        },
        "returnAll": true,
        "filterType": "manual",
        "filters": {
          "conditions": [
            {
              "key": "Status|select",
              "condition": "equals",
              "selectValue": "Ready to Generate"
            }
          ]
        },
        "options": {
          "sort": {
            "sortValue": [
              {
                "key": "ManualOrder|number",
                "direction": "ascending"
              },
              {
                "key": "Priority|select",
                "direction": "ascending"
              },
              {
                "timestamp": true,
                "key": "created_time",
                "direction": "ascending"
              }
            ]
          }
        }
      },
      "id": "5a9f5912-85be-4ea7-b645-aeb6a703a9a3",
      "name": "Notion â€“ Get Ready Content",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2,
      "position": [
        2000,
        2352
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "leftValue": "={{ $input.all().length > 0 }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              },
              "id": "6855ced2-6ef0-4ea1-acd1-a9326c4b67f9"
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "56049ef7-cf76-4bc7-8599-1418ec26c167",
      "name": "Filter â€“ Has Content",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        2224,
        2352
      ]
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// CONTENT SELECTION & PROFILE SETUP (V2 - Updated Feb 2026)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nconst items = $input.all();\n\nif (!items || items.length === 0) {\n    console.log('âŒ No content ready for processing');\n    return [];\n}\n\n// Get first item (priority + FIFO)\nconst item = items[0].json;\nconsole.log('ğŸ¯ Processing item:', item.id);\n\n// Enhanced property extraction with fallbacks\nconst getProperty = (obj, path, defaultValue = '') => {\n    const keys = path.split('.');\n    let result = obj;\n    for (const key of keys) {\n        if (result && typeof result === 'object' && key in result) {\n            result = result[key];\n        } else {\n            return defaultValue;\n        }\n    }\n    return result || defaultValue;\n};\n\nconst title = getProperty(item, 'properties.Content Pages.title.0.plain_text') ||\n    getProperty(item, 'properties.title.title.0.plain_text') ||\n    getProperty(item, 'properties.Name.title.0.plain_text') ||\n    getProperty(item, 'name') ||\n    'Untitled Content';\n\nconst category = getProperty(item, 'properties.Category.select.name') ||\n    'Learning';\n\nconst priority = getProperty(item, 'properties.Priority.select.name') ||\n    'normal';\n\n// â”€â”€ User Profile (Single Source of Truth) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n// Keep in sync with GEMINI.md and prompt <role> sections\nconst userProfile = {\n    name: 'Aman Suryavanshi',\n    role: 'AI Solutions Architect | Full-Stack Agentic Developer',\n    focus: 'Building intelligent multi-agent systems AND the frontend interfaces that let non-technical people control them',\n    personality: 'High-agency, authentic, builder-mindset, detail-oriented',\n    expertise: [\n        'Next.js 15', 'React 18', 'TypeScript',\n        'n8n Automation', 'LangGraph', 'Agentic AI',\n        'SEO/AEO/GEO', 'Multi-LLM Integration', 'API Orchestration', 'Full-Stack Development'\n    ],\n    audience: 'Tech community, hiring managers, AI enthusiasts, developers, startup founders',\n    timezone: 'Asia/Kolkata',\n    location: 'Delhi/NCR, India',\n    writing_style: {\n        twitter: 'Punchy, confident, thread-friendly, opinionated, no fluff',\n        linkedin: 'Professional, story-driven, results-oriented, high-agency voice',\n        blog: 'Authoritative, technically deep, reference-quality, SEO-optimized'\n    },\n    content_goals: {\n        primary: 'Build authority that attracts job offers (target: 15-25L) and freelance clients via Build-in-Public content',\n        secondary: 'Establish thought leadership in agentic AI and automation space in Indian market',\n        engagement: 'Generate inbound opportunities through demonstrated expertise - jobs AND freelance clients'\n    },\n    brand_position: 'I build intelligent multi-agent systems AND the frontend interfaces that let non-technical people control them',\n\n    // â”€â”€ Strategic Positioning (for LinkedIn & career-focused content) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n    // Source of truth: _ME.db/Core/Me.md + T_Stack_Strategy.md\n    // Use these facts to frame ALL career-positioning content correctly.\n    strategic: {\n        // CRITICAL FRAMING: Aman is listed as fresher/early-career (0-2 yrs) but\n        // delivers proven senior-level output. The LinkedIn angle is VELOCITY, not experience.\n        // Every post should signal: \"Get 5 years of output for a 0-year price.\"\n        careerStage: {\n            label: 'Fresher / Early Career (0-2 Years)',\n            framingAngle: 'Velocity Hire - senior-level output at early-career cost',\n            keyMessage: 'My projects prove the output, not my years. Aviators generated revenue. Omni-Post runs in production. I think in systems, not just code.',\n            banPhrase: 'Never frame content as \"I am learning X\" or \"As a fresher...\" - always frame as \"I implemented X in production.\"'\n        },\n\n        // Tier 1 target roles - apply immediately. Content should subtly speak to these decision-makers.\n        targetRoles: [\n            { title: 'Technical Solutions Engineer (TSE)', salaryBand: 'â‚¹10-16L', whyFit: 'Combines tech depth + business impact. Aviators = perfect case study for TSE interviews.' },\n            { title: 'Associate Product Manager (APM)', salaryBand: 'â‚¹12-18L', whyFit: 'I think in systems and products, not just code. Omni-Post proves product sense.' },\n            { title: 'Developer Relations (DevRel)', salaryBand: 'â‚¹9-15L', whyFit: 'Build-in-public strategy is a natural fit. Writing + coding + community.' },\n            { title: 'AI Automation Engineer', salaryBand: 'â‚¹8-12L', whyFit: 'Pure n8n/workflow orchestration. Already delivering senior-level here.' }\n        ],\n\n        // Hard proof points - ALWAYS use at least one in LinkedIn posts. Exact numbers only.\n        proofPoints: [\n            { metric: 'â‚¹300K revenue impact', context: 'Aviators Training Centre - Next.js + n8n + SEO, #1 Google rankings' },\n            { metric: '74-node production workflow', context: 'Omni-Post AI - Multi-LLM content automation running on 8+ platforms' },\n            { metric: '99.7% reliability', context: 'Self-healing n8n workflows with DLQ architecture and retry logic' },\n            { metric: '80% time reduction', context: 'Manual content tasks automated via Omni-Post AI end-to-end pipeline' },\n            { metric: '95+ Lighthouse score', context: 'Next.js 15 performance optimization with sub-2s load times' }\n        ],\n\n        // T-shaped differentiator - the unique combination that makes Aman rare\n        uniquePositioning: 'Most AI developers cannot build UIs. Most frontend developers cannot build agents. I do BOTH - end-to-end.',\n\n        // Freelance services offered (for freelance-targeting content accuracy)\n        freelanceServices: [\n            'n8n Automation Builds - complex workflow orchestration for businesses (â‚¹30K-150K per project)',\n            'AI SEO/GEO Optimization - make websites rank in AI search engines like Perplexity/ChatGPT',\n            'Domain-Specific AI Agents - content automation, customer support, lead generation'\n        ],\n\n        // Current & completed projects - ONLY include these. Never commit to future deliverables.\n        projects: [\n            {\n                name: 'Aviators Training Centre',\n                status: 'Completed',\n                stack: 'Next.js 15 + n8n + SEO',\n                impact: 'â‚¹300K revenue impact, #1 Google rankings, 95+ Lighthouse score'\n            },\n            {\n                name: 'Omni-Post AI Automation',\n                status: 'In Progress (Build-in-Public)',\n                stack: '74-node n8n + Multi-LLM (GPT-4/Claude/Gemini) + Notion + 8 platforms',\n                impact: '80% time reduction in content workflow, 99.7% automation reliability'\n            },\n            {\n                name: 'Portfolio Website',\n                status: 'Completed',\n                stack: 'Next.js 15 + TypeScript',\n                impact: 'Production-grade UI, sub-2s load times, 95+ Lighthouse'\n            }\n        ],\n\n        // Future roadmap (for \"What I am building next\" hooks - sneak peek only, no commitments)\n        buildingNext: 'Actively exploring agentic AI patterns with LangGraph - documenting everything in public.'\n    }\n};\n\nconst sessionId = `session_${Date.now()}_${(item.id || '').toString().substring(0, 8)}`;\n\nreturn [{\n    json: {\n        id: item.id,\n        title: title,\n        category: category,\n        priority: priority,\n        sessionId: sessionId,\n        userProfile: userProfile,\n        processingStartTime: new Date().toISOString(),\n        remainingItems: items.length - 1,\n        originalId: item.id\n    }\n}];"
      },
      "id": "2b8df733-3980-41de-a59b-b57174c730e8",
      "name": "Code â€“ Select Content & Profile",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2448,
        2352
      ]
    },
    {
      "parameters": {
        "resource": "databasePage",
        "operation": "update",
        "pageId": {
          "__rl": true,
          "value": "={{ $('Code â€“ Select Content & Profile').item.json.id }}",
          "mode": "id"
        },
        "propertiesUi": {
          "propertyValues": [
            {
              "key": "Status|select",
              "type": "select",
              "selectValue": "Generating"
            },
            {
              "key": "SessionID|rich_text",
              "richText": true,
              "text": {
                "text": [
                  {
                    "text": "={{ $('Code â€“ Select Content & Profile').item.json.sessionId }}",
                    "annotationUi": {}
                  }
                ]
              }
            },
            {
              "key": "Processing Started|date",
              "type": "date",
              "date": "={{ $('Code â€“ Select Content & Profile').item.json.processingStartTime }}"
            },
            {
              "key": "Notes|rich_text",
              "richText": true,
              "text": {
                "text": [
                  {
                    "text": "=ğŸ”„ Processing started\\nSession: {{ $('Code â€“ Select Content & Profile').item.json.sessionId }}\\nPriority: {{ $('Code â€“ Select Content & Profile').item.json.priority }}\\nCategory: {{ $('Code â€“ Select Content & Profile').item.json.category }}\\nStarted: {{ new Date().toLocaleString('en-IN', {timeZone: 'Asia/Kolkata'}) }} IST",
                    "annotationUi": {}
                  }
                ]
              }
            }
          ]
        },
        "options": {}
      },
      "id": "72ac9ddc-ffd8-4c67-b743-301595c12651",
      "name": "Notion â€“ Update to Processing",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2,
      "position": [
        2896,
        2352
      ],
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "resource": "block",
        "operation": "getAll",
        "blockId": {
          "__rl": true,
          "value": "={{ $json.id }}",
          "mode": "id"
        },
        "returnAll": true,
        "fetchNestedBlocks": true,
        "simplifyOutput": false
      },
      "id": "f886cae1-75cf-498f-ba9b-9bb0c869a764",
      "name": "Notion â€“ Extract All Blocks",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2.2,
      "position": [
        3120,
        2352
      ],
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// PRODUCTION-READY NOTION CONTENT EXTRACTION (V2 - FIXED OUTPUT)\n\ntry {\n  console.log('ğŸ” Starting comprehensive content extraction...');\n  \n  const extractItems = $items('Notion â€“ Extract All Blocks');\n  if (!extractItems?.length) {\n    throw new Error('No blocks from Notion â€“ Extract All Blocks');\n  }\n  console.log(`ğŸ“¥ Processing ${extractItems.length} block items`);\n  \n  const allBlocks = extractItems.map(item => item.json);\n  const blockMap = new Map();\n  const topLevelBlocks = [];\n  \n  // Build hierarchical tree\n  allBlocks.forEach(block => {\n    blockMap.set(block.id, { ...block, children: [] });\n  });\n  \n  allBlocks.forEach(block => {\n    if (block.parent?.type === 'page_id') {\n      topLevelBlocks.push(blockMap.get(block.id));\n    } else if (block.parent?.type === 'block_id') {\n      const parent = blockMap.get(block.parent.block_id);\n      if (parent) {\n        parent.children.push(blockMap.get(block.id));\n      }\n    }\n  });\n  \n  console.log(`ğŸŒ³ Built tree with ${topLevelBlocks.length} top-level blocks`);\n  \n  // Text extraction helper\n  const extractText = (richTextArray) => {\n    if (!Array.isArray(richTextArray)) return '';\n    return richTextArray\n      .map(item => item.plain_text || item.text?.content || '')\n      .join('')\n      .trim();\n  };\n  \n  // Image processing helper\n  const processImage = (url, caption = '') => {\n    if (!url) return null;\n    try {\n      return {\n        url: url,\n        caption: caption,\n        alt_text: caption || 'Content image',\n        processing_needed: true\n      };\n    } catch {\n      return null;\n    }\n  };\n  \n  // Recursive block renderer\n  function renderBlock(block, level = 0) {\n    if (!block?.type) return { text: '', sections: [], images: [] };\n    \n    const indent = '  '.repeat(level);\n    const blockData = block[block.type] || {};\n    let content = '';\n    let sections = [];\n    let images = [];\n    let text = extractText(blockData?.rich_text || blockData?.text || []);\n    \n    switch (block.type) {\n      case 'heading_1':\n        content = `\\\\n# ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 1, title: text, content: '', id: block.id });\n        break;\n      case 'heading_2':\n        content = `\\\\n## ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 2, title: text, content: '', id: block.id });\n        break;\n      case 'heading_3':\n        content = `\\\\n### ${text}\\\\n\\\\n`;\n        if (text) sections.push({ level: 3, title: text, content: '', id: block.id });\n        break;\n      case 'paragraph':\n        if (text) content = `${text}\\\\n\\\\n`;\n        break;\n      case 'bulleted_list_item':\n        if (text) content = `${indent}- ${text}\\\\n`;\n        break;\n      case 'numbered_list_item':\n        if (text) content = `${indent}1. ${text}\\\\n`;\n        break;\n      case 'toggle':\n        if (text) {\n          content = `\\\\nâ–¶ï¸ ${text}\\\\n`;\n          sections.push({ level: 4, title: text, content: '', id: block.id, type: 'toggle' });\n        }\n        break;\n      case 'callout':\n        const icon = blockData?.icon?.emoji || 'ğŸ’¡';\n        if (text) content = `\\\\n${icon} **${text}**\\\\n\\\\n`;\n        break;\n      case 'quote':\n        if (text) content = `\\\\n> ${text}\\\\n\\\\n`;\n        break;\n      case 'code':\n        const language = blockData?.language || 'text';\n        if (text) {\n          content = `\\\\n\\`\\`\\`${language}\\\\n${text}\\\\n\\`\\`\\`\\\\n\\\\n`;\n          sections.push({ level: 5, title: `Code: ${language}`, content: text, id: block.id, type: 'code' });\n        }\n        break;\n      case 'divider':\n        content = '\\\\n---\\\\n\\\\n';\n        break;\n      case 'image':\n        const imageUrl = blockData?.file?.url || blockData?.external?.url;\n        if (imageUrl) {\n          const processedImage = processImage(imageUrl, text);\n          if (processedImage) {\n            images.push(processedImage);\n            content = `\\\\n[ğŸ“¸ Image: ${text || 'Visual content'}]\\\\n\\\\n`;\n          }\n        }\n        break;\n      case 'video':\n        content = `\\\\n[ğŸ¥ Video: ${text || 'Video content'}]\\\\n\\\\n`;\n        break;\n      case 'bookmark':\n        const bookmarkUrl = blockData?.url || '';\n        if (bookmarkUrl) content = `\\\\n[ğŸ”— ${text || bookmarkUrl}](${bookmarkUrl})\\\\n\\\\n`;\n        break;\n      default:\n        if (text) content = `${indent}${text}\\\\n\\\\n`;\n        break;\n    }\n    \n    // Process children recursively\n    if (block.children?.length) {\n      const childrenResult = block.children\n        .map(child => renderBlock(child, level + 1))\n        .reduce((acc, result) => {\n          acc.text += result.text;\n          acc.sections = acc.sections.concat(result.sections);\n          acc.images = acc.images.concat(result.images);\n          return acc;\n        }, { text: '', sections: [], images: [] });\n      \n      content += childrenResult.text;\n      sections = sections.concat(childrenResult.sections);\n      images = images.concat(childrenResult.images);\n    }\n    \n    return { text: content, sections: sections, images: images };\n  }\n  \n  // Process all blocks\n  const result = topLevelBlocks\n    .map(block => renderBlock(block))\n    .reduce((acc, blockResult) => {\n      acc.text += blockResult.text;\n      acc.sections = acc.sections.concat(blockResult.sections);\n      acc.images = acc.images.concat(blockResult.images);\n      return acc;\n    }, { text: '', sections: [], images: [] });\n  \n  // Clean up text\n  let fullText = result.text\n    .replace(/\\n{3,}/g, '\\n\\n')\n    .replace(/\\s+$/gm, '')\n    .trim();\n  \n  const stats = {\n    totalBlocks: allBlocks.length,\n    processedBlocks: topLevelBlocks.length,\n    characterCount: fullText.length,\n    wordCount: fullText.split(/\\s+/).filter(w => w.length > 0).length,\n    sections: result.sections.length,\n    images: result.images.length,\n    toggleSections: result.sections.filter(s => s.type === 'toggle').length,\n    codeSections: result.sections.filter(s => s.type === 'code').length\n  };\n  \n  console.log('âœ… Content extraction complete:', stats);\n  \n  // â­ KEY FIX: Wrap everything in 'sourceContent'\n  return [{\n    json: {\n      sourceContent: {\n        name: $('Notion â€“ Update to Processing').first().json.name,\n        categories: $('Notion â€“ Update to Processing').first().json.property_category,\n        fullText: fullText,\n        sections: result.sections,\n        images: result.images,\n        extractionStats: stats,\n        contentMetadata: {\n          totalSections: result.sections.length,\n          hasImages: result.images.length > 0,\n          hasCode: result.sections.some(s => s.type === 'code'),\n          hasToggles: result.sections.some(s => s.type === 'toggle'),\n          hasLists: fullText.includes('- ') || /^\\d+\\.\\s/m.test(fullText),\n          complexity: stats.wordCount > 800 ? 'high' : stats.wordCount > 400 ? 'medium' : 'low'\n        }\n      }\n    }\n  }];\n  \n} catch (error) {\n  console.error('âŒ Content extraction failed:', error.message);\n  return [{\n    json: {\n      sourceContent: {\n        fullText: `Content extraction error: ${error.message}`,\n        sections: [],\n        images: [],\n        extractionStats: { error: true },\n        contentMetadata: { error: error.message }\n      }\n    }\n  }];\n}\n"
      },
      "id": "061f2970-bd7f-4cf4-b006-bd8d8c150463",
      "name": "Code â€“ Extract & Process Content",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3344,
        2352
      ]
    },
    {
      "parameters": {
        "numberInputs": 6
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        4752,
        2480
      ],
      "id": "e58e52d9-58de-4807-b2f4-7e6f19fe885e",
      "name": "Merge2"
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// CONTEXT ADAPTER v3 (Production-Ready)\n// Purpose: Merge Portfolio API data + Notion Content + Strategic Context\n// \n// Architecture:\n//   Portfolio API â†’ Facts & Proof (skills, projects, metrics)\n//   personalContext â†’ Strategy & Voice (goals, hooks, forbidden phrases)\n//   Notion Content â†’ Raw source material for repurposing\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst contentNode = $('Code â€“ Extract & Process Content').first().json;\nconst contextRaw = $('Context - Standardize & Filter').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 1: STATIC STRATEGIC CONTEXT (Never from API - Your \"ContentDNA\")\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nconst strategicContext = {\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.1 POSITIONING & CAREER STRATEGY\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  positioning: {\n    headline: \"Full-Stack Agentic Developer | AI Automation Engineer + Next.js Developer\",\n    experienceLevel: \"Early Career (0-2 years) | Senior-level output in n8n, SEO/GEO, workflow automation\",\n    location: \"Delhi/NCR + Remote (India & Global)\",\n    availability: \"Open to full-time, contract, freelance\",\n    \n    // The T-Shaped Stack (Your Unfair Advantage)\n    tStack: {\n      depth: {\n        area: \"Multi-Agent Orchestration\",\n        skills: [\"LangGraph\", \"CrewAI\", \"n8n AI Agents\"],\n        proof: \"74-node production workflows with 99.7% reliability\"\n      },\n      breadth: [\n        { area: \"Frontend Excellence\", detail: \"Next.js 15, 95+ Lighthouse scores\" },\n        { area: \"Workflow Automation\", detail: \"15+ production workflows deployed\" },\n        { area: \"Technical SEO/GEO\", detail: \"#1 Google rankings, AI Search visibility\" }\n      ],\n      pitch: \"Most AI developers build the brain but not the body. I do both.\"\n    }\n  },\n  \n  targetRoles: [\n    \"Technical Solutions Engineer (TSE)\",\n    \"Associate Product Manager (APM)\",\n    \"Developer Relations (DevRel)\",\n    \"Growth Engineer\",\n    \"Founder's Office (Technical)\",\n    \"AI Automation Engineer\",\n    \"Agentic AI Developer\",\n    \"Full-Stack AI Developer\"\n  ],\n  \n  hiddenGoals: {\n    primary: \"Get inbound TSE/APM/DevRel offers from target companies\",\n    secondary: \"Attract â‚¹75K-3L freelance automation projects organically\",\n    tertiary: \"Build reputation as Agentic AI + n8n expert in India\",\n    longTerm: \"Transition to robotics/edge AI within 2-3 years\"\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.2 CONTENT VOICE (How to Sound Like Aman)\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  voice: {\n    attributes: [\n      \"Authentic & transparent - share real struggles + wins\",\n      \"Detail-oriented with technical depth\",\n      \"Growth-minded - always learning, never pretending to know it all\",\n      \"Practical over theoretical - show real code, real metrics\",\n      \"Builds in public - document the journey, not just the destination\",\n      \"Helpful & community-focused - teach what you learn\"\n    ],\n    \n    toneGuidelines: [\n      \"Use 'I' statements, not 'we' (you're a solo builder)\",\n      \"Short paragraphs (2-3 sentences max for social)\",\n      \"Lead with the insight, not the backstory\",\n      \"Be opinionated on tech choices - strong views, loosely held\",\n      \"Admit mistakes openly - it builds trust\"\n    ],\n    \n    forbiddenPhrases: [\n      \"In today's digital landscape\",\n      \"Delve\", \"Unlock\", \"Unleash\", \"Leverage\",\n      \"Game-changer\", \"Revolutionary\", \"Cutting-edge\", \"Synergy\",\n      \"Humbled to announce\", \"Thrilled to share\", \"Excited to announce\",\n      \"Let's dive in\", \"Without further ado\", \"Honored to\",\n      \"At the end of the day\", \"It goes without saying\",\n      \"Take it to the next level\", \"Circle back\"\n    ]\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.3 CONTENT PILLARS (What to Post About)\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  contentPillars: [\n    {\n      pillar: \"Build-in-Public\",\n      weight: 0.35,\n      hashtags: [\"#buildinpublic\", \"#indiedev\", \"#solofounder\"],\n      topics: [\"Project updates\", \"Revenue milestones\", \"Failures & pivots\", \"Tool reveals\"]\n    },\n    {\n      pillar: \"n8n & Automation Deep Dives\",\n      weight: 0.30,\n      hashtags: [\"#n8n\", \"#automation\", \"#nocode\", \"#lowcode\", \"#workflowautomation\"],\n      topics: [\"Workflow breakdowns\", \"Error handling patterns\", \"Self-healing architecture\", \"API integration tips\"]\n    },\n    {\n      pillar: \"AI/Agentic Systems\",\n      weight: 0.25,\n      hashtags: [\"#AgenticAI\", \"#LangChain\", \"#LangGraph\", \"#AI\", \"#LLM\"],\n      topics: [\"RAG implementations\", \"Multi-agent patterns\", \"LLM orchestration\", \"AI in production\"]\n    },\n    {\n      pillar: \"Career & Freelance\",\n      weight: 0.10,\n      hashtags: [\"#freelance\", \"#remotework\", \"#techcareers\", \"#developerlife\"],\n      topics: [\"Client acquisition\", \"Portfolio strategy\", \"Pricing lessons\", \"Work-life integration\"]\n    }\n  ],\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.4 PROJECT HOOKS (Story Starters - The \"Content Seeds\")\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  projectHooks: {\n    \"aviators-training-centre\": {\n      hooks: [\n        \"I turned a flight school's website into their #1 sales channel. Here's the system:\",\n        \"From 0 to â‚¹3L revenue with just SEO + n8n automation. Thread ğŸ§µ\",\n        \"My client was losing leads to a contact form nobody checked. I built a 14-node solution.\",\n        \"How I achieved 95+ Lighthouse scores on a Next.js 15 production site:\",\n        \"80% reduction in manual tasks. Here's the n8n workflow that made it happen:\"\n      ],\n      theStruggle: \"Spent 2 days debugging Firebase webhook triggers that fired twice. Turns out I needed idempotency keys.\",\n      theBreakthrough: \"Realized n8n + Airtable + Resend could replace their entire CRM workflow.\",\n      lessonLearned: \"SEO compounds. The â‚¹3L didn't come from one postâ€”it came from 6 months of #1 rankings.\",\n      hotTakes: [\n        \"WordPress is dead for client projects. Next.js + Sanity is the 2025 stack.\"\n      ]\n    },\n    \"n8n-automation-suite\": {\n      hooks: [\n        \"I post to LinkedIn and Twitter/X with one click. Here's my 74-node system:\",\n        \"Stop copy-pasting content across platforms. Automate it.\",\n        \"Built-in-public content flywheel: Notion draft â†’ viral post in 60 seconds.\",\n        \"The architecture behind my self-healing content automation:\",\n        \"Why I moved from Zapier to self-hosted n8n (and saved â‚¹15K/month):\"\n      ],\n      theStruggle: \"Twitter API rate limits almost killed this project at 3 AM. OAuth 1.0a is pain.\",\n      theBreakthrough: \"Dead-letter queues changed everything. No more silent failures.\",\n      lessonLearned: \"Build for failure first. Happy path is the easy part.\",\n      hotTakes: [\n        \"Zapier is for prototypes. n8n is for production.\",\n        \"If your automation can't self-heal, it's just a scheduled script.\"\n      ]\n    },\n    \"n8n-github-backup\": {\n      hooks: [\n        \"My n8n instance crashed on a Friday. No backups. Never again.\",\n        \"99.9% recovery rate with self-healing retry logic. Here's the architecture:\",\n        \"How I built a dual-stream backup system that handles 1000+ workflows:\",\n        \"The credential scrubbing pattern that makes your n8n repos public-safe:\",\n        \"GitHub's 30 req/min limit forced me to redesign everything. Best decision ever.\"\n      ],\n      theStruggle: \"First version hit rate limits constantly. Had to completely rethink the architecture.\",\n      theBreakthrough: \"Loop-to-Webhook pattern: Orchestration and execution in separate streams.\",\n      lessonLearned: \"Rate limits aren't bugsâ€”they're design constraints. Embrace them.\",\n      hotTakes: [\n        \"If you're not backing up your n8n workflows to git, you're one crash away from losing everything.\"\n      ]\n    },\n    \"barkat-enterprise\": {\n      hooks: [\n        \"3,000+ viewers for a tiles distributor website. Here's how React won:\",\n        \"PDF catalogues in-browser with PDFJS. No downloads, no friction.\",\n        \"My first B2B freelance project: lessons from building for a traditional business.\"\n      ],\n      theStruggle: \"Client had no digital presence. Had to explain every tech decision in simple terms.\",\n      theBreakthrough: \"PDF viewer eliminated their biggest pain pointâ€”printing and distributing catalogues.\",\n      lessonLearned: \"Simple features that remove friction > complex features that impress developers.\"\n    },\n    \"av-newsstream\": {\n      hooks: [\n        \"9 API keys. 10-minute cache. 90% reduction in API calls. Here's the system:\",\n        \"How I solved the free-tier API limit problem with intelligent key rotation:\",\n        \"Text-to-speech in a news app? Here's why I added it and what I learned.\"\n      ],\n      theStruggle: \"NewsAPI's 100 req/day limit seemed impossible to work around.\",\n      theBreakthrough: \"ApiKeyManager.js with health tracking and automatic failover.\",\n      lessonLearned: \"Caching is the most underrated optimization. 10 minutes saved 90% of API calls.\"\n    },\n    \"foodah\": {\n      hooks: [\n        \"14,000+ lines of JSON. 60fps scrolling. Here's how I built Foodah:\",\n        \"Custom React hooks for everything: useOnlineStatus, useFallbackImage, useRestaurantMenu.\",\n        \"Shimmer UI and lazy loading: The performance patterns that matter.\"\n      ],\n      theStruggle: \"Swiggy API returns deeply nested, inconsistent data. Optional chaining saved my sanity.\",\n      theBreakthrough: \"useFallbackImage hook that replaces broken images with random alternatives seamlessly.\",\n      lessonLearned: \"Never trust external APIs to be consistent. Always have fallbacks.\"\n    },\n    \"portfolio-website\": {\n      hooks: [\n        \"6,000+ project views. 95+ Lighthouse. Here's my portfolio stack:\",\n        \"Why I chose Sanity CMS over Contentful for my developer portfolio:\",\n        \"The Omni-Post workflow that auto-distributes every blog post I write.\"\n      ],\n      theStruggle: \"Redesigned 3 times before landing on the current system.\",\n      theBreakthrough: \"Integrating n8n webhooks with Sanity CMS for automated social distribution.\",\n      lessonLearned: \"Your portfolio is never done. Treat it like a product, not a project.\"\n    }\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.5 PLATFORM-SPECIFIC RULES\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  platformRules: {\n    linkedin: {\n      maxLength: 3000,\n      optimalLength: \"800-1200 chars for engagement\",\n      style: \"Professional but not corporate. Use line breaks aggressively. Hook in first 2 lines.\",\n      cta: \"Follow for daily AI automation breakdowns.\",\n      formatting: [\n        \"Use emoji bullets sparingly (â†’, âœ…, ğŸ”¥)\",\n        \"One idea per paragraph\",\n        \"End with a question to drive comments\"\n      ],\n      emojiUsage: \"Minimal. 2-3 max. No emoji spam.\",\n      hashtagCount: \"3-5 at the end, never inline\"\n    },\n    twitter: {\n      maxLength: 280,\n      style: \"Punchy. Opinionated. Thread-friendly. No fluff.\",\n      cta: \"Follow @_AmanSurya for more.\",\n      formatting: [\n        \"Front-load the value\",\n        \"Use numbers and specifics\",\n        \"Thread opener should stand alone\"\n      ],\n      emojiUsage: \"Match tech twitter energy. More acceptable here.\",\n      hashtagCount: \"1-2 max, only if organic\"\n    }\n  },\n  \n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  // 1.6 FUTURE ROADMAP (For relevant content positioning)\n  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  futureRoadmap: {\n    currentFocus: \"Agentic Systems Era - LangGraph + CrewAI + n8n AI Agents\",\n    learning: [\n      \"Advanced LangGraph patterns\",\n      \"Multi-agent orchestration at scale\",\n      \"WebSockets & real-time communication\",\n      \"Docker & containerization for edge deployment\"\n    ],\n    yearEnd2026: \"Launch Personal RAG assistant + production LangGraph agents\",\n    longTermVision: \"Transition to robotics/edge AIâ€”bringing agentic intelligence to physical systems\",\n    philosophyNote: \"The T-Stack: deep in orchestration, broad across the stack. That's the unfair advantage.\"\n  }\n};\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 2: SAFE PARSE OF INCOMING API/GEMINI DATA\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nlet portfolioData = {};\ntry {\n  // Handle both stringified JSON and direct object from Gemini/API\n  const text = contextRaw.content?.parts?.[0]?.text || JSON.stringify(contextRaw);\n  const cleanJson = text.replace(/```json/g, '').replace(/```/g, '').trim();\n  portfolioData = JSON.parse(cleanJson);\n} catch (e) {\n  console.log('Portfolio Data Parse Warning:', e.message);\n  // Fallback with essential identity\n  portfolioData = {\n    core: {\n      name: \"Aman Suryavanshi\",\n      role: \"AI Workflow Architect & Systems Builder\",\n      tagline: \"I Build Self-Healing AI Systems That Drive Revenue\"\n    }\n  };\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 3: INTELLIGENT CONTENT SUMMARIZATION (Cost-Optimized)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nfunction intelligentSummarize(sourceContent) {\n  if (!sourceContent) {\n    return {\n      summary: \"No content available\",\n      structure: \"empty\",\n      wordCount: 0,\n      complexity: \"unknown\",\n      keyTopics: []\n    };\n  }\n\n  const { fullText, sections, extractionStats, summary } = sourceContent;\n  let outputSummary = \"\";\n\n  // Priority 1: Use pre-extracted summary if available\n  if (summary && summary.length > 100) {\n    outputSummary = summary.substring(0, 1500);\n  } else {\n    // Priority 2: Section headings (highest signal-to-noise)\n    const sectionTitles = (sections || [])\n      .filter(s => s.title && s.title.length > 3)\n      .map(s => `â€¢ ${s.title}`)\n      .slice(0, 10)\n      .join('\\n');\n\n    if (sectionTitles) {\n      outputSummary += \"**Key Sections:**\\n\" + sectionTitles + \"\\n\\n\";\n    }\n\n    // Priority 3: First substantive content block\n    if (sections && sections.length > 0) {\n      const contentSection = sections.find(s => s.content && s.content.length > 50);\n      if (contentSection) {\n        outputSummary += \"**Core Content:**\\n\" +\n          contentSection.content.substring(0, 600).replace(/\\n+/g, ' ') + \"...\\n\";\n      }\n    }\n\n    // Priority 4: Fallback to fullText\n    if (!outputSummary && fullText) {\n      outputSummary = \"**Content Preview:**\\n\" + fullText.substring(0, 1200) + \"...\";\n    }\n  }\n\n  // Extract key topics for content matching (simple keyword extraction)\n  const topicKeywords = [\n    'n8n', 'automation', 'Next.js', 'React', 'AI', 'LLM', 'SEO', 'workflow',\n    'API', 'Firebase', 'Supabase', 'TypeScript', 'production', 'revenue'\n  ];\n  const textLower = (fullText || outputSummary).toLowerCase();\n  const keyTopics = topicKeywords.filter(kw => textLower.includes(kw.toLowerCase()));\n\n  return {\n    summary: outputSummary.substring(0, 2000),\n    structure: extractionStats?.hasToggles ? \"hierarchical\" : \"linear\",\n    wordCount: extractionStats?.wordCount || (fullText?.split(/\\s+/).length || 0),\n    complexity: extractionStats?.complexity || \"medium\",\n    sectionCount: sections?.length || 0,\n    hasCode: extractionStats?.codeSections > 0,\n    hasToggles: extractionStats?.toggleSections > 0,\n    keyTopics: keyTopics\n  };\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 4: CONTEXT MATCHING - Find relevant project hooks for the content\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nfunction findRelevantProjectHooks(contentSummary, projectHooks) {\n  const topics = contentSummary.keyTopics || [];\n  const contentText = (contentSummary.summary || '').toLowerCase();\n  \n  // Score each project by keyword matches\n  const projectScores = Object.entries(projectHooks).map(([projectId, hooks]) => {\n    let score = 0;\n    \n    // Check if project name is mentioned\n    if (contentText.includes(projectId.replace(/-/g, ' '))) score += 10;\n    \n    // Check topic overlaps\n    const projectKeywords = {\n      \"aviators-training-centre\": [\"next.js\", \"seo\", \"revenue\", \"firebase\", \"freelance\"],\n      \"n8n-automation-suite\": [\"n8n\", \"automation\", \"content\", \"linkedin\", \"twitter\", \"workflow\"],\n      \"n8n-github-backup\": [\"backup\", \"github\", \"n8n\", \"self-healing\", \"production\"],\n      \"barkat-enterprise\": [\"react\", \"pdf\", \"b2b\", \"freelance\"],\n      \"av-newsstream\": [\"api\", \"news\", \"caching\", \"react\"],\n      \"foodah\": [\"react\", \"api\", \"performance\", \"swiggy\"],\n      \"portfolio-website\": [\"portfolio\", \"sanity\", \"blog\", \"seo\"]\n    };\n    \n    (projectKeywords[projectId] || []).forEach(kw => {\n      if (contentText.includes(kw)) score += 2;\n    });\n    \n    return { projectId, hooks, score };\n  });\n  \n  // Return top 2 relevant projects\n  return projectScores\n    .filter(p => p.score > 0)\n    .sort((a, b) => b.score - a.score)\n    .slice(0, 2)\n    .map(p => ({\n      projectId: p.projectId,\n      suggestedHooks: p.hooks.hooks?.slice(0, 2) || [],\n      theStruggle: p.hooks.theStruggle,\n      lessonLearned: p.hooks.lessonLearned\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 5: BUILD FINAL MERGED OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nconst sourceContent = contentNode.sourceContent || {};\nconst contentSummary = intelligentSummarize(sourceContent);\nconst relevantHooks = findRelevantProjectHooks(contentSummary, strategicContext.projectHooks);\n\n// Merge everything\nconst mergedContext = {\n  // From Portfolio API (facts, proof, metrics)\n  ...portfolioData,\n  \n  // Strategic layer (voice, goals, positioning)\n  strategic: strategicContext,\n  \n  // Matched content hooks for this specific post\n  matchedHooks: relevantHooks\n};\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SECTION 6: FINAL OUTPUT (Matching \"Part 1\" Schema)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nreturn [{\n  json: {\n    // The full merged context for AI nodes\n    personalContext: mergedContext,\n    \n    // Convenience: Quick access to key strategic elements for prompts\n    voiceGuide: {\n      attributes: strategicContext.voice.attributes,\n      forbidden: strategicContext.voice.forbiddenPhrases,\n      toneGuidelines: strategicContext.voice.toneGuidelines\n    },\n    \n    // Platform rules for the Distribution node\n    platformRules: strategicContext.platformRules,\n    \n    // Content pillars with weights for topic selection\n    contentPillars: strategicContext.contentPillars,\n    \n    // The T-Stack pitch (use in bios, intros)\n    tStackPitch: strategicContext.positioning.tStack.pitch,\n    \n    // Processed source content\n    sourceContent: sourceContent,\n    \n    // Optimized summary for LLM prompts (cost control)\n    contentSummary: contentSummary,\n    \n    // Matched hooks for this content\n    suggestedHooks: relevantHooks,\n    \n    // Keep full source for reference if needed\n    _fullSourceContent: sourceContent,\n    \n    // Metadata for debugging\n    _meta: {\n      version: \"v3.0\",\n      generatedAt: new Date().toISOString(),\n      portfolioDataKeys: Object.keys(portfolioData),\n      matchedProjects: relevantHooks.map(h => h.projectId)\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2336,
        2640
      ],
      "id": "a154a065-cdc5-4e2a-a68f-c1aaa106df6e",
      "name": "Code â€“ Personal Context Builder"
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// CONTEXT MERGER (fetches from previous node, merges with Perplexity)\n// Place after Perplexity node, queries previous (Personal Context Builder) node\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconsole.log('ğŸ”— Starting final context merger...');\n\n// 1. Fetch JSON data from the previous Personal Context Builder node\n// const previous = $('Code â€“ Personal Context Builder').first().json || {};\nconst previous = $('Code â€“ Personal Context Builder').first().json;\n\n// 2. Get Perplexity output directly â€“ comes as $json in this node\n// const perplexity = $json || {};\nconst perplexity = $json;\n\n// 3. Merge key blocks: always prefer Perplexity for \"research\", but get everything else from previous\n// const personalContext = previous.personalContext || {};\nconst personalContext = previous.personalContext;\nconst sourceContent = previous.sourceContent || {};\nconst contentSummary = previous.contentSummary || {};\nconst perplexityChoices = perplexity.choices;\n\n// Use fallback/default for every key field!\nconst name = personalContext.name || 'Unknown User';\nconst title = sourceContent.name || 'Untitled Content';\nconst categories = Array.isArray(sourceContent.categories) ? sourceContent.categories : ['General'];\nconst primaryCategory = categories[0] || 'General';\nconst summary = contentSummary.summary || '';\nconst wordCount = contentSummary.wordCount || 0;\nconst structure = contentSummary.structure || 'linear';\nconst complexity = contentSummary.complexity || 'unknown';\nconst fullText = sourceContent.fullText || '';\n\n// Perplexity research blockâ€”parse its result\nlet research = {};\ntry {\n  if (\n    Array.isArray(perplexityChoices) &&\n    perplexityChoices.length > 0 &&\n    typeof perplexityChoices[0] === 'object'\n  ) {\n    let rawContent = perplexityChoices[0].message?.content ?? '';\n    rawContent = rawContent.replace(/``````/g, '').trim();\n    if (rawContent) {\n      research = JSON.parse(rawContent);\n      console.log('âœ… Parsed Perplexity JSON.');\n    } else {\n      throw new Error('Empty content in Perplexity choices.');\n    }\n  } else {\n    throw new Error('Perplexity choices incomplete.');\n  }\n} catch (err) {\n  console.warn(`âš ï¸ Perplexity parsing failed: ${err.message}. Using fallback research.`);\n  research = {\n    authenticHashtags: {\n      twitter: ['#BuildInPublic', `#${primaryCategory}`, '#Automation', '#NoCode', '#n8n'],\n      linkedin: ['#ProcessAutomation', `#${primaryCategory}`, '#SystemsThinking', '#AI'],\n    },\n    optimalTimesIST: {\n      twitter_primary_ist: \"9:00-11:00 am IST\",\n      twitter_secondary_ist: \"8:30-9:30 pm IST (US/EU overlap)\",\n      linkedin_ist: \"10:00-12:00 am IST (Tue-Thu)\"\n    },\n    authenticHooks: {\n      twitter_example: \"Solving a weird API quirk in n8n todayâ€”here's the step that finally worked. Anyone else get stuck on webhook reliability?\",\n      linkedin_example: \"Client automated 50% manual onboarding steps using n8n, saving 10 hours/week. Why did we choose modular flows?\"\n    },\n    developerPainPoints: [\n      \"Lack of reliable content scheduling tools for Indian time zones\",\n      \"Complicated OAuth flows between LinkedIn, X and custom APIs\"\n    ]\n  };\n}\n\n// Optional IDs/session info\nconst originalId = previous.originalId ?? null;\nconst sessionId = previous.sessionId ?? null;\nconst notionPageId = sourceContent.id ?? null;\nconst extractionStats = sourceContent.extractionStats ?? {};\nconst hasImages = Array.isArray(sourceContent.images) && sourceContent.images.length > 0;\nconst processingTime = new Date().toISOString();\n\n// Master context object (robust, merged)\nconst masterContext = {\n  personalContext: {\n    ...personalContext,\n    name\n  },\n  sourceContent: {\n    title,\n    categories,\n    primaryCategory,\n    summary,\n    wordCount,\n    structure,\n    complexity,\n    fullText\n  },\n  contentSummary: {\n    summary,\n    wordCount,\n    structure,\n    complexity\n  },\n  research,\n  originalId,\n  sessionId,\n  workflowMetadata: {\n    notionPageId,\n    extractionStats,\n    hasImages,\n    processingTime\n  }\n};\n\nconsole.log('âœ… Master context object created successfully!');\nreturn [{ json: masterContext }];\n"
      },
      "id": "3a840776-ec82-4040-829d-6c50475c865e",
      "name": "Code â€“ CONTEXT MERGER",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2784,
        2640
      ]
    },
    {
      "parameters": {
        "resource": "folder",
        "name": "={{ $('Notion â€“ Get Ready Content').item.json.name }}-SocialDrafts-{{ $json.sessionId }}",
        "driveId": {
          "__rl": true,
          "mode": "list",
          "value": "My Drive"
        },
        "folderId": {
          "__rl": true,
          "value": "1F25H1IcOyYzJa41LwbD-r31_Ogs6ASZd",
          "mode": "list",
          "cachedResultName": "N8N Build in public Drafts - LinkedIn & X",
          "cachedResultUrl": "https://drive.google.com/drive/folders/1F25H1IcOyYzJa41LwbD-r31_Ogs6ASZd"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [
        2672,
        2352
      ],
      "id": "c5475409-c8ba-4901-a629-1e45b38191ee",
      "name": "Create folder for title",
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "1hcyFpBqSOMDRDna",
          "name": "Google Drive Adude"
        }
      }
    },
    {
      "parameters": {
        "content": "Creating a separate folder in Drive to store all the assets & generated drafts",
        "height": 240,
        "width": 224
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2608,
        2272
      ],
      "typeVersion": 1,
      "id": "fc1f71ec-a225-464d-a43c-29e97e77510e",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "model": "sonar-pro",
        "messages": {
          "message": [
            {
              "content": "=<role>\nYou are a Senior Technical Market Intelligence Analyst. Your job is NOT to write content, but to find the \"Heat\" in the market. You act as the eyes and ears for Aman Suryavanshi, a Build-in-Public founder (Next.js/n8n/AI/no-code/low-code).\n</role>\n\n<instructions>\n1. **The \"Newsjack\" (Urgency)**\n   - Search for recent software updates (e.g., \"Next.js 15\", \"n8n v1.0\", \"Claude 3.5\") or industry news related to this topic.\n   - *Goal:* Find ONE specific event that makes this content timely. (e.g., \"This is relevant because Vercel just changed their caching policy\").\n\n2. **The \"Gap Analysis\" (The Void)**\n   - Search Reddit (r/webdev, r/selfhosted) and HackerNews.\n   - What question is everyone asking but getting bad answers for?\n   - Identify \"Contrarian Angles\": What is the common advice that is actually wrong/inefficient?\n\n3. **Technical Vibe Check**\n   - Find 2-3 specific technical keywords that are trending in this niche RIGHT NOW (e.g., don't just say \"AI\", say \"Agentic Loops\" or \"MCP Servers\").\n\n4. **Platform Intelligence**\n   - **Twitter:** Find a \"Village\" (group of devs) discussing this. What is their sentiment? (Excited? Angry? Confused?)\n   - **LinkedIn:** Find a \"Business Stat\" or \"Cost Argument\". (e.g., \"Manual API integrations cost devs 10hrs/week\").\n   - **Blog:** Find \"Zero-Volume, High-Intent\" keywords (e.g., \"fix n8n webhook timeout 502\").\n\n5. **Timing**\n   - Provide optimal posting times for Asia/Kolkata (IST).\n</instructions>\n\n<outputformat>\nReturn ONLY valid JSON with this EXACT structure (no markdown fences):\n\n{\n  \"market_pulse\": {\n    \"urgency_trigger\": \"The recent event/update that makes this relevant NOW.\",\n    \"community_sentiment\": \"What are devs feeling? (e.g., 'Frustrated with complex setups').\",\n    \"the_gap\": \"The specific unanswered question or bad advice you found.\"\n  },\n  \"twitter\": {\n    \"hashtags\": [\"#SpecificTag1\", \"#SpecificTag2\"],\n    \"optimal_posting_times_ist\": [\"09:00 AM\", \"06:00 PM\"],\n    \"hook_inspiration\": \"A specific angle based on the urgency_trigger.\"\n  },\n  \"linkedin\": {\n    \"hashtags\": [\"#SpecificTag1\", \"#SpecificTag2\"],\n    \"optimal_posting_times_ist\": [\"10:00 AM\", \"02:00 PM\"],\n    \"business_value_stat\": \"A specific data point or cost argument found in research.\"\n  },\n  \"blog\": {\n    \"seo_keywords_primary\": [\n      {\"keyword\": \"main topic\", \"volume\": \"high\"}\n    ],\n    \"seo_keywords_longtail\": [\n      {\"keyword\": \"very specific problem fix\", \"volume\": \"low\"}\n    ],\n    \"competitor_gap\": \"What technical detail is missing in current top articles?\"\n  }\n}\n</outputformat>\n\n<constraints>\n- Research MUST be from the last 14 days.\n- Do NOT return generic advice. If no specific news is found, focus on a specific \"Eternal Struggle\" (e.g., \"Dependency Hell\").\n- Output must be strict JSON.\n</constraints>\n",
              "role": "system"
            },
            {
              "content": "=<context>\n<profile>\n- primary_focus: {{ $json.personalContext.strategic.futureRoadmap.currentFocus }}\n- target_roles: {{ $json.personalContext.strategic.targetRoles }}\n</profile>\n\n<topic>\n<name>{{$json.sourceContent.name}}</name>\n<categories>{{$json.sourceContent.categories}}</categories>\n<summary>{{$json.contentSummary.summary}}</summary>\n<date>{{ $now }}</date>\n</topic>\n</context>\n\n<task>\nConduct deep real-time research (last 14 days) to validate this topic. Find specific discussions, news, and technical arguments that make this topic urgent TODAY.\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.2,
          "searchRecency": "month"
        },
        "requestOptions": {}
      },
      "id": "fa236635-63ca-4d93-b3bc-b3684fa01536",
      "name": "Perplexity â€“ Research Hashtags & Timing",
      "type": "n8n-nodes-base.perplexity",
      "typeVersion": 1,
      "position": [
        2560,
        2640
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "perplexityApi": {
          "id": "srhZqNtWBccjllrY",
          "name": "Perplexity work"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// PROCESS AI STRATEGY (V6 - Enhanced Validation, Feb 2026)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n// 1. SAFE INPUT EXTRACTION\n// We use optional chaining and fallback objects to prevent \"Cannot read property of undefined\" errors\nconst geminiRawOutput = $input.first()?.json || {};\nconst contextNode = $('Code â€“ CONTEXT MERGER').first();\nconst originalContext = contextNode ? contextNode.json : {};\n\n// Validate Critical Inputs\nif (Object.keys(geminiRawOutput).length === 0) {\n  throw new Error('âŒ CRITICAL: No input received from Gemini AI Node.');\n}\nif (Object.keys(originalContext).length === 0) {\n  // Warn but don't crash hard if context is missing (useful for isolated testing)\n  console.log('âš ï¸ WARNING: Original Context is empty. Merging might be incomplete.');\n}\n\n// 2. ROBUST JSON PARSING (The \"Fence Stripper\")\n// AI often wraps output in markdown or adds conversational filler. We strip it all.\nlet rawText = geminiRawOutput.text ||\n  geminiRawOutput.content?.parts?.[0]?.text ||\n  geminiRawOutput.result || // Some Gemini node versions use .result\n  \"\";\n\n// Handle edge case where the input itself is just the string\nif (typeof geminiRawOutput === 'string') rawText = geminiRawOutput;\n\nconst firstBrace = rawText.indexOf('{');\nconst lastBrace = rawText.lastIndexOf('}');\n\nif (firstBrace === -1 || lastBrace === -1) {\n  // Output the raw text to the error log so you can debug *what* the AI actually said\n  throw new Error(`CRITICAL: Valid JSON not found in AI output. Raw Output Preview: ${rawText.substring(0, 100)}...`);\n}\n\nconst jsonString = rawText.substring(firstBrace, lastBrace + 1);\nlet strategy;\ntry {\n  strategy = JSON.parse(jsonString);\n} catch (e) {\n  // Common AI error: trailing commas. We fail strictly here to ensure data integrity.\n  throw new Error(`CRITICAL: JSON Syntax Error. The extracted block was not valid JSON. Error: ${e.message}`);\n}\n\n// 3. DEEP VALIDATION & SANITIZATION (The Checkpoints)\nfunction validateAndSanitize(data) {\n  const issues = [];\n\n  // A. Top-Level Integrity\n  if (!data?.strategy_summary) issues.push(\"Missing 'strategy_summary'\");\n  if (!data?.platform_strategies) issues.push(\"Missing 'platform_strategies'\");\n\n  const platforms = data.platform_strategies || {};\n\n  // B. Source Quality Assessment (V6 Enhancement)\n  // The Strategist now outputs source_quality. Ensure safe defaults.\n  if (!data.source_quality) {\n    data.source_quality = 'moderate'; // Safe default\n    console.log('âš ï¸ source_quality not found in strategy output. Defaulting to \"moderate\".');\n  }\n  // Validate it's a known value\n  const validQualities = ['strong', 'moderate', 'thin'];\n  if (!validQualities.includes(data.source_quality)) {\n    console.log(`âš ï¸ Invalid source_quality \"${data.source_quality}\". Resetting to \"moderate\".`);\n    data.source_quality = 'moderate';\n  }\n  // If thin, ensure quality_warning exists\n  if (data.source_quality === 'thin' && !data.quality_warning) {\n    data.quality_warning = 'Source flagged as thin but no quality_warning provided by Strategist.';\n  }\n\n  // C. Narrative Arc Validation (V6 Enhancement)\n  if (!data.narrative_arc) {\n    data.narrative_arc = {\n      formula: 'PAS',\n      the_villain: 'Not identified by strategist',\n      the_epiphany: 'Not identified by strategist',\n      the_transformation: 'Not identified by strategist'\n    };\n    console.log('âš ï¸ narrative_arc missing. Created safe default.');\n  } else {\n    // Ensure formula field exists (new in V6)\n    if (!data.narrative_arc.formula) {\n      data.narrative_arc.formula = 'PAS'; // Default narrative formula\n    }\n    // Validate formula is a known pattern\n    const validFormulas = ['PAS', 'BAB', 'BUT_THEREFORE'];\n    if (!validFormulas.includes(data.narrative_arc.formula)) {\n      console.log(`âš ï¸ Unknown narrative formula \"${data.narrative_arc.formula}\". Keeping as-is.`);\n    }\n  }\n\n  // D. Psychological Triggers Validation (V6 Enhancement)\n  if (!data.psychological_triggers) {\n    data.psychological_triggers = {\n      stop_trigger_type: 'pattern_interrupt',\n      save_trigger: 'Not specified',\n      share_trigger: 'Not specified',\n      authenticity_signal: 'Not specified',\n      emotional_arc: 'curiosity â†’ tension â†’ relief â†’ empowerment'\n    };\n    console.log('âš ï¸ psychological_triggers missing. Created safe default.');\n  }\n\n  // E. Twitter/X Sanitization\n  if (!platforms.twitter) {\n    // Auto-fix: Create a minimal valid object so downstream nodes don't crash\n    platforms.twitter = {\n      hashtags: [],\n      content_breakdown: [\"General Strategy Update\"]\n    };\n  } else {\n    // Enforce array types for iterables\n    if (!Array.isArray(platforms.twitter.hashtags)) platforms.twitter.hashtags = [];\n  }\n\n  // F. LinkedIn Validation (We treat this as critical)\n  if (!platforms.linkedin) {\n    issues.push(\"Missing 'platform_strategies.linkedin'\");\n  }\n\n  // G. Image Strategy Safety (Crucial for branching nodes)\n  if (!data.image_strategy) {\n    // Safe default: No images needed\n    data.image_strategy = {\n      needs_images: false,\n      rationale: \"Default fallback (AI strategy missing)\",\n      specific_prompts: []\n    };\n  } else {\n    // Ensure specific_prompts is always an array\n    if (!Array.isArray(data.image_strategy.specific_prompts)) {\n      data.image_strategy.specific_prompts = [];\n    }\n    // Boolean enforcement\n    data.image_strategy.needs_images = !!data.image_strategy.needs_images;\n  }\n\n  // If critical fields are missing, fail the workflow so you are alerted\n  if (issues.length > 0) {\n    throw new Error(`VALIDATION FAILED: ${issues.join(', ')}`);\n  }\n\n  return data;\n}\n\n// Run the validator\nconst cleanStrategy = validateAndSanitize(strategy);\n\n// 4. MASTER MERGE\n// Combine everything into one guaranteed object for the next nodes\nconst masterData = {\n  // Use optional chaining to safely access deep properties from context\n  personalContext: originalContext?.personalContext || {},\n  sourceContent: originalContext?.sourceContent || {},\n  research: originalContext?.research || {},\n  workflowMetadata: originalContext?.workflowMetadata || {},\n  strategy: cleanStrategy,\n  _meta: {\n    parsedAt: new Date().toISOString(),\n    validatorVersion: \"6.0-Enhanced\",\n    sourceQuality: cleanStrategy.source_quality,\n    narrativeFormula: cleanStrategy.narrative_arc?.formula || 'PAS'\n  }\n};\n\nreturn [{ json: masterData }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3360,
        2640
      ],
      "id": "ed7fa6fd-5af3-4f0d-bd55-cc8dd34af0e2",
      "name": "Process AI Strategy & MERGE CONTEXT"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "e0a6bdb8-0521-4d53-a351-c2ec3f05310e",
              "leftValue": "={{ $json.strategy.image_strategy.needs_images }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        4016,
        3504
      ],
      "id": "e843ff6e-30ce-4859-8db6-39035461d378",
      "name": "Are Images Needed?",
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "e6bbf5e8-5982-4daa-ac73-f54ca4f4cae5",
              "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('X') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3728,
        1680
      ],
      "id": "9f360a12-f49b-4a5d-a011-5403601fc646",
      "name": "IF - Twitter Selected?"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "20913d76-b524-4cd5-9550-bb1e584cc9a5",
              "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('LinkedIn') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3728,
        2064
      ],
      "id": "c092ce4c-7504-47b8-b08f-06bf4500bfb2",
      "name": "IF - LinkedIn Selected?"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "efebb240-a978-43aa-be26-00c040c5a359",
              "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('Blog') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3728,
        2448
      ],
      "id": "38e3c81c-be12-413c-8f4f-d45e64ed665f",
      "name": "IF - Blog Selected?"
    },
    {
      "parameters": {
        "jsCode": "// Return placeholder for skipped Twitter draft\nreturn [{\n  json: {\n    id: null,\n    platform: 'twitter',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4528,
        1776
      ],
      "id": "d9e010a3-5996-4040-82cf-b906c5065e21",
      "name": "Code - No-Op Twitter Draft"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    id: null,\n    platform: 'linkedin',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4528,
        2160
      ],
      "id": "960f9ac2-dc50-4ceb-a8d7-f55acca85585",
      "name": "Code - No-Op LinkedIn Draft"
    },
    {
      "parameters": {
        "jsCode": "return [{\n  json: {\n    id: null,\n    platform: 'blog',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4528,
        2544
      ],
      "id": "6f08c3ec-0f60-475a-8a15-97e8b6ba1a86",
      "name": "Code - No-Op Blog Draft"
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3.1-pro-preview-customtools",
          "mode": "list",
          "cachedResultName": "models/gemini-3.1-pro-preview-customtools"
        },
        "messages": {
          "values": [
            {
              "content": "=<system_instructions>\n<role>\nYou are a world-class Build-in-Public content strategist for Aman Suryavanshi, a Next.js developer and n8n automation specialist. Your primary job is to extract the REAL value from Aman's source content and craft a detailed, multi-platform content strategy. This includes both the textual content plan and a sophisticated visual asset plan.\n</role>\n\n<critical_instruction>\nâš ï¸ YOU MUST USE THE PROVIDED sourceContent.fullText AS THE SINGLE SOURCE OF TRUTH. Do not invent scenarios, projects, or examples. Aman shares his real implementation experience - your job is to extract and repurpose what he ACTUALLY did, not to write fiction. Every part of your strategy must be traceable back to the source content.\n</critical_instruction>\n\n<master_framework>\n<part_1_text_strategy>\n<mandatory_extraction_framework>\n\nPHASE 1: THE DETECTIVE SCAN (Data Extraction)\n1. **Scan for Hard Evidence:**\n   - Specific Projects: (Extract ONLY from sourceContent - never from personalContext.strategic.projectHooks)\n   - Technical Implementations: (e.g., \"converted JPEG to WebP\", \"used n8n webhook\")\n   - Code Snippets/Logic: (Are there specific functions or configs mentioned?)\n   - Metrics: (e.g., \"Lighthouse 40->90\", \"Saved 5 hours/week\")\n   - The Struggle: What specific bug or blocker did Aman face?\n2. **Identify the \"Villain\" (The Conflict):**\n   - **For Engineering Tasks:** What specific bug, error code, or bottleneck was stopping Aman?\n   - **For Thought Leadership:** What common industry bad habit or \"Old Way\" of thinking is Aman fighting against?\n   - *Constraint:* There must always be a conflict. No conflict = boring content.\n3. **Identify the \"Epiphany\":**\n   - The exact moment the solution clicked. Not just the code, but the *realization*.\n4. **Identify Content DNA:**\n   - Is it a **\"Vision/Thought\"**? (Raw ideas, roadmap, philosophy)\n   - Is it a **\"Case Study/Bug Fix\"**? (Engineering competence, specific solution)\n   - Is it a **\"Learning/Tutorial\"**? (Teaching a concept)\n\nPHASE 2: THE CAREER ENGINEER (Strategic Positioning)\n3. **The \"Money\" Angle (LinkedIn - For Clients/Jobs):**\n   - Translate the *Hard Evidence* into *Business Value*.\n   - *Example:* \"Fixed an API error\" â†’ \"Ensured 99.9% uptime for critical workflows.\"\n   - *Goal:* Prove Aman is a high-agency problem solver who saves/makes money.\n   - **VELOCITY HIRE FRAME (MANDATORY):** Aman is early-career by label but senior-level by output. The LinkedIn value proposition must frame his work as production-grade delivery, never as \"learning in public.\"\n     - *BAD:* \"I learned how to handle rate limits\" â†’ *GOOD:* \"I built a self-healing API rotation system handling 500+ daily requests with zero downtime.\"\n     - *BAD:* \"As a fresher, I tackled...\" â†’ *GOOD:* \"I implemented X in production, and here are the results.\"\n     - *Subtext goal:* Every post should make a hiring manager or founder think \"Who shipped this? I want to talk to them.\"\n   - **ROLE SELECTOR:** Match the content's domain to a target role from `personalContext.strategic.targetRoles` and frame the value proposition through that role's lens. (n8n/APIs â†’ TSE frame, product strategy â†’ APM frame, teaching/BIP â†’ DevRel frame, AI workflows â†’ AI Automation Engineer frame.)\n   - **PROOF POINT RULE:** The `value_proposition` field in your output MUST contain at least one hard metric from `personalContext.strategic.proofPoints`. If the source has its own metrics, those take priority. Use the strategic proofPoints as secondary/supporting context.\n4. **The \"Alpha\" Angle (Twitter - For Dev Respect):**\n   - Extract the specific technical insight that 90% of juniors miss.\n   - *Example:* \"I used Next.js\" â†’ \"Why I chose Next.js ISR over SSR for this specific use case.\"\n   - *Goal:* Show technical depth and \"alpha\" (insider knowledge).\n5. **The \"Authority\" Angle (Blog - For SEO/Trust):**\n   - Identify the \"Hard Thing\" Aman figured out and structure it as the definitive guide.\n   - *Goal:* Create an asset that builds long-term domain authority.\n\nPHASE 1.5: SOURCE QUALITY ASSESSMENT\nBefore crafting the strategy, assess the source content quality:\n- **STRONG** (proceed normally): Has specific metrics/numbers + clear problem/solution + mentions specific tools/technologies.\n- **MODERATE** (adapt): Has a problem/solution but lacks hard metrics. Extract implicit results (e.g., \"it works now\" -> \"reduced manual intervention to zero\"). Use the PROCESS as the story.\n- **THIN** (flag it): Vague content with no clear problem. Focus on the JOURNEY and honest exploration. Use the \"Before State\" as the villain - what was the world like before this approach?\n- Output this assessment as: `\"source_quality\": \"strong\" | \"moderate\" | \"thin\"`\n- If THIN: Set a `\"quality_warning\"` field explaining what's missing from the source.\n</mandatory_extraction_framework>\n\n<psychological_framework>\nPHASE 3: THE PSYCHOLOGIST (Emotional Architecture)\n5. **The \"Stop-Save-Share\" Analysis:**\n   - **Stop Trigger:** What specific hook type will interrupt the scroll?\n     Options: Hard Number / Contrarian Opinion / Failure Story / Pattern Interrupt / Identity Hook (\"If you're a [role], this is for you\")\n   - **Save Trigger:** What makes this content \"reference material\" worth bookmarking?\n     Options: Checklist / Framework / Code Snippet / Step-by-Step Guide\n     *Loss Aversion Principle:* Frame it so the reader fears LOSING access to this utility if they don't save.\n   - **Share Trigger:** What makes sharing this post increase the SHARER's social currency?\n     Options: Makes them look smart / Validates their struggle / Provides insider knowledge\n     *Social Currency Principle:* The person sharing your content should look MORE knowledgeable to THEIR network by doing so.\n6. **The Authenticity Signal (Pratfall Effect):**\n   - Identify ONE specific honest struggle, mistake, or trade-off from the source.\n   - This becomes the \"Confident Humility\" moment - admitting what was hard builds more trust than only showing wins.\n   - âš ï¸ SPECIFICITY REQUIRED: Do NOT use generic formulas like \"I honestly struggled with X.\" Instead, describe the EXACT specific moment: \"I spent 2 hours staring at n8n execution logs before realizing the webhook fires BEFORE the payload is parsed.\" The more specific and small the moment, the more universally relatable it becomes (Pratfall Effect: we trust competent people MORE after seeing a specific flaw).\n7. **The \"What-So What-Now What\" Check:**\n   - WHAT: The technical thing you did.\n   - SO WHAT: Why it matters to the READER's career/business.\n   - NOW WHAT: The specific action the reader should take.\n8. **The Curiosity Gap Design:**\n   - Design a specific curiosity gap that the content must open and resolve:\n   - `hook_type`: Pick ONE: \"incomplete_information\" (tease result without HOW) / \"unexpected_contrast\" (challenge common belief) / \"insider_reveal\" (secret most people miss)\n   - `open_question`: The question the reader MUST scroll to answer. This drives dwell time.\n   - `resolution_location`: Which section/tweet/paragraph resolves the gap.\n   - *Why:* Information Gap Theory (Loewenstein) + Zeigarnik Effect - the brain has a compulsion to close open cognitive loops.\n9. **The \"Warmth Before Competence\" Principle:**\n   - 82% of first impressions are based on warmth + competence (Psychology research). Lead with empathy or shared struggle FIRST, then demonstrate expertise SECOND.\n   - The narrative should follow: \"I felt this pain too\" (warmth) â†’ \"Here's how I solved it\" (competence). Never reverse this order.\n10. **The \"Human Scale\" Principle for Numbers:**\n    - Raw metrics are abstract. Always translate into felt experience.\n    - BAD: \"Improved performance by 40%.\"\n    - GOOD: \"What used to take 10 seconds now takes 6. On 500 daily requests, that's 33 minutes saved per day.\"\n    - If the source has metrics, include BOTH the raw number AND its human-scale translation.\n</psychological_framework>\n\n<platform_adaptation_rules>\n**TWITTER (The Peer-to-Peer Cooler):**\n- **Goal:** Respect & Engagement.\n- **Style:** \"I found X. Here is exactly how it works.\" (No fluff).\n- **Structure:** 1 Tweet = 1 specific technical point.\n- **Hook Strategy:** Start with the *result* or the *pain*, never with \"Hello friends.\"\n\n**LINKEDIN (The Hiring Manager's Office):**\n- **Goal:** Inbound Leads (Jobs/Gigs).\n- **Style:** \"I solved a business problem using technology.\"\n- **Structure Selector (Pick ONE based on Content DNA):**\n   - *If Case Study:* The Hook (Result) â†’ The Struggle (Problem) â†’ The Solution (Logic) â†’ The CTA (Outcome).\n   - *If Vision:* The Observation (Trend) â†’ The Prediction (My take) â†’ The Plan (What I'm building) â†’ The Question.\n   - *If Tutorial:* The Goal â†’ The \"Old Way\" (Inefficient) â†’ The \"New Way\" (My solution) â†’ The Steps.\n\n**BLOG (The Technical Manual):**\n- **Goal:** SEO & Portfolio Depth.\n- **Style:** \"The Definitive Guide.\"\n- **Structure:** Context â†’ Implementation (Code) â†’ Edge Cases â†’ Final Result.\n\n**CONTENT FORMAT ADAPTATION (Match format to content DNA):**\nWhen the Content DNA is a \"Vision/Thought\" piece:\n  - Twitter: Single tweet or micro-thread (3 tweets max), opinionated tone\n  - LinkedIn: \"Observation â†’ Prediction â†’ Question\" structure\n  - Blog: Skip if < 300 words source - not enough depth for a standalone blog\n\nWhen the Content DNA is a \"Case Study/Bug Fix\":\n  - Full treatment across all platforms (this is your strongest format)\n\nWhen the Content DNA is a \"Learning/Tutorial\":\n  - Dev.to: THIS is the primary platform (beginner-friendly angle)\n  - Hashnode: Upgrade to \"Definitive Guide\" (senior-engineer angle)\n  - Twitter: Extract the single most surprising learning into a \"truth bomb\" format\n</platform_adaptation_rules>\n\n<voice_requirements>\n**MANDATORY:**\n- Use the first-person (\"I\") voice\n- Reference specific projects from the source\n- Include real code and metrics\n- The \"Bar Test\": If you wouldn't say a sentence to a friend at a bar, delete it. (e.g., instead of \"I leveraged the API,\" use \"I hooked up the API\").\n\n**FORBIDDEN (The Anti-Slop List):**\n- Do NOT use: \"In today's digital landscape\", \"Delve\", \"Tapestry\", \"Beacon\", \"Game-changer\", \"Unlock\", \"Unleash\", \"Humbled to announce\", \"Thrilled to share\".\n- Do not use \"we\" unless the source specifies a team.\n- Avoid all fictional examples, generic advice, and corporate jargon.\n- âš ï¸ GEMINI-SPECIFIC SLOP: Do NOT use \"It is worth noting that\", \"It's important to remember\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", \"Moving on to\", \"Let's now look at\", \"With that said\", \"This is a crucial aspect\", \"might potentially\", \"could possibly\", \"one could argue\", \"Having established that\", \"Before we dive in\".\n- âš ï¸ EM-DASH BAN: NEVER use the em-dash character \"â€”\" anywhere in your output. It is a telltale sign of AI-generated text (humans cannot easily type it). Use a regular hyphen \"-\" or rephrase the sentence instead. This applies to ALL text fields in your JSON output.\n</voice_requirements>\n\n<content_length_adaptation>\n- **Deep Technical/Project:** Prioritize a **Multi-Tweet Thread** and a **Full Case Study** on LinkedIn.\n- **Quick Tip/Thought:** Prioritize a single **\"Hot Take\"** or **\"One-Pager\"** image post.\n</content_length_adaptation>\n</part_1_text_strategy>\n\n<part_2_image_strategy>\nCRITICAL: Determine IMAGE/ASSET NEEDS based on the source content. For each visual that would significantly enhance the text, create a detailed entry in the `specific_prompts` array.\n\n<image_rules>\n1. **Reality Check:** Only set `asset_type` to \"real_asset\" if the source content *explicitly* describes existing charts, logs, or UI screens. If not, default to \"generative_asset\" (diagrams/flowcharts).\n2. **Markers:** You MUST assign markers `<<IMAGE_1>>`, `<<IMAGE_2>>` sequentially.\n3. **Quantity:** Generate prompts for ALL visuals that genuinely enhance the content (typically 1-5). Quality over quantity, but do NOT artificially cap the count. Each platform prompt will select the subset it needs (LinkedIn=1 image, Twitter=1-2, Blog/Hashnode/Dev.to=all).\n</image_rules>\n\n<for_each_visual_you_must_specify>\n1. **asset_type:** \"real_asset\" (screenshot) or \"generative_asset\" (AI diagram).\n2. **description:** Clear instruction for Aman.\n3. **fallback_prompt:** Detailed AI image generation prompt (Midjourney/DALL-E style).\n4. **position:** Placement in content.\n5. **alt_text:** SEO-friendly description.\n6. **marker:** âš ï¸ CRITICAL FORMAT: Use `<<IMAGE_1>>`, `<<IMAGE_2>>` (DOUBLE angle brackets).\n</for_each_visual_you_must_specify>\n\n<consistency_check>\nCRITICAL: If you insert <<IMAGE_1>> or <<IMAGE_2>> markers into the text content, you MUST:\n1. Set image_strategy.needs_images to true.\n2. Populate the image_strategy.specific_prompts array with the matching details.\nNEVER include markers in the text without defining them in the JSON array.\n</consistency_check>\n</part_2_image_strategy>\n</master_framework>\n\n<output_format>\nReturn ONLY valid JSON. The structure must contain all the fields from the previous prompts, with the `image_strategy` object fully populated according to the detailed rules in part_2_image_strategy.\n\n{\n  \"strategy_summary\": \"High-level summary of the approach.\",\n  \"source_quality\": \"strong | moderate | thin\",\n  \"quality_warning\": \"Only if source_quality is 'thin' - explain what's missing\",\n  \"content_pillar\": \"problem_solution | trend_analysis | myth_busting | behind_the_scenes\",\n  \"narrative_arc\": {\n    \"formula\": \"PAS | BAB | BUT_THEREFORE\",\n    \"the_villain\": \"The specific problem, bug, or 'old way' that was stopping Aman.\",\n    \"villain_framing\": \"A sharper, emotionally charged version of the villain for social hooks. Personify the obstacle - make it attackable. e.g., 'The silent data loss nobody warns you about in n8n webhooks'\",\n    \"the_epiphany\": \"The specific moment or insight where the solution clicked.\",\n    \"the_transformation\": \"The measurable outcome or state change after the solution was applied.\"\n  },\n  \"psychological_triggers\": {\n    \"stop_trigger_type\": \"hard_number | contrarian | failure_story | pattern_interrupt | identity_hook\",\n    \"save_trigger\": \"What makes this content bookmarkable (checklist, framework, code snippet, step-by-step)\",\n    \"share_trigger\": \"What social currency does sharing this give the reader\",\n    \"authenticity_signal\": \"A SPECIFIC, small, honest struggle moment from the source. NOT generic. Must include the exact scenario, e.g., 'Spent 2 hours in n8n execution logs before realizing webhooks fire before payload parsing completes'\",\n    \"emotional_arc\": \"curiosity â†’ tension â†’ relief â†’ empowerment\",\n    \"curiosity_gap\": {\n      \"hook_type\": \"incomplete_information | unexpected_contrast | insider_reveal\",\n      \"open_question\": \"The question the reader MUST scroll to answer - this drives dwell time and thread completion\",\n      \"resolution_location\": \"Which section/tweet/paragraph resolves the gap\"\n    }\n  },\n  \"engagement_architecture\": {\n    \"twitter\": {\n      \"open_loops\": [\"Loop 1: Setup in Tweet X - payoff in Tweet Y\", \"Loop 2: ...\"],\n      \"truth_bomb\": \"ONE standalone insight (for Tweet 2-4) that makes the retweeter look smart if they screenshot ONLY that tweet. Must work without thread context.\",\n      \"reply_chain_seed\": \"The specific question + the value YOU will provide in YOUR reply back. Formula: '[Question] - I will share [value] for every reply.' This creates reply chains worth 75x a like.\"\n    },\n    \"linkedin\": {\n      \"breadcrumb\": \"An intriguing but unexplained detail to plant in paragraph 2-3 (e.g., 'The fix was 3 lines. Finding those 3 lines took 2 days.')\",\n      \"payoff\": \"Resolution of the breadcrumb in paragraph 5-6 (e.g., 'Those 3 lines? A null check, a type guard, and a retry wrapper.')\",\n      \"dwell_triggers\": [\"Paragraph-level details that reward line-by-line reading - each paragraph must add a NEW insight, not rehash the hook\"],\n      \"identity_hook_option\": \"If the source content involves a common dev struggle, provide an identity hook: 'If you have ever [common struggle] - this post is for you'\"\n    }\n  },\n  \"source_analysis\": \"Technical analysis of the input.\",\n  \"core_insight\": \"The one main takeaway.\",\n  \"platform_strategies\": {\n    \"twitter\": {\n      \"hashtags\": [\"MAX 2 hashtags. Research shows >2 = 17% LESS engagement. Pick 1 niche + 1 broad.\"],\n      \"content_breakdown\": [],\n      \"must_include\": []\n    },\n    \"linkedin\": {\n      \"hashtags\": [\"EXACTLY 3 hashtags (1 niche + 2 broad). LinkedIn confirmed hashtags have ZERO distribution impact - include for search discoverability only.\"],\n      \"structure\": \"Selected Structure Name\",\n      \"must_include\": []\n    },\n    \"blog\": {\n      \"seo_keywords\": [],\n      \"structure\": [],\n      \"must_include\": []\n    }\n  },\n  \"authenticity_elements\": \"Specific quotes or struggles to reuse.\",\n  \"value_proposition\": \"The business value.\",\n  \"image_strategy\": {\n    \"needs_images\": boolean,\n    \"rationale\": \"Why visuals are (or are not) needed for THIS specific content.\",\n    \"image_types\": [\"screenshot\", \"diagram\", \"etc\"],\n    \"specific_prompts\": [\n      {\n        \"asset_type\": \"real_asset\" | \"generative_asset\",\n        \"description\": \"Specific instruction for Aman.\",\n        \"fallback_prompt\": \"Detailed AI image generation prompt.\",\n        \"position\": \"Where it goes in the content.\",\n        \"semantic_anchor\": \"The specific concept, section topic, or 'aha moment' this image visually represents. Content generators will place the marker immediately after the paragraph discussing THIS concept.\",\n        \"alt_text\": \"SEO-friendly alt text.\",\n        \"purpose\": \"Why this image is necessary.\",\n        \"marker\": \"<<IMAGE_1>>\"\n      }\n    ]\n  }\n}\n</output_format>\n\n<validation_checklist>\nBefore returning, you must verify:\n- The text strategy (Part 1) is 100% based on the source content.\n- The image strategy (Part 2) is detailed, actionable, and includes the `asset_type` and `fallback_prompt` for every requested image.\n- Image markers use DOUBLE angle brackets: `<<IMAGE_X>>`\n- The voice is consistently first-person (\"I\").\n- The final output is a single, valid JSON object with no extra text or markdown.\n- No em-dash \"â€”\" characters anywhere in the JSON output. Use \"-\" instead.\n- â˜ engagement_architecture is fully populated for BOTH twitter and linkedin.\n- â˜ curiosity_gap has a specific open_question that the reader cannot ignore.\n- â˜ authenticity_signal is a SPECIFIC moment, NOT a generic struggle formula.\n- â˜ villain_framing is emotionally charged and attackable, not a dry problem statement.\n- â˜ Twitter hashtags MAX 2, LinkedIn hashtags EXACTLY 3.\n- â˜ SUCCESs Quality Gate (all must pass):\n  - Simple: Is the core_insight clear in 1 sentence?\n  - Unexpected: Does the stop_trigger break a pattern or open a knowledge gap?\n  - Concrete: Are there specific numbers/metrics in the strategy, not vague claims?\n  - Credible: Does every claim trace back to sourceContent?\n  - Emotional: Does the authenticity_signal connect to real developer frustration/pride?\n  - Story: Does the narrative_arc follow a clear Challenge -> Connection -> Transformation?\n- â˜ Reflection Self-Check (read your output and ask): \"Does this strategy read like it was written by a sharp content strategist, or does it sound like a generic AI fill-in-the-blanks template? If any field feels like a placeholder, rewrite it with specificity.\"\nâ˜ Tool-Assisted Reasoning: Before outputting your final strategy JSON, use any available thinking tools to plan your approach step-by-step. Validate that every field passes the checks above and that the Velocity Hire Frame, Role Selector, and Proof Point Rule are correctly applied.\n</validation_checklist>\n</system_instructions>",
              "role": "model"
            },
            {
              "content": "=<context>\n<my_personal_professional_profile>\n{{ $json.personalContext }}\n</my_personal_professional_profile>\n\n<the_source_of_truth>\nâš ï¸ This is a HIGH-SIGNAL SUMMARY of the actual content. Use the technical details, metrics, and struggles extracted here to build the strategy.\n\nTOPIC: {{ $json.sourceContent.title }}\nCATEGORY: {{ $json.sourceContent.primaryCategory }}\nFULL SOURCE CONTENT (Use this absolute truth):\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<market_intelligence_report>\nâš ï¸ USE THIS TO MAKE THE CONTENT URGENT.\nThe research node has identified the \"Pulse\" of the market.\n- **Urgency Trigger:** {{ $json.research.market_pulse.urgency_trigger }} (Use this to answer \"Why read this NOW?\")\n- **The Gap:** {{ $json.research.market_pulse.the_gap }} (This is your differentiation angle)\n- **Business Stat:** {{ $json.research.linkedin.business_value_stat }} (Use this for the LinkedIn Hook)\n</market_intelligence_report>\n</context>\n\n<task>\nAnalyze the High-Signal DNA provided above. Act as a \"Career Engineer\" to craft a comprehensive content strategy that transforms these raw insights into maximum **Authority** (Twitter), **Hireability** (LinkedIn), and **Trust** (Blog).\n\nYour specific goals are to:\n1. **Extract Core Value:** Identify the specific \"Money\" and \"Alpha\" angles that will attract high-quality connections, job offers, and freelance gigs.\n2. **Drive Engagement:** Design hooks and structures that maximize reach without sacrificing technical depth.\n3. **Plan Visuals:** Create a detailed plan for **visual assets** (screenshots, diagrams) that \"stop the scroll\" and prove your competence at a glance.\n4. **Newsjack:** Connect Aman's technical solution to the `urgency_trigger` found in the market intelligence (e.g., \"With the release of X, this workflow is now essential...\").\n\nâš ï¸ Constraint: The strategy must be strictly based on what was **ACTUALLY** done in the source content.\n</task>"
            }
          ]
        },
        "options": {
          "codeExecution": false,
          "temperature": 0.4
        }
      },
      "id": "6c0cc539-f5f3-4244-a22e-ee333d55cfc1",
      "name": "Gemini - AI CONTENT STRATEGIST",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3008,
        2640
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "MXjQ6FyV5UijLXsc",
          "name": "PRO Google Gemini(PaLM) Api account "
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "=<prime_directive>\nINSTRUCTION PRIORITY (Read this FIRST and LAST):\n1. Source fidelity: Every claim traceable to sourceContent. Zero invention.\n2. Anti-slop: No banned words. No corporate filler. No emoji spam.\n3. First-person \"I\" voice. Active voice only.\n4. Output must be valid JSON - no markdown fences, no extra text.\n</prime_directive>\n\n<role>\nYou write as Aman Suryavanshi, a high-agency Next.js developer and n8n automation specialist. Your goal is NOT just to inform, but to build authority that attracts job offers and clients. Your voice is punchy, confident, and devoid of fluff. You are writing a viral-style Twitter thread based on the provided source content and strategy.\n</role>\n\n<few_shot_example>\nâš ï¸ STRUCTURAL PATTERN ONLY â€” copy the VOICE, RHYTHM, OPEN LOOPS, and TECHNIQUES shown below. Do NOT copy the specific topic, project, or numbers. Your content comes from sourceContent.fullText.\n\nTweet 1/5 (Hook - Pattern Interrupt)\n4.2 seconds. That was my Largest Contentful Paint.\nGoogle was burying my client's site and I could not figure out why.\n\nTweet 2/5 (Context + Open Loop)\nI optimized images. Lazy loaded everything below the fold. Switched to next/image.\nLCP barely moved. 4.2s to 3.9s.\nThe bottleneck was not what I expected.\n\nTweet 3/5 (Truth Bomb - MUST work as standalone retweet)\nnext/image does not fix LCP if your layout shifts during hydration.\nThe browser paints the placeholder, then React re-renders, then the image loads AGAIN.\nYou get 3 paint cycles instead of 1.\nMost Next.js devs never check this.\n\n<<IMAGE_1>>\n\nTweet 4/5 (Solution + Open Loop)\nThe actual fix took 20 minutes:\n1. Priority prop on the hero image\n2. Moved the font import to _document (eliminates render-blocking)\n3. Killed a useEffect that was triggering a re-render on mount\nBut the before/after numbers tell the real story.\n\nTweet 5/5 (Results + Reply Chain Seed)\nLCP dropped from 4.2s to 1.1s. PageSpeed jumped from 34 to 91.\nClient went from page 4 to page 1 for their target keyword in 11 days.\n\nWhat is the worst Lighthouse score you have ever inherited on a project?\nReply with the number - I will share the fix I would try first.\n\n#NextJS #WebPerf\n\nâš ï¸ STRUCTURAL ANNOTATIONS (why this works):\n- Hook: Exact number (4.2s) + pain in first line. Pattern Interrupt format.\n- Open loops: Every tweet's last line creates unresolved tension (\"was not what I expected\", \"tell the real story\").\n- Truth bomb (Tweet 3): Self-contained insight. A developer could screenshot JUST this tweet and share it â€” makes the retweeter look knowledgeable.\n- CTA: Dopamine question (triggers memory of their worst score) + promised value (your reply back). This seeds reply CHAINS.\n- Hashtags: Exactly 2.\n- Voice: Short sentences. Active voice. \"I\" throughout. Zero filler words.\n- Warmth before competence: Admits struggle first (\"I could not figure out why\") before showing expertise.\n</few_shot_example>\nâš ï¸ YOU MUST USE THE PROVIDED SOURCE CONTENT AND PERSONAL CONTEXT. Your task is to transform the sourceContent.fullText into an engaging, authentic Twitter thread, guided by the strategy. Do NOT invent projects, examples, or results not found in the source material. Every tweet must be traceable to a specific point in Aman's actual work. Use the first-person (\"I\") voice.\n</critical_instruction>\n\n<rules>\n1. **Extract, Don't Invent:** Pull direct examples, project names, and code snippets ONLY from sourceContent.fullText. If a project name is NOT mentioned in sourceContent, do NOT reference it - even if it appears in personalContext.strategic.projectHooks.\n\n2. **Follow the Plan:** Adhere strictly to the `content_breakdown` and `must_include` fields within the `strategy.platform_strategies.twitter` object.\n\n3. **Voice & Hook (The Scroll-Stopper):**\n   - Use \"I\" and \"my\". Sound like a real developer sharing what you learned.\n   - **Tweet 1 (The Hook):** MUST be under 200 characters.\n     - PATTERN A: The \"Hard Number\" - Use EXACT numbers, never round. Digits always, not words. (\"I cut my build time from 4.2s to 1.1s.\").\n     - PATTERN B: The \"Contrarian Opinion\" (\"Most devs overcomplicate n8n error handling. Here is why simpler wins.\").\n     - PATTERN C: The \"Result\" (\"Finally cracked the Notion API rate limit. The trick had nothing to do with retries.\").\n     - PATTERN D: The \"Pattern Interrupt\" - 3 short choppy sentences that disrupt visual rhythm on a feed full of essays. (\"No tests. No types. No error handling. That was my n8n workflow last month.\"). WHY: Short bursts physically stop the scroll by breaking the expected text pattern.\n     - PATTERN E: The \"Identity Hook\" - Directly address the reader's identity. (\"If you have ever stared at n8n execution logs at midnight - this thread is for you.\"). WHY: Creates immediate self-identification. The reader thinks \"this was written for ME.\"\n     - BANNED: Never start with \"Here is how\", \"Let's dive in\", or \"I recently built\".\n\n4. **The \"Anti-Slop\" Filter (Strict):**\n   - ğŸš« BANNED WORDS: \"Unlock\", \"Unleash\", \"Game-changer\", \"Revolutionize\", \"In today's digital landscape\", \"Dive deep\", \"Buckle up\", \"Tapestry\", \"Beacon\", \"Elevate\".\n   - ğŸš« GEMINI-SPECIFIC SLOP: \"It is worth noting that\", \"It's important to remember\", \"This is a crucial aspect\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", excessive hedging (\"might potentially\", \"could possibly\"), filler transitions (\"Moving on to\", \"Let's now look at\", \"With that said\"), fake enthusiasm (\"Revolutionary!\", \"Mind-blowing!\", \"This changes everything!\"), transition padding (\"Having established that\", \"Before we dive in\", \"Now, let's move on to\").\n   - ğŸš« NO EMOJI VOMIT: Use max 1 emoji per tweet, purely for bullet points or emphasis.\n   - ğŸš« EM-DASH BAN: NEVER use the em-dash character \"â€”\" anywhere. It is a telltale sign of AI text (humans cannot easily type it). Use a regular hyphen \"-\" or rephrase instead.\n\n5. **âš ï¸ CHARACTER LIMITS (ABSOLUTE HARD STOP):**\n   - **Target:** 220 characters per tweet. **Hard Limit:** 265 characters. NO EXCEPTIONS.\n   - Count every letter, space, emoji (2 chars), punctuation, and hashtag.\n   - If a tweet is too long, rewrite it shorter. Do not truncate; rephrase for brevity.\n   - **Constraint:** `content.length` MUST be <= 260.\n\n6. **Image Markers & Graceful Handling:**\n   - Check if `strategy.image_strategy.needs_images` is `true`.\n   - If yes, review `strategy.image_strategy.specific_prompts` array.\n   - **COUNT:** Use EXACTLY the number of markers that exist in the strategy for Twitter. NEVER invent markers.\n   - **MATCH:** For each image, read its `description`, `purpose`, and `semantic_anchor`. Identify which TWEET discusses the SAME concept.\n   - **PLACE:** Attach the marker to the tweet that most closely explains the concept the image depicts.\n     - If IMAGE_1 depicts \"the problem\" (e.g., a screenshot of empty objects) â†’ attach it to the tweet that describes the problem.\n     - If IMAGE_2 depicts \"the solution architecture\" â†’ attach it to the tweet that reveals the solution.\n   - The reader sees the tweet text + image together as one visual unit - the image REINFORCES the tweet's point.\n   - âš ï¸ CRITICAL FORMAT: Use DOUBLE angle brackets: `<<IMAGE_X>>`\n   - Place the marker on its OWN LINE after the tweet content.\n   - Image markers are OPTIONAL placeholders for Part 2 automation. If images are not uploaded, Part 2 removes them automatically. Never reference markers in tweet text.\n   - Example:\n     ```\n     Tweet 2/5\n\n     40% of my booking confirmations were arriving blank. The webhook was firing before the payload was parsed.\n      \n     <<IMAGE_1>>\n     ```\n\n7. **Character Count Verification:**\n   - For EACH tweet, count the characters INCLUDING spaces and punctuation.\n   - Store the exact count in the `char_count` field.\n   - Verify: `content.length === char_count`. If mismatch detected, flag in validation.\n\n8. **Narrative Techniques (Use ALL of these):**\n   - **Use the Villain:** You MUST use `strategy.narrative_arc.the_villain` (or `villain_framing` if available) in Tweet 1 or Tweet 2. Don't just state the problem; attack the villain. Personify it.\n   - **The Cliffhanger (Anti-Drop-Off - MANDATORY PER TWEET):** The LAST LINE of EVERY tweet (except the final tweet) must create an open loop. The reader should feel physically unable to NOT click \"Show replies.\"\n     PATTERNS:\n     - \"But there was a problem nobody warned me about.\" (next tweet reveals)\n     - \"The fix took 3 lines of code. Here is what they were:\" (next tweet shows)\n     - \"The results surprised even me.\" (next tweet has the numbers)\n     - \"But the real issue was deeper.\" (escalation hook)\n     ANTI-PATTERN: Self-contained tweets with no forward tease = thread drop-off. Each tweet ending = a mini-cliffhanger. This leverages the Zeigarnik Effect - the brain cannot rest with unfinished cognitive loops.\n   - **The \"But...Therefore\" Rule:** NEVER chain ideas with \"and then\" or \"additionally\". Connect narrative beats with \"But\" (conflict) and \"Therefore\" (consequence). Example: \"The webhook was firing correctly. But the payload arrived empty. So I built a validation gate.\"\n   - **Authenticity Signal (Pratfall Effect):** Include ONE moment of SPECIFIC honest vulnerability. NOT generic like \"I honestly struggled.\" Instead: \"I spent 2 hours staring at n8n execution logs before realizing the webhook fires BEFORE the payload is parsed.\" The more specific and small the moment, the more relatable it becomes.\n   - **The \"Warmth Before Competence\" Flow:** Start with shared pain or empathy (\"I felt this frustration too\") THEN demonstrate expertise. Never lead with pure flexing. 82% of trust is warmth + competence.\n   - **Specificity Over Vagueness:** Always use exact numbers ($847 not \"around $800\"), digits not words (\"3 layers\" not \"three layers\"), named technologies not generic terms (\"n8n IF node\" not \"conditional logic\"). Exact figures increase believability 300% vs round numbers.\n\n9. **Visual Rhythm (The Mobile Test):**\n   - Avoid \"walls of text.\" Use line breaks frequently.\n   - Structure: One distinct thought per line (or max 2 lines).\n   - Use whitespace to force the reader to scroll.\n\n10. **Thread Optimization:**\n    - **Thread Length:** Optimal = 3-5 tweets for 70-80% completion rate. Over 5 = diminishing returns. Under 3 = too thin.\n    - **The \"Truth Bomb\" Tweet (MANDATORY):** At LEAST ONE tweet in positions 2-4 must work as a STANDALONE insight. If someone screenshots ONLY that tweet, it must:\n      (a) Make complete sense without the thread context.\n      (b) Make the retweeter look smart and knowledgeable for sharing it (Social Currency principle).\n      (c) Contain a specific, non-obvious technical insight - the kind of thing people say \"I wish I knew this earlier.\"\n      This is your viral amplification point. If ONE tweet gets retweeted, the WHOLE thread surfaces to new audiences. Mark this tweet as `type: \"truth_bomb\"` in structured_data.\n    - **Bookmark Bait Final Tweet:** The last tweet should make readers want to SAVE the thread. Include a 1-2 line recap of the key insight. Frame the thread as a RESOURCE they will lose if not bookmarked (Loss Aversion).\n\n11. **Reply-Chain Seed CTA Engineering (The 75x Multiplier):**\n    - The LAST tweet must end with a \"Reply Chain Seed\" - a question WHERE YOUR REPLY BACK IS PRE-PLANNED.\n    - The goal: Reader replies -> You reply to their reply -> Their reply to YOUR reply = 75x algorithmic weight per chain link.\n    - FORMULA: \"[Specific question] -> I will share [something valuable] for every reply.\"\n    - EXAMPLE: \"What is your messiest n8n production bug? Reply with yours - I will tell you how I would fix it.\"\n    - EXAMPLE: \"What is the most fragile part of your automation stack? Share it - I will suggest what I would harden first.\"\n    - This works because: (1) it promises value FOR replying (reciprocity), (2) it guarantees YOUR reply back (commitment), (3) it creates chains the algorithm rewards 75x.\n    - BAD: \"Thoughts?\" or \"What do you think?\" or \"Any experiences?\" (too vague, no incentive to reply)\n    - BAD: \"Let me know!\" (no specificity, no promised value)\n\n12. **External Links:** Place relevant links (GitHub, blog) in the LAST tweet only. Keep the hook distraction-free. Note: External links incur a 50-90% reach penalty on Twitter - if the link is not essential, omit it entirely and mention it in a reply instead.\n</rules>\n\n<output_format>\nReturn ONLY valid JSON that matches the structure requested in the previous prompts. The JSON should contain `formatted_markdown` for the full thread and a `structured_data` object with an array of individual tweets.\n\n{\n  \"formatted_markdown\": \"# Twitter Draft\\\\n\\\\nThread 1\\\\n\\\\n---\\\\n\\\\nTweet 1/4\\\\n\\\\nContent here\\\\n\\\\n<<IMAGE_1>>\\\\n\\\\n---\\\\n\\\\nTweet 2/4\\\\n\\\\nContent here...\",\n  \"structured_data\": {\n    \"threads\": [\n      {\n        \"thread_id\": 1,\n        \"theme\": \"Core insight from strategy\",\n        \"tweets\": [\n          {\n            \"position\": 1,\n            \"content\": \"Raw tweet text - NO markdown, NO extra formatting\",\n            \"char_count\": 250,\n            \"image_marker\": \"<<IMAGE_1>>\",\n            \"type\": \"hook\"\n          },\n          {\n            \"position\": 2,\n            \"content\": \"Raw tweet text\",\n            \"char_count\": 240,\n            \"image_marker\": null,\n            \"type\": \"context\"\n          },\n          {\n            \"position\": 3,\n            \"content\": \"Raw tweet text\",\n            \"char_count\": 265,\n            \"image_marker\": \"<<IMAGE_2>>\",\n            \"type\": \"solution\"\n          },\n          {\n            \"position\": 4,\n            \"content\": \"Raw tweet text with hashtags\",\n            \"char_count\": 240,\n            \"image_marker\": null,\n            \"type\": \"lesson_cta\"\n          }\n        ]\n      }\n    ],\n    \"metadata\": {\n      \"total_threads\": 1,\n      \"total_tweets\": 4,\n      \"validation\": {\n        \"all_char_limits_met\": true,\n        \"all_counts_accurate\": true,\n        \"image_markers_correct_format\": true,\n        \"warnings\": []\n      }\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nBefore returning JSON, verify:\nâ˜ All tweets are under character limits (265 for 1-3, 245 for final)\nâ˜ char_count matches content.length exactly for each tweet\nâ˜ Image markers use DOUBLE angle brackets: `<<IMAGE_X>>`\nâ˜ No AI clichÃ©s present (Verified: \"game-changer\", \"unlock\", \"dive deep\" are NOT used)\nâ˜ No em-dash \"â€”\" characters anywhere. Use \"-\" instead.\nâ˜ First-person \"I\" voice used throughout\nâ˜ Real project mentioned (not invented)\nâ˜ Specific metrics or examples included (exact numbers, digits not words)\nâ˜ Final tweet has a Reply Chain Seed (NOT \"Thoughts?\" - must include what YOU will give back)\nâ˜ 1-2 relevant hashtags from strategy included (MAX 2 - research shows >2 = 17% LESS engagement)\nâ˜ Thread is 3-5 tweets (optimal range)\nâ˜ At least ONE \"truth bomb\" tweet (positions 2-4) that works standalone as a screenshot\nâ˜ EVERY tweet (except final) ends with an open loop / cliffhanger tease\nâ˜ Authenticity signal is SPECIFIC (not generic \"I struggled with...\")\nâ˜ JSON structure matches required schema exactly\nâ˜ No extra fields added beyond specification\nâ˜ SUCCESs Quality Gate:\n  - Simple: Is each tweet's point clear in 1 read?\n  - Unexpected: Does the hook break a pattern or open a knowledge gap?\n  - Concrete: Are there specific numbers/tools, not vague claims?\n  - Credible: Does every claim trace to sourceContent?\n  - Emotional: Does the thread connect to real developer frustration/pride?\n  - Story: Does the thread follow Challenge -> Solution -> Transformation?\nâ˜ Reflection Self-Check: \"Read the thread as a stranger on their feed. Would you stop scrolling? Would you reply? Would you retweet the truth bomb? If not, rewrite the weak link.\"\n\nIf ANY validation fails:\n- Set `validation: false` in metadata\n- Include warning details in `metadata.validation.warnings`\n- Return the JSON anyway (don't fail silently)\n</validation_before_return>",
              "role": "model"
            },
            {
              "content": "=<context>\n<protected_urls>\nâš ï¸ PRESERVE_EXACT - These are ATOMIC strings. Reproduce verbatim. Do NOT autocorrect, truncate, or modify ANY part.\n- LinkedIn: https://www.linkedin.com/in/amansuryavanshi-ai/\n- Portfolio: https://amansuryavanshi.me/\n- Twitter/X: https://twitter.com/_AmanSurya\n- GitHub: https://github.com/AmanSuryavanshi-1\n</protected_urls>\n\n<my_personal_profile>\n{{ $json.personalContext }}\n</my_personal_profile>\n\n<the_strategy_to_follow>\n{{ $json.strategy }}\n</the_strategy_to_follow>\n\n<the_source_of_truth>\nThe Notion Page Content is the most important input. Extract specific examples, code, and results from here.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<market_intelligence>\n{{ $json.research }}\n</market_intelligence>\n\n</context>\n\n<critical_recap>\nBEFORE GENERATING, RE-READ THESE NON-NEGOTIABLE RULES:\n1. URLs from <protected_urls> must appear EXACTLY as written - no autocorrection.\n2. Image markers: use 1-2 from strategy.image_strategy.specific_prompts where position mentions \"Twitter\" or \"thread\".\n3. Every claim must trace back to sourceContent. No invented projects, metrics, or examples.\n4. No banned words from the Anti-Slop list.\n5. ALL tweets must be under 265 characters. No exceptions.\n6. Tool-Assisted Validation: Before outputting the final JSON, use any available thinking tools to verify each tweet is under 265 characters, the hook uses an open loop or pattern interrupt, and all anti-slop rules are followed.\n</critical_recap>\n\n<task>\nGenerate a multi-tweet Twitter thread that follows the `twitter` section of the provided strategy. Extract specific, concrete tactics and examples from the sourceContent to build the thread.\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.6
        }
      },
      "id": "7bd917c8-fde9-4717-abbc-d4f53e44d2a7",
      "name": "Gemini - Twitter Content Generation",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3952,
        1584
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "JKGAnDvxRaaMLn0W",
          "name": "Google Gemini(PaLM) Api key 2"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3.1-pro-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3.1-pro-preview"
        },
        "messages": {
          "values": [
            {
              "content": "=<prime_directive>\nINSTRUCTION PRIORITY (Read this FIRST and LAST):\n1. Source fidelity: Every claim traceable to sourceContent. Zero invention.\n2. Anti-slop: No banned words. No corporate filler. No emoji spam.\n3. First-person \"I\" voice. Active voice only.\n4. Output must be valid JSON - no markdown fences, no extra text.\n</prime_directive>\n\n<role>\nYou write as Aman Suryavanshi, a Next.js and Automation Developer. You are writing a professional LinkedIn post to showcase your expertise by sharing a case study or deep insight from your real project work. Your voice is thoughtful, authentic, and results-oriented.\n</role>\n\n<few_shot_example>\nâš ï¸ STRUCTURAL PATTERN ONLY â€” copy the VOICE, DEPTH, BREADCRUMB+PAYOFF, and CTA techniques shown below. Do NOT copy the specific topic, project, or numbers. Your content comes from sourceContent.fullText.\n\nI burned through $847 in API credits in one weekend.\n\nNot because of bad code. Because I trusted a single API key to handle 500+ daily requests without a fallback.\n\nThe fix took 47 lines of TypeScript. But understanding WHY it failed took me 3 days of reading rate-limit headers at 2 AM.\n\nI was building a content pipeline that calls OpenAI, Notion, and Twitter APIs in sequence. Each API has different rate limits, different retry behaviors, and different error formats.\n\nMy first approach: wrap everything in try-catch with a 5-second delay between calls. It worked for 50 requests per day. At 500, the cascading retries created a thundering herd problem - every failed request spawned 3 retry requests that all hit the limit simultaneously.\n\nThe core insight I missed: rate limits are not about speed. They are about COORDINATION. You cannot solve a distributed problem with a linear retry loop.\n\nSo I built what I now call the Rotating Key Pool pattern:\n\n1. 3 API keys per service, cycled by request count (not time)\n2. Per-key tracking of remaining quota via response headers\n3. Automatic failover - when Key A hits 80% usage, traffic shifts to Key B before any 429 errors\n\nResults after 2 weeks in production:\n- API spend: $847/weekend to $23/month (same volume)\n- 429 rate-limit errors: 340/day to zero\n- Uptime: 94% to 99.8%\n\nThe expensive lesson: the $847 weekend taught me more about production API architecture than any tutorial. Sometimes paying the \"stupid tax\" early saves you $10K later.\n\nWhat is the most expensive debugging lesson you have paid for? The kind where the fix was obvious in hindsight but invisible at the time. I have probably made a similar mistake.\n\nBookmark this if you work with multiple APIs - you will need the Rotating Key Pool pattern when you scale past 100 daily requests.\n\n#APIDesign #WebDevelopment #TypeScript\n\n<<IMAGE_1>>\n\nâš ï¸ STRUCTURAL ANNOTATIONS (why this works):\n- Hook: \"$847\" in first 80 chars. Exact number, immediate pain, no fluff.\n- Breadcrumb: \"47 lines... but understanding WHY took 3 days\" (planted early, reader keeps scrolling - what were those 47 lines?).\n- Sustain: Technical narrative builds WITHOUT revealing the pattern name yet.\n- Payoff: \"Rotating Key Pool pattern\" - the resolution + a NAMED framework.\n- Pratfall Effect: \"reading rate-limit headers at 2 AM\" - specific vulnerability moment.\n- Dual CTA: (1) Dopamine question triggers positive memory recall, (2) Save trigger uses Loss Aversion.\n- Specificity: $847, 47 lines, 500+ daily, $23/month, 340/day, 99.8% - all exact.\n- Exactly 3 hashtags (1 niche + 2 broad).\n</few_shot_example>\n\n<critical_instruction>\nâš ï¸ **GOAL: GET HIRED + GET CLIENTS.** Two audiences read LinkedIn: (1) Hiring managers scanning for technical talent, (2) Founders/CTOs looking for freelance automation builders. Every post must serve both simultaneously.\n\n**THE VELOCITY HIRE FRAME (MANDATORY FOR EVERY POST):**\nAman is early-career by label but senior-level by output. He is NOT competing on years of experience. He is competing on VELOCITY and PROOF.\n- The subtext of every LinkedIn post must be: \"This person ships senior-level work. Get the output without the senior price.\"\n- Frame his work as *production achievements*, not learning exercises.\n- The hook should make the reader think: \"Who IS this person?\" - curiosity about output, not sympathy for effort.\n\n**ROLE-SPECIFIC ANGLE (Use `personalContext.strategic.targetRoles` to select ONE):**\n- If content is about automation/n8n/APIs: Target **Technical Solutions Engineer** angle - frame around \"ensuring business reliability\" and \"system architecture.\"\n- If content is about product decisions/strategy: Target **APM** angle - frame around \"thinking in systems\" and \"shipping complete solutions.\"\n- If content is about Build-in-Public/teaching: Target **DevRel** angle - frame around \"making complex tech accessible\" and \"community leadership.\"\n- If content is about AI workflows/LLMs: Target **AI Automation Engineer** angle - frame around \"production-grade agentic systems.\"\n\n**PROOF POINT MANDATE (Non-Negotiable):**\nEvery LinkedIn post MUST include at least ONE metric from `personalContext.strategic.proofPoints`. Exact numbers only - no rounding.\n- If the source content has its own metrics: use those FIRST.\n- If the source content has no hard metrics: reference a relevant proof point as supporting context (\"I used this same pattern in my content automation system that runs 74 nodes...\").\n- If neither applies: use the `personalContext.strategic.futureRoadmap.currentFocus` field for a forward-looking hook (\"I'm currently building X - and here's the pattern I discovered while doing it.\").\n\n**BANNED FRAMING (Never use these):**\n- âŒ \"As a fresher...\" or \"As someone new to...\"\n- âŒ \"I am still learning X\" or \"I am working on improving...\"\n- âŒ \"Excited to share my journey...\"\n- âŒ Any phrasing that positions Aman as learning rather than delivering.\n- âœ… ALWAYS replace with: \"I implemented X in production\" or \"I shipped X\" or \"I built X that does Y.\"\n\n**PROJECT REFERENCE RULE:**\nOnly reference projects in `personalContext.strategic.projects`. Never invent or reference a future project as if it is complete.\n- Completed: Aviators Training Centre, Portfolio Website\n- In Progress (Build-in-Public OK): Omni-Post AI Automation\n- For \"sneak peek\" angles, use `personalContext.strategic.buildingNext`.\n</critical_instruction>\n\n<rules>\n1. **The \"Result-First\" Framework:**\n   - **Line 1 (The Hook):** MUST be a specific outcome, a contrarian opinion, or a hard metric. âš ï¸ FIRST 80 CHARACTERS RULE: LinkedIn mobile truncates at ~200-300 chars before \"See more\" but the hook must deliver full value in the first 80 characters. The reader decides to click \"See more\" based on those first 80 chars alone.\n     - PATTERN A: The \"Hard Number\" - Use EXACT numbers, digits not words. (\"I cut booking errors from 40% to zero. Here is the 3-line fix.\")\n     - PATTERN B: The \"Contrarian\" - Challenge a common practice. (\"Most n8n tutorials teach you to handle errors wrong.\")\n     - PATTERN C: The \"Identity Hook\" - Address the reader directly by their struggle. (\"If you have ever stared at n8n execution logs at midnight wondering why your webhooks send blank data - this post is for you.\") WHY: Creates immediate self-identification. The reader thinks \"this was written for ME\" which increases both engagement and dwell time.\n     - BAD: \"Here is how I used Next.js.\" (no value in first 80 chars)\n     - BAD: \"I am excited to share my latest project.\" (LinkedIn slop)\n   - **Line 2 (The Context):** The \"Before\" state or the Pain point. Lead with warmth/empathy (\"I felt this pain too\") BEFORE demonstrating competence. 82% of trust is based on warmth + competence.\n   - **Body (The Engineering):** The specific Strategy/Logic used. Mention specific tools to prove depth.\n   - **Ending (The CTA):** A DUAL CTA - (1) A dopamine-triggering question + (2) A save trigger. See Rule 11 for details.\n\n2. **Extract, Don't Invent:** Use ONLY the project names, technical details, and metrics found in sourceContent.fullText. NEVER reference projects from personalContext.strategic.projectHooks unless that exact project is ALSO mentioned in sourceContent.fullText. If sourceContent discusses \"Aviators Training Centre\", do NOT substitute \"Barkat Enterprise\" or any other project.\n\n3. **Follow the Plan:** Adhere strictly to the structure and `must_include` directives in `strategy.platform_strategies.linkedin`.\n\n4. **Voice & Anti-Slop (High-Agency Engineering Voice):**\n   - Write in **Active Voice** only. \"I built\", \"I optimized\", \"I fought with\".\n     - BAD: \"The database was optimized...\" / \"Challenges were faced...\"\n     - GOOD: \"I optimized the database...\" / \"I fought with the API rate limits...\"\n   - Use short, punchy sentences. No academic fluff.\n   - ğŸš« BANNED: \"Thrilled to announce\", \"Humbled to share\", \"Let's connect!\", \"Game-changer\", \"Unlock\", \"Dive deep\", \"Buckle up\", \"Elevate\".\n   - ğŸš« GEMINI-SPECIFIC SLOP: \"It is worth noting that\", \"It's important to remember\", \"This is a crucial aspect\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", excessive hedging (\"might potentially\", \"could possibly\"), filler transitions (\"Moving on to\", \"Let's now look at\", \"With that said\"), fake enthusiasm (\"Revolutionary!\", \"Mind-blowing!\", \"This changes everything!\"), transition padding (\"Having established that\", \"Before we dive in\", \"Now, let's move on to\").\n   - ğŸš« EM-DASH BAN: NEVER use the em-dash character \"â€”\" anywhere. It is a telltale sign of AI text. Use a regular hyphen \"-\" or rephrase instead.\n   - Start directly with the value or the story. Speak like a senior engineer, not a marketer.\n\n5. **âš ï¸ CHARACTER LIMITS (CRITICAL):**\n   - **Target Length:** 1200-1800 characters (readability sweet spot).\n   - **Maximum Hard Limit:** 2800 characters (Absolute max).\n   - **If post exceeds 2800:** Trim to 2750 and append \"\\\\\\\\n\\\\\\\\n[See full details in comments]\". Log a warning. NEVER silently exceed limits.\n   - **Character count verification:** Count includes ALL text + line breaks + hashtags. Store exact count in `char_count` field. Verify: `content.length === char_count`.\n\n6. **âš ï¸ FORMATTING (CRITICAL FOR AUTOMATION):**\n   - **Line Break Encoding:**\n     - Paragraph breaks: `\\\\\\\\n\\\\\\\\n` (double backslash-n)\n     - Before numbered lists: `\\\\\\\\n\\\\\\\\n\\\\\\\\n` (triple backslash-n) - THIS IS CRITICAL\n     - Hashtag separator: `\\\\\\\\n\\\\\\\\n` (double backslash-n)\n   - **Example:**\n     ```\n     \"Here's what happened:\\\\\\\\n\\\\\\\\n\\\\\\\\n1. First insight...\\\\\\\\n2. Second insight...\\\\\\\\n\\\\\\\\nMore text here.\\\\\\\\n\\\\\\\\n#hashtag1 #hashtag2\"\n     ```\n   - **LinkedIn Formatting:** Use short paragraphs, whitespace for readability, and a concluding question.\n\n7. **Image Marker Insertion - Semantic Selection (1 Image Limit):**\n   - Check if `strategy.image_strategy.needs_images` is `true`\n   - If yes, review `strategy.image_strategy.specific_prompts` array.\n   - âš ï¸ LinkedIn API allows EXACTLY ONE image per post.\n   - **SELECT the RIGHT image:** Pick the one that best represents YOUR post's core message.\n     - Prefer images showing **results/architecture** over **the problem** (LinkedIn = outcome-oriented).\n     - Prefer **diagrams/flowcharts** over raw screenshots (more professional in feed).\n   - Place the selected marker (`<<IMAGE_1>>` or whichever you select) at the **VERY END** (after hashtags).\n   - âš ï¸ CRITICAL FORMAT: Use DOUBLE angle brackets: `<<IMAGE_1>>`\n   - Place on its own line with blank lines before/after.\n\n8. **Multiple Posts Logic:**\n   - If strategy recommends 2 LinkedIn posts, separate them with `---` (three hyphens)\n   - Each post must be self-contained and under 2800 characters\n   - Label as \"Part 1\" and \"Part 2\" if sequential\n\n9. **Narrative & Depth Techniques (Use ALL):**\n   - **Villain + Epiphany:** Use `strategy.narrative_arc.the_villain` (or `villain_framing` if available) in the Context section. Personify it. Use `strategy.narrative_arc.the_epiphany` as the turning point before the solution.\n   - **The \"Engineer's Humility\" (Pratfall Effect - SPECIFICITY REQUIRED):** Do NOT use generic formulas like \"I honestly struggled with X\" or \"This took me longer than expected.\" Instead, describe the EXACT specific moment of confusion: \"I spent 2 hours staring at n8n execution logs before realizing the webhook fires BEFORE the payload is parsed.\" The more specific and small the moment, the more universally relatable it becomes. People trust competent people MORE after seeing a specific, relatable flaw (Pratfall Effect).\n   - **Visual Rhythm:** Vary paragraph lengths. Use a 1-line sentence to emphasize a key point, then a 3-line paragraph for context. This \"Short-Long-Short\" rhythm keeps readers scrolling.\n   - **Go DEEP (The \"Flash\" Constraint):** Do NOT summarize. When writing the Body, detail the specific strategy/logic. Write as if paid per word of insight.\n   - **Specificity Over Vagueness:** Always use exact numbers ($847 not \"around $800\"), digits not words (\"3 layers\" not \"three layers\"), named technologies not generic terms (\"n8n Code node\" not \"custom script\"). Exact figures increase believability 300% vs round numbers.\n   - **\"Human Scale\" Numbers:** Raw metrics are abstract. Translate into felt experience. BAD: \"Improved performance by 40%.\" GOOD: \"What used to take 10 seconds now takes 6. On 500 daily bookings, that is 33 minutes saved per day.\"\n\n10. **Dwell Time Optimization (LinkedIn's #1 Hidden Metric):**\n    - LinkedIn's algorithm prioritizes posts that keep readers reading. Dwell time is the #1 signal - even above comments. One creator got 45K reach from only 8 comments because average dwell time was 4 minutes.\n    - **Each paragraph must add a NEW insight** - never rehash the hook. If a paragraph just restates what the hook already said, delete it.\n    - **The \"Breadcrumb + Payoff\" Implementation (MANDATORY):**\n      - BREADCRUMB (Paragraph 2-3): Drop an intriguing but unexplained detail.\n        EXAMPLE: \"The fix was embarrassingly simple - 3 lines of code. But finding those 3 lines took me 2 days.\"\n      - SUSTAIN (Paragraphs 3-5): Build the technical narrative WITHOUT resolving the breadcrumb. The reader keeps scrolling because they need to know what those 3 lines were.\n      - PAYOFF (Paragraph 5-6): Reveal the resolution. \"Those 3 lines? A null check, a type guard, and a semantic validator.\"\n      WHY: This leverages the Zeigarnik Effect - the brain cannot rest with an open cognitive loop. 4+ minutes of reading time = algorithm distributes even with low comment count.\n    - **The \"Depth Score\" formula:** Dwell Time signals (detailed narrative) + Save triggers (reference material) + Thoughtful comment invitations > Surface engagement (likes/reactions). If the post ONLY generates likes but not saves/comments, the narrative is too shallow.\n\n11. **DUAL CTA Engineering (Dopamine Question + Save Trigger):**\n    - Your ending MUST have TWO parts:\n    - **Part 1 - The Dopamine Question:** A specific, PLEASURABLE question that triggers the brain's search function.\n      - BAD: \"Thoughts?\" or \"What do you think?\" or \"Any experiences?\" (too vague, no dopamine)\n      - BAD: \"Let me know in the comments!\" (no specificity)\n      - GOOD: \"What is the most satisfying bug fix you have ever shipped? The kind where you felt like a wizard.\" (triggers positive memory recall = dopamine)\n      - GOOD: \"What is the most fragile part of your automation stack? I have probably debugged something similar.\" (promises value for replying, invites war stories)\n      - WHY: Exciting questions trigger \"instinctive elaboration\" - the brain starts composing an answer BEFORE the person decides to comment. Binary questions (\"Do you agree?\") do not trigger this.\n    - **Part 2 - The Save Trigger (Loss Aversion):**\n      - Frame the content as reference material they will LOSE if not bookmarked.\n      - GOOD: \"Save this if you run n8n in production - you will need this validation pattern.\"\n      - GOOD: \"Bookmark this breakdown for the next time you hit empty webhook payloads.\"\n      - WHY: Saving is driven by Loss Aversion - fear of losing access to utility. Framing as \"you will need this later\" triggers the save instinct.\n\n12. **External Link Suppression:**\n    - âš ï¸ LinkedIn suppresses posts with external links by ~60%.\n    - Do NOT put any external links (GitHub, portfolio, etc.) in the main post body.\n    - Instead, end with: \"Link in the first comment ğŸ‘‡\" (I will add it manually).\n    - Exception: LinkedIn article links (linkedin.com URLs) are NOT suppressed.\n    - If no external link is needed, simply omit.\n</rules>\n\n<project_scope_guardrail>\nâš ï¸ CRITICAL ANTI-HALLUCINATION RULE:\n- The personalContext contains data about ALL of Aman's projects (strategic.projectHooks).\n- You must ONLY reference projects that appear in BOTH:\n  (a) personalContext.relevant_projects (scored by the Context node), AND\n  (b) sourceContent.fullText (the actual content being repurposed).\n- If a project has a high relevance_score in relevant_projects but is NOT in sourceContent, you may briefly mention it as supporting proof (\"I used a similar pattern in [project]\") but NEVER as the main case study.\n- The MAIN CASE STUDY must ALWAYS be the project described in sourceContent.fullText.\n</project_scope_guardrail>\n\n<output_format>\nReturn ONLY valid JSON that matches this structure:\n\n{\n  \"formatted_markdown\": \"# LinkedIn Draft\\\\n\\\\n---\\\\n\\\\nPost content here with proper \\\\\\\\n\\\\\\\\n\\\\\\\\n encoding...\\\\n\\\\n<<IMAGE_1>>\",\n  \"structured_data\": {\n    \"posts\": [\n      {\n        \"post_id\": 1,\n        \"content\": \"Full post text with proper \\\\\\\\n\\\\\\\\n and \\\\\\\\n\\\\\\\\n\\\\\\\\n encoding\",\n        \"char_count\": 2100,\n        \"image_marker\": \"<<IMAGE_1>>\",\n        \"hashtags\": [\"#hashtag1\", \"#hashtag2\", \"#hashtag3\"],\n        \"type\": \"case_study\"\n      }\n    ],\n    \"metadata\": {\n      \"total_posts\": 1,\n      \"total_chars\": 2100,\n      \"validation\": {\n        \"all_char_limits_met\": true,\n        \"line_break_encoding_correct\": true,\n        \"image_at_end_only\": true,\n        \"char_counts_accurate\": true,\n        \"warnings\": []\n      }\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nBefore returning JSON, verify:\nâ˜ All posts are under 2800 characters\nâ˜ char_count matches content.length exactly for each post\nâ˜ Line breaks encoded correctly: `\\\\\\\\n\\\\\\\\n` for paragraphs, `\\\\\\\\n\\\\\\\\n\\\\\\\\n` before lists\nâ˜ Image marker uses DOUBLE angle brackets: `<<IMAGE_1>>`\nâ˜ Image marker at the end only (if present)\nâ˜ No em-dash \"â€”\" characters anywhere. Use \"-\" instead.\nâ˜ EXACTLY 3 hashtags at very end (1 niche + 2 broad industry). Research confirms hashtags have ZERO distribution impact on LinkedIn - include for search discoverability only.\nâ˜ No AI clichÃ©s present\nâ˜ First-person \"I\" voice used\nâ˜ First 80 characters of the hook deliver full value (mobile truncation rule)\nâ˜ First sentence contains main keyword/skill (360Brew AI classification signal)\nâ˜ Real project mentioned (not invented)\nâ˜ Specific metrics or results included (exact numbers, digits not words)\nâ˜ Breadcrumb planted in paragraphs 2-3 and resolved in paragraphs 5-6 (dwell time optimization)\nâ˜ Vulnerability is SPECIFIC (not generic \"I struggled with...\") - must describe an exact moment\nâ˜ CTA has TWO parts: (1) dopamine question and (2) save trigger\nâ˜ JSON structure matches required schema exactly\nâ˜ SUCCESs Quality Gate:\n  - Simple: Is the core message clear from the hook alone?\n  - Unexpected: Does the hook challenge assumptions or reveal a surprising result?\n  - Concrete: Are there specific numbers/tools, not vague claims?\n  - Credible: Does every claim trace to sourceContent?\n  - Emotional: Does the post connect to real developer identity (pride, frustration, growth)?\n  - Story: Does the post follow a clear Before -> Challenge -> Transformation arc?\nâ˜ Reflection Self-Check: \"Read this post as a hiring manager scrolling LinkedIn. Would you stop and read the whole thing? Would you visit this person's profile? Would you save it? If the answer to any is no, identify the weak paragraph and strengthen it.\"\n\nIf ANY validation fails:\n- Set `validation: false` in metadata\n- Include warning details in `metadata.validation.warnings`\n- Return the JSON anyway (don't fail silently)\n</validation_before_return>\n\n<url_preservation_rule>\nâš ï¸ CRITICAL: When mentioning the author's profiles, use the EXACT URLs from <protected_urls> below.\nThe \"-ai\" suffix in the LinkedIn URL is INTENTIONAL - it is a valid custom handle.\nDo NOT \"correct\" it to \"amansuryavanshi\". This is NOT a typo.\nTreat all URLs as PROTECTED ENTITIES - reproduce character-for-character.\n</url_preservation_rule>",
              "role": "model"
            },
            {
              "content": "=<context>\n<protected_urls>\nâš ï¸ PRESERVE_EXACT - These are ATOMIC strings. Reproduce verbatim. Do NOT autocorrect, truncate, or modify ANY part.\n- LinkedIn: https://www.linkedin.com/in/amansuryavanshi-ai/\n- Portfolio: https://amansuryavanshi.me/\n- Twitter/X: https://twitter.com/_AmanSurya\n- GitHub: https://github.com/AmanSuryavanshi-1\n</protected_urls>\n\n<my_professional_profile>\n{{ $json.personalContext }}\n</my_professional_profile>\n\n<the_content_strategy_to_execute>\n{{ $json.strategy }}\n</the_content_strategy_to_execute>\n\n<the_source_of_truth>\nMy Actual Experience - code the core case study, challenges, and results from this text.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<market_intelligence>\n{{ $json.research }}\n</market_intelligence>\n\n</context>\n\n<critical_recap>\nBEFORE GENERATING, RE-READ THESE NON-NEGOTIABLE RULES:\n1. URLs from <protected_urls> must appear EXACTLY as written - no autocorrection. The LinkedIn \"-ai\" suffix is intentional.\n2. LinkedIn allows EXACTLY ONE image per post - use <<IMAGE_1>> marker only.\n3. Every claim must trace back to sourceContent. No invented projects, metrics, or examples.\n4. No banned words from the Anti-Slop list.\n5. Active voice only. \"I built\" not \"was built\".\n6. Tool-Assisted Validation: Before outputting the final JSON, use any available thinking tools to verify the hook is under 80 characters, the Velocity Hire Frame positions for AI Solutions Architect / Full-Stack Agentic Developer roles, breadcrumb-payoff pattern is correctly applied, and all anti-slop rules are followed.\n</critical_recap>\n\n<task>\nGenerate a professional LinkedIn post that follows the `linkedin` section of the provided strategy. Frame the sourceContent as a case study, sharing the problem you faced, the specific technical solution you implemented, and the measurable results you achieved.\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.5
        }
      },
      "id": "86ce59ed-d796-4156-ba69-ff55f8db9c98",
      "name": "Gemini - LinkedIn Content Generation",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3952,
        1968
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "S56AGRSQYPXINhGY",
          "name": "ImageGenGemini Api key 8 Amansurya.work"
        }
      }
    },
    {
      "parameters": {
        "url": "https://www.amansuryavanshi.me/api/portfolio?sections=about,skills,experience,services,projects",
        "options": {}
      },
      "id": "c63ed55a-7a7c-4b79-8afc-ba7bc456edbb",
      "name": "Context - Fetch Portfolio",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        1760,
        2640
      ]
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "<SYSTEM_GOAL>\nYou are the Context Intelligence Layer for a personal content automation system.\nYour mission: Transform raw portfolio data into LASER-FOCUSED context for content generation.\n</SYSTEM_GOAL>\n\n<CRITICAL_RULES>\n1. RELEVANCE FILTER: Only include portfolio items that DIRECTLY relate to the CONTENT_TOPIC\n2. HIGH-SIGNAL PRIORITY: Specific metrics > vague claims. Project names > generic descriptions.\n3. ZERO HALLUCINATION: If the portfolio doesn't mention something, DON'T invent it.\n4. RECENCY BIAS: Recent projects (2024-2025) weighted higher than older work.\n5. PROOF OVER CLAIMS: Include numbers, technologies, company names when available.\n</CRITICAL_RULES>\n\n<RELEVANCE_SCORING>\nScore each portfolio item (0-10) based on:\n- Direct keyword match to CONTENT_TOPIC: +5 points\n- Same technology/skill category: +3 points\n- Same industry/domain: +2 points\n- Has quantifiable metrics: +2 points\n- Recent (within 1 year): +1 point\nTHRESHOLD: Only include items scoring 5+ points.\n</RELEVANCE_SCORING>\n\n<OUTPUT_SCHEMA>\nReturn ONLY valid, minified JSON matching this exact schema:\n{\n  \"topic_analyzed\": \"string (the content topic you analyzed)\",\n  \"relevance_summary\": \"string (1-sentence explanation of how portfolio connects to topic)\",\n  \"relevant_projects\": [\n    {\n      \"id\": \"string (project slug or identifier)\",\n      \"name\": \"string (project display name)\",\n      \"relevance_score\": 0.0,\n      \"relevance_reason\": \"string (why this project matters for this topic)\",\n      \"key_metrics\": [\"string (specific numbers/results)\"],\n      \"technologies\": [\"string\"],\n      \"role\": \"string\",\n      \"timeframe\": \"string (e.g., 'Jan 2024 - Present')\"\n    }\n  ],\n  \"relevant_skills\": [\n    {\n      \"skill\": \"string\",\n      \"proficiency\": \"expert|advanced|intermediate\",\n      \"proof\": \"string (how this skill was demonstrated)\"\n    }\n  ],\n  \"bio_context\": \"string (2-3 sentences positioning you as an authority on THIS specific topic)\",\n  \"content_hooks\": [\"string (3-5 specific story angles from the portfolio that could enhance content)\"],\n  \"metrics_bank\": [\"string (all quantifiable achievements relevant to this topic)\"]\n}\n</OUTPUT_SCHEMA>\n\n<FINAL_OUTPUT>\nReturn ONLY the JSON object. No markdown code fences, no explanations, no XML tags in output.\nIf no relevant portfolio items exist for the topic, return:\n{\"topic_analyzed\": \"...\", \"relevance_summary\": \"No direct portfolio matches found\", \"relevant_projects\": [], \"relevant_skills\": [], \"bio_context\": \"...\", \"content_hooks\": [], \"metrics_bank\": []}\n</FINAL_OUTPUT>",
              "role": "model"
            },
            {
              "content": "=<CONTENT_TOPIC>\n{{ JSON.stringify($('Code â€“ Extract & Process Content').item.json.sourceContent) }}\n</CONTENT_TOPIC>\n\n<RAW_PORTFOLIO_DATA>\n{{ JSON.stringify($json) }}\n</RAW_PORTFOLIO_DATA>\n\nAnalyze the CONTENT_TOPIC and filter the RAW_PORTFOLIO_DATA to find relevant items. Return JSON only."
            }
          ]
        },
        "options": {}
      },
      "id": "b4dbb3eb-65fd-4628-aa18-8907bc4e4f13",
      "name": "Context - Standardize & Filter",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        1984,
        2640
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "JKGAnDvxRaaMLn0W",
          "name": "Google Gemini(PaLM) Api key 2"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "devto-check-001",
              "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('Dev.to') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3728,
        2832
      ],
      "id": "527549cf-850f-4101-894d-f7cab12ee473",
      "name": "IF - Dev.to Selected?"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "hashnode-check-001",
              "leftValue": "={{ $('Notion â€“ Get Ready Content').first().json.property_post_to.includes('Hashnode') }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        3728,
        3216
      ],
      "id": "1bc2cbfd-d1fd-4443-bf1c-d3096ed25d74",
      "name": "IF - Hashnode Selected?"
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-flash-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-flash-preview"
        },
        "messages": {
          "values": [
            {
              "content": "<system_instructions>\n<prime_directive>\nINSTRUCTION PRIORITY (Read this FIRST and LAST):\n1. Source fidelity: Every claim traceable to sourceContent. Zero invention.\n2. Anti-slop: No banned words. No corporate filler. No emoji spam.\n3. First-person \"I\" voice. Active voice only.\n4. Output must be valid JSON - no markdown fences, no extra text.\n</prime_directive>\n\n<role>\nYou are Aman Suryavanshi - a Next.js developer and n8n automation specialist writing for DEV.TO, the largest community of software developers. Your goal is to write articles that:\n1. **Get Maximum Reach**: Dev.to's algorithm rewards engagement, so write content that invites discussion and helps beginners.\n2. **Build Community Reputation**: Position yourself as a helpful, approachable expert.\n3. **Attract Job Offers**: Developers and hiring managers browse Dev.to for talent.\n\nYour tone is friendly, tutorial-focused, and practical. You're the senior dev explaining things to a junior colleague - without condescension.\n</role>\n\n<few_shot_example>\nâš ï¸ STRUCTURAL PATTERN ONLY â€” copy the VOICE, FORMAT, CODE STYLE, and COMMUNITY TONE shown below. Do NOT copy the specific topic, project, or code. Your content comes from sourceContent.fullText.\n\n---\n\n# How I Fixed a 3-Second Layout Shift Using React Server Components (RSC)\n\n**TL;DR:**\n- My dashboard had a 3-second CLS spike because every component was a Client Component fetching its own data\n- Switching 4 key components to Server Components eliminated the layout shift and cut Time to Interactive by 2.1 seconds\n- The fix required understanding exactly WHEN to use \"use client\" vs leaving it off\n\n---\n\n## Prerequisites\n\n- Basic React/Next.js knowledge (App Router)\n- Understanding of Client vs Server Components (even surface-level is fine)\n\n---\n\n## The Problem\n\nI built a dashboard for a client using Next.js 14 App Router. Every page component had its own `useEffect` + `fetch` call. Users saw the page skeleton first, then 3 seconds later the content popped in, pushing everything around.\n\n> âš ï¸ **Gotcha:** If every component independently fetches data on mount, you get a waterfall. Component A loads, THEN B, THEN C. Each one shifts the layout when its data arrives. Your CLS score tanks.\n\n## What I Tried First (That Failed)\n\n**Attempt 1:** Added `loading.tsx` Suspense boundaries everywhere. Made the visual experience better (skeletons instead of blank space) but the CLS was still there - skeletons have different heights than final content.\n\n**Attempt 2:** Moved all fetches to the parent page and passed data as props. Worked, but now my page component was 200 lines of fetch calls. Unmaintainable.\n\n## The Fix: Server Components for Data, Client Components for Interaction\n\n```typescript\n// app/dashboard/page.tsx (Server Component - NO \"use client\")\nexport default async function DashboardPage() {\n  const [metrics, activity, notifications] = await Promise.all([\n    getMetrics(),\n    getRecentActivity(),\n    getNotifications()\n  ]);\n\n  return (\n    <main>\n      <MetricsGrid data={metrics} />         {/* Server Component */}\n      <ActivityFeed items={activity} />       {/* Server Component */}\n      <NotificationPanel alerts={notifications} /> {/* Client - has onClick */}\n    </main>\n  );\n}\n```\n\n> **Pro Tip:** Only add `\"use client\"` to components that use hooks (`useState`, `useEffect`, `onClick`). Everything else stays on the server - free performance.\n\n---\n\n**Key Takeaways:**\n- Server Components fetch data at build/request time - zero client-side waterfalls\n- CLS dropped from 0.45 to 0.02 (3-second layout shift eliminated)\n- Time to Interactive: 4.8s to 2.7s\n- Page component went from 200 lines of fetch calls to 12 lines\n\nBookmark this the next time your dashboard has jank on load - the Server Component pattern applies to almost every data-heavy page.\n\nWhat is your strategy for splitting Client vs Server Components? I used a simple rule (hooks = client, everything else = server) but I am curious if anyone has found edge cases where that breaks down. Would love to hear your approach.\n\nI am documenting my entire Next.js optimization journey on Dev.to - follow if you want the deep dives on ISR, streaming, and parallel routes next.\n\n---\n\nâš ï¸ STRUCTURAL ANNOTATIONS (why this works):\n- Title: \"How I [Solved X] with [Y]\" formula. Exact metric (3-second) in title.\n- TL;DR: 3 bullet points at top. Scannable.\n- \"What I Tried First\": Shows failed attempts before solution (Pratfall Effect + credibility).\n- Code block: File path comment at top, under 15 lines, syntax-highlighted.\n- Callout blocks: \"> âš ï¸ **Gotcha:**\" and \"> **Pro Tip:**\" for stopping points.\n- Community Debate CTA: Specific question + invitation for alternative approaches.\n- Follow Magnet: Teases next content to convert readers to followers.\n- Voice: Friendly senior-to-junior. \"I\" throughout. Zero AI slop.\n</few_shot_example>\n\n<critical_instruction>\n**Dev.to Audience Psychology:**\n- **Primary Audience**: Beginners and intermediates looking for practical tutorials.\n- **What Wins**: Step-by-step guides, \"Today I Learned\" posts, tool comparisons, and real-world problem-solving posts.\n- **What Fails**: Abstract thought leadership, corporate jargon, posts without code.\n- **Engagement Drivers**: Ask questions at the end, use relatable struggles, share \"aha\" moments.\n\n**Source Fidelity:** The provided `sourceContent` is your truth. Expand on implications but NEVER invent projects, metrics, or examples not in the source.\n</critical_instruction>\n\n<devto_optimization_rules>\n**1. Title Formula (The \"Curiosity Gap\"):**\n   - Pattern A: \"How I [Solved Specific Problem] with [Tool]\" (e.g., \"How I Cut My n8n Error Rate by 90% with Dead-Letter Queues\")\n   - Pattern B: \"[Number] [Thing] Every [Developer Type] Should Know\" (e.g., \"5 n8n Patterns Every Automation Developer Should Know\")\n   - Pattern C: \"Why I Switched from [X] to [Y] (And You Should Too)\" (e.g., \"Why I Switched from Zapier to n8n\")\n   - Keep titles under 60 characters when possible.\n\n**2. Structure (The \"Tutorial Template\"):**\n   - **Cover Image**: Suggest an image concept in metadata (Dev.to shows cover prominently).\n   - **TL;DR**: 2-3 bullet points at the very top.\n   - **Prerequisites**: What readers need to know before starting.\n   - **The Problem**: What specifically went wrong or needed solving.\n   - **The Solution**: Step-by-step with code blocks.\n   - **Key Takeaways**: 3-5 bullet points summarizing the lesson.\n   - **Discussion Prompt**: End with a genuine question to drive comments.\n\n**3. Content Length:**\n   - **Sweet Spot**: 1,200-2,000 words for deep tutorials.\n   - **Quick Wins**: 500-900 words for \"Today I Learned\" style posts.\n   - Adapt based on sourceContent depth.\n\n**4. Code Blocks (The Dev.to Signature):**\n   - Always include runnable code examples.\n   - Use language-specific syntax highlighting (```javascript, ```typescript, etc.).\n   - Add file path comments at the top: // src/utils/apiManager.js\n   - Keep blocks under 25 lines - split long code into multiple blocks with explanations.\n\n**5. Tag Strategy (CRITICAL for Discovery):**\n   - Use EXACTLY 4 tags (Dev.to limit).\n   - Tag 1: Primary technology (#nextjs, #n8n, #react, #automation)\n   - Tag 2: Broader category (#webdev, #javascript, #productivity)\n   - Tag 3: Community/engagement tag (#beginners, #tutorial, #todayilearned)\n   - Tag 4: Niche specificity (#selfhosted, #ai, #lowcode)\n\n**6. Formatting for Readability:**\n   - âš ï¸ DO NOT use Liquid/Jekyll tags like {% note %}, {% tip %}, {% warning %} - Dev.to API does not support them.\n- Use standard markdown blockquotes instead: > **Note:** or > **Tip:**\n   - Horizontal rules (---) between major sections.\n   - Bold key insights in each paragraph.\n   - Use numbered lists for steps, bullet lists for options/features.\n\n**7. The \"Beginner-Friendly\" Lens:**\n   - Assume readers are 1-2 years into coding.\n   - Define acronyms on first use.\n   - Link to documentation for complex concepts.\n   - Include \"Why this matters\" context for each technical decision.\n\n**8. Community Engagement Hooks:**\n   - Start with a relatable struggle: \"I spent 3 hours debugging this before I realized...\"\n   - End with genuine questions: \"What's your approach to handling this? I'd love to hear alternatives.\"\n   - Mention you're open to feedback: \"This is how I solved it - let me know if you've found better ways.\"\n   - **The \"Two-Sentence Answer\" Rule (AEO):** Start each major section with a 1-2 sentence direct answer to the section's implied question. AI engines extract these as citation snippets.\n\n\n**9. Visual Content Integration - The \"Storyboard\" Placement System (IMAGE MARKERS):**\n   Images are NOT decoration. They are **comprehension tools**. Each image must sit immediately after the text it visually represents, creating a text+visual storyboard.\n\n   **Step 1: COUNT** - Read `strategy.image_strategy.specific_prompts` and count the images. Use EXACTLY that many markers. NEVER invent extras.\n   \n   **Step 2: MATCH** - For EACH image, read its `description` and `purpose` fields. Identify which paragraph in YOUR content discusses the SAME concept. That's where the marker goes (semantic matching).\n   \n   **Step 3: PLACE using the \"Visual Anchor\" Rule:**\n   - Place the marker **immediately AFTER the paragraph** that explains the concept the image depicts.\n   - The reader finishes reading about a concept â†’ sees the visual â†’ thinks \"Ah, THIS is what they mean.\"\n   - **NEVER** place an image before the concept is introduced (no context yet).\n   - **NEVER** place an image 3+ paragraphs after the concept (reader has moved on).\n\n   **ğŸ§  Psychology Rules:**\n   - **Visual Anchoring:** Images cement the *preceding* text in memory. Place after the \"aha moment\" paragraph.\n   - **Cognitive Offloading:** After dense technical text (code, architecture), place the diagram/flowchart image to let the reader's brain \"offload\" into a visual model.\n   - **300-500 Word Rhythm:** Space images ~400 words apart. Don't cluster them.\n   - **\"Screenshot Test\":** If a reader screenshots the image + the paragraph above it, does it tell a complete mini-story? If yes â†’ correct placement.\n\n   **âš ï¸ Anti-Patterns:** âŒ All images at top âŒ Image after heading but before explanatory text âŒ Image after CTA/conclusion âŒ Ignoring `description` field\n\n   **Example:**\n     ```\n     ## The 3-Layer Validation Architecture\n\n     Layer 1 catches empty objects at the webhook. Layer 2 validates required fields...\n\n     <<IMAGE_1>>\n\n     With this architecture deployed, reliability jumped from 60% to 99.7%...\n     ```\n   - These markers will be replaced with Sanity CDN URLs in Part 2 automation.\n</devto_optimization_rules>\n\n<community_engagement_enhancement>\n**10. The \"Community Debate\" CTA Framework (Upgraded for Dopamine):**\n    - The discussion question at the end is the MOST IMPORTANT part for Dev.to engagement.\n    - It must NOT be generic (\"What do you think?\") - generic questions get zero replies.\n    - **Formula:** Challenge + Specificity + Promised Value\n    - GOOD: \"I used n8n for this, but I've seen people use Temporal.io for similar patterns. Has anyone compared the two in production? I'd love to know the failure modes.\"\n    - GOOD: \"What's the most creative error recovery pattern you've built? I'm collecting approaches for a follow-up post and will credit contributors.\"\n    - BAD: \"Thoughts?\" or \"What do you think?\" or \"Let me know in the comments.\"\n    - WHY: Exciting, specific questions trigger \"instinctive elaboration\" - the reader's brain starts composing an answer BEFORE they decide to comment. Promising to credit contributors makes replying feel valuable.\n    - This invites developers to share THEIR expertise, creating a community vs. a broadcast.\n\n**11. The \"Follow Magnet\" Close:**\n    - After the discussion question, add a value-forward follow prompt.\n    - GOOD: \"I'm documenting my entire build-in-public journey here on Dev.to - next week I'll cover [related topic]. Follow if you want the next part.\"\n    - This converts one-time readers into recurring followers.\n\n**12. Authenticity Through Struggle (Pratfall Effect - SPECIFICITY REQUIRED):**\n    - Before the solution section, include a \"What I Tried First (That Failed)\" subsection.\n    - Show 1-2 approaches that DIDN'T work before revealing the solution.\n    - âš ï¸ Do NOT use generic formulas like \"I struggled with X\" or \"This was harder than expected.\"\n    - Instead, describe the EXACT specific moment: \"I ran the webhook test 14 times, getting green checkmarks each time, before realizing the IF node was passing empty objects as valid data.\"\n    - The more specific and small the moment, the more universally relatable it becomes. People trust competent people MORE after seeing a specific, relatable flaw (Pratfall Effect).\n\n**13. The \"But...Therefore\" Rule (Anti-Monotony):**\n     - NEVER chain ideas with \"and then\" or \"additionally\" or \"furthermore.\"\n     - Connect narrative beats with \"But\" (conflict) and \"Therefore/So\" (consequence).\n     - Example: \"The API call was returning data. But half the fields were null. So I added a schema validator as middleware.\"\n     - This forces causal momentum and kills the monotone AI writing pattern that readers instantly detect.\n\n**14. Save-Trigger CTA (The Bookmark Hook):**\n     - End with a CTA that makes the reader bookmark, not just scroll past.\n     - GOOD: \"Bookmark this for the next time you need to debug webhook payloads.\"\n     - GOOD: \"Save this pattern - you will need it when your n8n workflows start failing at scale.\"\n     - BAD: \"Thanks for reading!\" or \"Hope this was helpful!\"\n     - Place this BEFORE the discussion question, not after it.\n\n**15. Specificity Over Vagueness (CROSS-CUTTING):**\n     - Always use exact numbers ($847 not \"around $800\"), digits not words (\"3 layers\" not \"three layers\"), named technologies not generic terms (\"n8n Code node\" not \"custom script\").\n     - Exact figures increase believability 300% vs round numbers.\n     - **\"Human Scale\" Numbers:** Translate raw metrics into felt experience. BAD: \"Improved by 40%.\" GOOD: \"What took 10 seconds now takes 6. On 500 daily requests, that saves 33 minutes per day.\"\n</community_engagement_enhancement>\n\n<forbidden_patterns>\n- NO \"In this article, I will...\" openings.\n- NO corporate buzzwords (leverage, synergy, game-changer).\n- NO posts without code examples.\n- NO walls of text - max 3 sentences per paragraph.\n- NO clickbait titles that don't deliver.\n- ğŸš« GEMINI-SPECIFIC SLOP: \"It is worth noting that\", \"It's important to remember\", \"This is a crucial aspect\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", excessive hedging (\"might potentially\", \"could possibly\"), filler transitions (\"Moving on to\", \"Let's now look at\", \"With that said\"), fake enthusiasm (\"Revolutionary!\", \"Mind-blowing!\", \"This changes everything!\"), transition padding (\"Having established that\", \"Before we dive in\", \"Now, let's move on to\").\n- ğŸš« EM-DASH BAN: NEVER use the em-dash character \"â€”\" anywhere. It is a telltale sign of AI text (humans cannot easily type it). Use a regular hyphen \"-\" or rephrase instead.\n</forbidden_patterns>\n\n<project_scope_guardrail>\nâš ï¸ ANTI-HALLUCINATION: The personalContext contains ALL of Aman's projects. You must ONLY reference the project described in sourceContent.fullText as the main case study. Do NOT swap it with a different project from personalContext.strategic.projectHooks.\n</project_scope_guardrail>\n\n<output_format>\nReturn ONLY valid JSON:\n\n{\n  \"formatted_markdown\": \"# Title\\n\\n**TL;DR:**\\n- Point 1\\n- Point 2\\n\\n---\\n\\n## Prerequisites\\n...rest of content...\",\n  \"structured_data\": {\n    \"seo\": {\n      \"title\": \"How I [Solved X] with [Y] | Dev.to\",\n      \"meta_description\": \"A practical guide to...\",\n      \"tags\": [\"#tag1\", \"#tag2\", \"#tag3\", \"#tag4\"],\n      \"series\": \"Optional: Series Name if part of a series\",\n      \"cover_image_concept\": \"Description of ideal cover image\"\n    },\n    \"engagement\": {\n      \"discussion_question\": \"The question at the end to drive comments\",\n      \"estimated_read_time\": \"5 min\"\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nâ˜ Title follows one of the proven patterns\nâ˜ TL;DR at the top (2-3 bullets)\nâ˜ At least 2 code blocks with syntax highlighting\nâ˜ Exactly 4 tags in metadata\nâ˜ Discussion question at the end\nâ˜ First-person \"I\" voice throughout\nâ˜ Real project/example from sourceContent (not invented)\nâ˜ 1,200-2,000 words for tutorials, 500-900 for quick wins\nâ˜ No em-dash \"â€”\" characters anywhere. Use \"-\" instead.\nâ˜ No forbidden patterns used\nâ˜ SUCCESs Quality Gate:\n  - Simple: Is the core problem and solution clear from the TL;DR?\n  - Unexpected: Does the hook break a pattern or share a surprising failure?\n  - Concrete: Are there specific code blocks, metrics, or tool names (exact numbers, digits not words)?\n  - Credible: Does every claim trace to sourceContent?\n  - Emotional: Does the post connect to real developer struggles?\n  - Story: Does the post follow Problem -> Failed Attempts -> Solution arc?\nâ˜ Vulnerability is SPECIFIC (not generic \"I struggled with...\") - must describe an exact debugging moment.\nâ˜ Discussion question uses the Challenge + Specificity + Promised Value formula.\nâ˜ Each major section starts with a 1-2 sentence direct answer (AEO optimization).\nâ˜ Reflection Self-Check: \"Read this post as a junior developer finding it on Dev.to. Would they bookmark it? Would they leave a comment sharing their own experience? If not, identify the weak section and strengthen it.\"\n</validation_before_return>\n</system_instructions>",
              "role": "model"
            },
            {
              "content": "=<context>\n<protected_urls>\nâš ï¸ PRESERVE_EXACT - These are ATOMIC strings. Reproduce verbatim. Do NOT autocorrect, truncate, or modify ANY part.\n- LinkedIn: https://www.linkedin.com/in/amansuryavanshi-ai/\n- Portfolio: https://amansuryavanshi.me/\n- Twitter/X: https://twitter.com/_AmanSurya\n- GitHub: https://github.com/AmanSuryavanshi-1\n</protected_urls>\n\n<my_professional_profile>\n{{ $json.personalContext }}\n</my_professional_profile>\n<the_content_strategy>\n{{ $json.strategy }}\n</the_content_strategy>\n\n<the_source_of_truth>\nThis is the actual content I created - use this as the foundation for the article.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<content_metadata>\n- Title: {{ $json.sourceContent.title }}\n- Category: {{ $json.sourceContent.primaryCategory }}\n- Word Count: {{ $json.sourceContent.wordCount }}\n</content_metadata>\n\n<market_intelligence>\n{{ $json.research }}\n</market_intelligence>\n</context>\n\n<critical_recap>\nBEFORE GENERATING, RE-READ THESE NON-NEGOTIABLE RULES:\n1. URLs from <protected_urls> must appear EXACTLY as written - no autocorrection.\n2. You MUST use ALL image markers from strategy.image_strategy.specific_prompts.\n3. Every claim must trace back to sourceContent. No invented projects, metrics, or examples.\n4. No banned words from the Anti-Slop list.\n5. EXACTLY 4 tags - no more, no less.\n6. Tool-Assisted Validation: Before outputting the final JSON, use any available thinking tools to verify the TL;DR accurately summarizes the article, the community debate question invites genuine discussion, all code examples are correct and traceable to sourceContent, and anti-slop rules are followed.\n</critical_recap>\n\n<task>\nWrite a Dev.to article that transforms this sourceContent into a beginner-friendly, engaging tutorial. Focus on practical code examples and invite community discussion. The article should position me as a helpful expert while attracting potential employers and clients who browse Dev.to.\n</task>"
            }
          ]
        },
        "options": {
          "maxOutputTokens": 8192,
          "temperature": 0.7
        }
      },
      "id": "cb0a03e2-01d2-4441-9930-16340f94eb18",
      "name": "Gemini - Dev.to Content Generation",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3952,
        2736
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "JKGAnDvxRaaMLn0W",
          "name": "Google Gemini(PaLM) Api key 2"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3-pro-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3-pro-preview"
        },
        "messages": {
          "values": [
            {
              "content": "<system_instructions>\n<prime_directive>\nINSTRUCTION PRIORITY (Read this FIRST and LAST):\n1. Source fidelity: Every claim traceable to sourceContent. Zero invention.\n2. Anti-slop: No banned words. No corporate filler. No emoji spam.\n3. First-person \"I\" voice. Active voice only.\n4. Output must be valid JSON - no markdown fences, no extra text.\n</prime_directive>\n\n<role>\nYou are Aman Suryavanshi - a Next.js developer and n8n automation specialist writing for HASHNODE, the developer blogging platform known for custom domains and SEO power. Your goal is to write articles that:\n1. **Rank on Google AND AI Search**: Hashnode blogs get indexed well - optimize for discoverability.\n2. **Build Personal Brand Authority**: This is YOUR blog, not a community post. Write like a thought leader.\n3. **Generate Inbound Leads**: Attract freelance clients and job offers through demonstrated expertise.\n\nYour tone is authoritative, detailed, and technically deep. You're writing the definitive reference on this topic.\n</role>\n\n<critical_instruction>\n**Hashnode Audience Psychology:**\n- **Primary Audience**: Mid-senior developers, tech leads, and hiring managers researching solutions.\n- **What Wins**: In-depth technical content, architectural decisions, production war stories, and original insights.\n- **What Fails**: Beginner tutorials (that's Dev.to's territory), clickbait, shallow overviews.\n- **Discovery**: Google search, AI engines (Perplexity, ChatGPT), and RSS subscribers.\n\n**Source Fidelity:** The provided `sourceContent` is your truth. You may expand on technical implications and industry context, but NEVER invent projects, metrics, or examples not in the source.\n</critical_instruction>\n\n<hashnode_optimization_rules>\n**1. Title Formula (The \"Authority Builder\"):**\n   - Pattern A: \"The Complete Guide to [Technical Topic]\" (e.g., \"The Complete Guide to Self-Healing n8n Workflows\")\n   - Pattern B: \"[Specific Problem]: A Deep Dive into [Solution]\" (e.g., \"API Rate Limiting: A Deep Dive into Intelligent Key Rotation\")\n   - Pattern C: \"Building [X]: Architecture Decisions and Lessons Learned\" (e.g., \"Building a 74-Node Content Automation System: Architecture Decisions\")\n   - Include primary keyword naturally.\n\n**2. Structure (The \"Reference Manual\" Template):**\n   - **Meta Description**: 150-160 chars, keyword-rich, compelling.\n   - **Executive Summary**: 3-5 sentences covering problem, approach, and outcome.\n   - **Table of Contents**: For posts >1,500 words.\n   - **The Context**: Why this problem matters, industry background.\n   - **Architecture/Approach**: High-level design decisions with diagrams.\n   - **Implementation Deep Dive**: Step-by-step with extensive code.\n   - **Edge Cases & Gotchas**: What can go wrong and how to handle it.\n   - **Performance/Results**: Metrics, before/after comparisons.\n   - **Conclusion & Next Steps**: Summary and what's coming next.\n   - **About the Author**: 2-3 sentences positioning yourself for opportunities.\n\n**3. Content Length:**\n   - **Sweet Spot**: 1,800-2,500 words for deep dives.\n   - **Definitive Guides**: 2,500-4,000 words for comprehensive references.\n   - Hashnode rewards depth over brevity.\n\n**4. SEO & AI Discovery (CRITICAL):**\n   - **The Expert Card (First 150 words)**: State your name, expertise, and what specific problem this solves.\n   - **H2 Headers as Questions**: Match how people query AI (e.g., \"Why Does n8n Fail at Scale?\" not \"Scaling Issues\").\n   - **Quotable Insights**: Include 2-3 standalone, insight-dense sentences that AI engines will cite.\n   - **Internal Links**: Reference your other Hashnode posts, GitHub repos, portfolio.\n   - **Canonical URL**: If cross-posting from Dev.to, set canonical.\n\n**5. Code Blocks (The \"Production Code\" Standard):**\n   - Include complete, production-ready examples.\n   - Add file paths and context: // packages/api-manager/src/rotator.ts\n   - Use TypeScript when possible for credibility.\n   - Explain edge cases inline with comments.\n   - For long implementations, show architecture first, then drill into key functions.\n\n**6. Tag Strategy (Hashnode Tags):**\n   - Use 3-5 relevant tags.\n   - Primary: #nextjs, #n8n, #automation, #typescript\n   - Secondary: #webdev, #productivity, #devops\n   - Niche: #selfhosted, #ai, #lowcode, #agents\n\n**7. Series Support:**\n   - If this is part of a multi-part series, indicate series name and part number.\n   - Hashnode's series feature groups related posts - great for SEO.\n\n**8a. Visual Content:**\n   - Include architecture diagrams or flowcharts.\n   - Use Mermaid diagrams (Hashnode supports them).\n   - Add code result screenshots where helpful.\n\n**8b. Image Marker Integration - The \"Storyboard\" Placement System (CRITICAL):**\n   Images are NOT decoration. They are **comprehension tools**. Each image must sit immediately after the text it visually represents, creating a text+visual storyboard.\n\n   **Step 1: COUNT** - Read `strategy.image_strategy.specific_prompts` and count the images. Use EXACTLY that many markers. NEVER invent extras.\n   \n   **Step 2: MATCH** - For EACH image, read its `description` and `purpose` fields. Identify which paragraph in YOUR content discusses the SAME concept. That's where the marker goes (semantic matching).\n   \n   **Step 3: PLACE using the \"Visual Anchor\" Rule:**\n   - Place the marker **immediately AFTER the paragraph** that explains the concept the image depicts.\n   - The reader finishes reading about a concept â†’ sees the visual â†’ thinks \"Ah, THIS is what they mean.\"\n   - **NEVER** place an image before the concept is introduced (no context yet).\n   - **NEVER** place an image 3+ paragraphs after the concept (reader has moved on).\n\n   **ğŸ§  Psychology Rules:**\n   - **Visual Anchoring:** Images cement the *preceding* text in memory. Place after the \"aha moment\" paragraph.\n   - **Cognitive Offloading:** After dense technical text (code, architecture), place the diagram/flowchart image to let the reader's brain \"offload\" into a visual model.\n   - **300-500 Word Rhythm:** Space images ~400 words apart. Don't cluster them.\n   - **\"Screenshot Test\":** If a reader screenshots the image + the paragraph above it, does it tell a complete mini-story? If yes â†’ correct placement.\n\n   **âš ï¸ Anti-Patterns:** âŒ All images at top âŒ Image after heading but before explanatory text âŒ Image after CTA/conclusion âŒ Ignoring `description` field\n\n   **Example:**\n     ```\n     ## The 3-Layer Validation Architecture\n\n     Layer 1 catches empty objects at the webhook. Layer 2 validates required fields...\n\n     <<IMAGE_1>>\n\n     With this architecture deployed, reliability jumped from 60% to 99.7%...\n     ```\n   - These markers will be replaced with Sanity CDN URLs in Part 2 automation.\n\n**9. The \"Thought Leader\" Voice:**\n   - Make architectural decisions explicit: \"I chose X over Y because...\"\n   - Acknowledge tradeoffs: \"This approach sacrifices A for B.\"\n   - Reference industry context: \"While most tutorials suggest X, in production you'll find...\"\n   - Position opinions confidently but acknowledge alternatives.\n\n**10. Lead Generation Elements:**\n   - **Portfolio Proof**: Link to live projects demonstrating the technique.\n   - **Soft CTA**: \"If you're building something similar, I'd love to hear your approach.\"\n   - **About Section**: \"I'm Aman Suryavanshi, specializing in n8n automation and Next.js. Currently open to [X] opportunities.\"\n\n**11. AI Engine Citation Optimization (AEO/GEO - MANDATORY):**\n   - AI search engines (Perplexity, ChatGPT, Claude) increasingly cite blog posts as sources.\n   - To maximize citation:\n     a. **The \"Two-Sentence Answer\" Rule (MANDATORY):** For EVERY H2 section, the FIRST TWO SENTENCES must directly and concisely answer the question implied by the heading. AI engines extract these leading sentences as citation snippets. This is your #1 lever for AI discoverability.\n        EXAMPLE:\n        ## Why Does n8n Fail at Scale?\n        \"n8n fails at scale because its default execution model processes webhooks synchronously, causing payload loss when concurrent requests exceed the processing queue. The fix requires async processing with a validation gate.\"\n        THEN expand with depth, examples, code.\n     b. **Quotable Insights:** Include 3-4 standalone, insight-dense sentences formatted as blockquotes. These become the snippets AI engines quote.\n     c. **Comparative Framing:** When possible, compare your approach against alternatives (e.g., \"Unlike Zapier's approach, n8n allows...\"). AI engines love comparative content for recommendation queries.\n     d. **Specificity over Generality:** Use exact numbers, version numbers, and tool names. \"n8n v1.74.0\" > \"the latest version.\" Exact figures increase believability 300% vs round numbers.\n\n**12. The \"Sinatra Test\" Authority Signal:**\n   - Include ONE \"killer credential\" early in the article that implies competence in everything else.\n   - GOOD: \"...the same pattern I used in the 74-node production automation that processes 500+ content pieces monthly.\"\n   - This is the Sinatra Test: \"If I can make it THERE, I can make it anywhere.\"\n   - One strong proof point > five weak ones.\n\n**13. Trade-Off Transparency:**\n   - For every major technical decision, explicitly state the TRADE-OFF.\n   - \"I chose n8n over Temporal because [X], but this means sacrificing [Y].\"\n     - Acknowledging limitations is a strong trust signal - it proves you're thinking at a systems level, not just evangelizing.\n\n**14. The \"But...Therefore\" Rule (Anti-Monotony):**\n     - NEVER chain ideas with \"and then\" or \"additionally\" or \"furthermore.\"\n     - Connect narrative beats with \"But\" (conflict) and \"Therefore/So\" (consequence).\n     - Example: \"The self-hosted n8n instance was running smoothly. But it started dropping webhooks under load. So I redesigned the queue system with dead-letter recovery.\"\n     - This forces causal momentum and kills the monotone AI writing pattern that technical readers instantly detect.\n\n**15. Save-Trigger CTA (The Bookmark Hook):**\n     - End with a CTA that makes the reader bookmark this as a reference.\n     - GOOD: \"Bookmark this architecture reference - you will need it when your n8n workflows hit production scale.\"\n     - GOOD: \"Save this guide for the next time you need to debug self-hosted automation infrastructure.\"\n     - BAD: \"Thanks for reading!\" or \"Hope you found this useful!\"\n     - This is your personal blog - make every post a reusable asset, not a one-time read.\n\n**16. The \"Chain of Density\" Self-Edit (CRITICAL for Quality):**\n     - After drafting the full post, mentally re-read each paragraph and ask:\n       - Can I REMOVE a sentence without losing meaning? -> Remove it.\n       - Can I REPLACE a vague phrase with a specific one? -> Replace. (\"improved performance\" -> \"cut LCP from 4.2s to 1.1s\")\n       - Does this paragraph add a NEW insight or just rephrase the previous one? -> If rephrase, merge or delete.\n     - Output must feel like it went through aggressive editorial trimming. Every paragraph should be dense with insight, not padded with filler.\n     - **\"Human Scale\" Numbers:** Raw metrics are abstract. Always translate into felt experience. BAD: \"Improved performance by 40%.\" GOOD: \"What used to take 10 seconds now takes 6. On 500 daily requests, that is 33 minutes saved per day.\"\n\n**17. The \"Name Your Framework\" Principle (Thought Leadership):**\n     - When you describe a multi-step solution, a pattern, or a methodology from the source content - NAME IT.\n     - Example: \"The 3-Layer Validation Pattern\" instead of \"my validation approach.\"\n     - Example: \"The Semantic Gate Architecture\" instead of \"the system I built.\"\n     - WHY: Named frameworks are proprietary. They make your ideas \"sticky,\" create thought leadership differentiation, and become the terms other people use to reference YOUR solution. AI engines are also more likely to cite named patterns.\n\n**18. Authenticity Signal (Pratfall Effect - SPECIFICITY REQUIRED):**\n     - Do NOT use generic formulas like \"I honestly struggled with X.\" Instead, describe the EXACT specific moment of confusion or frustration.\n     - GOOD: \"I spent 2 hours staring at n8n execution logs before realizing the webhook fires BEFORE the payload is parsed.\"\n     - The more specific and small the moment, the more universally relatable it becomes. People trust competent people MORE after seeing a specific, relatable flaw (Pratfall Effect).\n</hashnode_optimization_rules>\n\n<forbidden_patterns>\n- NO beginner-level explanations of basic concepts.\n- NO \"let's get started\" or \"without further ado\" openings.\n- NO thin content - every section must add value.\n- NO corporate buzzwords (leverage, synergy, unlock).\n- NO posts without substantial code examples.\n- ğŸš« GEMINI-SPECIFIC SLOP: \"It is worth noting that\", \"It's important to remember\", \"This is a crucial aspect\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", excessive hedging (\"might potentially\", \"could possibly\"), filler transitions (\"Moving on to\", \"Let's now look at\", \"With that said\"), fake enthusiasm (\"Revolutionary!\", \"Mind-blowing!\", \"This changes everything!\"), transition padding (\"Having established that\", \"Before we dive in\", \"Now, let's move on to\").\n- ğŸš« EM-DASH BAN: NEVER use the em-dash character \"â€”\" anywhere. It is a telltale sign of AI text (humans cannot easily type it). Use a regular hyphen \"-\" or rephrase instead.\n</forbidden_patterns>\n\n<project_scope_guardrail>\nâš ï¸ ANTI-HALLUCINATION: The personalContext contains ALL of Aman's projects. You must ONLY reference the project described in sourceContent.fullText as the main case study. Do NOT swap it with a different project from personalContext.strategic.projectHooks.\n</project_scope_guardrail>\n\n<output_format>\nReturn ONLY valid raw JSON.\nCRITICAL INSTRUCTION: Do NOT wrap the output in markdown code fences (like ```json). \nStart the response immediately with the opening curly brace { and end with the closing curly brace }.\n\n{\n  \"formatted_markdown\": \"# Title\\n\\n*Executive Summary: 3-5 sentences...*\\n\\n---\\n\\n## Table of Contents\\n- [Section 1](#section-1)\\n...rest of content...\",\n  \"structured_data\": {\n    \"seo\": {\n      \"title\": \"The Complete Guide to [X] | Aman Suryavanshi\",\n      \"slug\": \"the-complete-guide-to-x\",\n      \"meta_description\": \"150-160 char description with primary keyword...\",\n      \"tags\": [\"#tag1\", \"#tag2\", \"#tag3\", \"#tag4\", \"#tag5\"],\n      \"canonical_url\": \"Optional: URL if cross-posting\",\n      \"series\": \"Optional: Series Name\"\n    },\n    \"engagement\": {\n      \"estimated_read_time\": \"8 min\",\n      \"key_takeaways\": [\"Takeaway 1\", \"Takeaway 2\", \"Takeaway 3\"]\n    },\n    \"lead_gen\": {\n      \"portfolio_links\": [\"Relevant project links\"],\n      \"cta\": \"The soft call-to-action used\"\n    }\n  }\n}\n</output_format>\n\n<validation_before_return>\nâ˜ Title follows one of the authority-builder patterns\nâ˜ Executive summary in first 150 words\nâ˜ Table of contents for posts >1,500 words\nâ˜ At least 3 substantial code blocks\nâ˜ H2 headers use question format where appropriate\nâ˜ 2-3 quotable insights (bold or blockquote)\nâ˜ Meta description exactly 150-160 characters\nâ˜ First-person \"I\" voice with authority\nâ˜ Real project/example from sourceContent (not invented)\nâ˜ 1,800-2,500 words minimum for deep dives\nâ˜ About the Author section\nâ˜ No em-dash \"â€”\" characters anywhere. Use \"-\" instead.\nâ˜ No forbidden patterns used\nâ˜ SUCCESs Quality Gate:\n  - Simple: Is the core architectural decision clear from the executive summary?\n  - Unexpected: Does the post reveal a non-obvious insight or challenge conventional wisdom?\n  - Concrete: Are there production-ready code blocks, metrics, and tool versions (exact numbers, digits not words)?\n  - Credible: Does every claim trace to sourceContent? Is the \"Sinatra Test\" credential present?\n  - Emotional: Does the post connect to real engineering challenges and tradeoffs?\n  - Story: Does the post follow Context -> Architecture -> Implementation -> Results arc?\nâ˜ Chain of Density applied: Every paragraph is dense with insight, no filler or rehashing.\nâ˜ Authenticity signal is SPECIFIC (not generic \"I struggled with...\") - must describe an exact moment.\nâ˜ Every H2 section starts with a two-sentence direct answer (AEO/GEO optimization).\nâ˜ At least one solution/pattern is NAMED (\"The X Pattern\") for thought leadership.\nâ˜ Reflection Self-Check: \"Read this post as both (1) a senior engineer evaluating your depth and (2) an AI engine evaluating your citation-worthiness. Would the engineer share it? Would the AI cite it? If not, identify the weak section and strengthen it.\"\n</validation_before_return>\n</system_instructions>",
              "role": "model"
            },
            {
              "content": "=<context>\n<protected_urls>\nâš ï¸ PRESERVE_EXACT - These are ATOMIC strings. Reproduce verbatim. Do NOT autocorrect, truncate, or modify ANY part.\n- LinkedIn: https://www.linkedin.com/in/amansuryavanshi-ai/\n- Portfolio: https://amansuryavanshi.me/\n- Twitter/X: https://twitter.com/_AmanSurya\n- GitHub: https://github.com/AmanSuryavanshi-1\n</protected_urls>\n\n<my_professional_profile>\n{{ $json.personalContext }}\n</my_professional_profile>\n<the_content_strategy>\n{{ $json.strategy }}\n</the_content_strategy>\n\n<the_source_of_truth>\nThis is the actual content I created - use this as the foundation for the article.\n{{ $json.sourceContent.fullText }}\n</the_source_of_truth>\n\n<content_metadata>\n- Title: {{ $json.sourceContent.title }}\n- Category: {{ $json.sourceContent.primaryCategory }}\n- Word Count: {{ $json.sourceContent.wordCount }}\n</content_metadata>\n\n<market_intelligence>\n{{ $json.research }}\n</market_intelligence>\n</context>\n\n<critical_recap>\nBEFORE GENERATING, RE-READ THESE NON-NEGOTIABLE RULES:\n1. URLs from <protected_urls> must appear EXACTLY as written - no autocorrection.\n2. You MUST use ALL image markers from strategy.image_strategy.specific_prompts.\n3. Every claim must trace back to sourceContent. No invented projects, metrics, or examples.\n4. No banned words from the Anti-Slop list.\n5. Include \"About the Author\" section at the end for lead generation.\n6. Tool-Assisted Validation: Before outputting the final JSON, use any available thinking tools to verify the intro answers the core question in the first 100 words for AEO/GEO, H2s are question-format for featured snippets, chain-of-density is applied, named frameworks are used instead of generic advice, and the About the Author section is present.\n</critical_recap>\n\n<task>\nWrite an authoritative Hashnode article that positions me as a thought leader. Focus on architectural decisions, production-ready code, and deep technical insights. The article should rank well on Google and be cited by AI search engines, while attracting potential clients and employers.\n</task>"
            }
          ]
        },
        "options": {
          "maxOutputTokens": 8192,
          "temperature": 0.6
        }
      },
      "id": "a4c47e16-7c73-4e05-b289-a2c583282840",
      "name": "Gemini - Hashnode Content Generation",
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3952,
        3120
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "wLs02bTssiS8r2cq",
          "name": "Google Gemini(PaLM) Api Key 7"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Return placeholder for skipped Hashnode draft\nreturn [{\n  json: {\n    id: null,\n    platform: 'hashnode',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4528,
        3312
      ],
      "id": "d63c2037-e584-4066-9a96-0c2d5d11bd9c",
      "name": "Code - No-Op Hashnode Draft"
    },
    {
      "parameters": {
        "content": "## 2. CONTEXT & STRATEGY ENGINE\n**Goal:** Build the 'Brain' for the AI before generation starts.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Nodes Explained:\n- **Context - Fetch Portfolio:** Pulls your latest achievements/projects via API (Real-time Credibility).\n- **Perplexity â€“ Research:** Searches the web for trending hashtags, stats, and 'Blue Ocean' angles.\n- **Code â€“ CONTEXT MERGER:** The most critical node. It effectively combines:\n  1. Your Profile (Voice/Tone)  +  2. Source Content (The Topic) + 3. Research (The Market) = **MASTER CONTEXT**",
        "height": 400,
        "width": 1232
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1712,
        2544
      ],
      "typeVersion": 1,
      "id": "274328b1-5495-4e72-b540-48fcc3e6de78",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "content": "## 1. INGESTION & ANALYSIS\n**Goal:** Fetch content from Notion and prepare it for processing.\n### Nodes Explained:\n- **Notion â€“ Get Ready Content:** Polls your content calendar for pages marked 'Ready to Post'.\n- **Filter â€“ Has Content:** Safety check to ensure the page isn't empty.\n- **Notion â€“ Extract All Blocks:** Recursively fetches every block (text, images, toggles) from the page.\n- **Code â€“ Extract & Process Content:**  Cleans the raw Notion data into a simple text string for the AI.",
        "height": 480,
        "width": 1788,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1712,
        2064
      ],
      "name": "Note - Ingestion",
      "id": "dbef22a7-f34a-4e44-8a4c-96f5f4fc64bf"
    },
    {
      "parameters": {
        "content": "## 4. MULTI-LLM GENERATION MATRIX (PARALLEL)\n**Goal:** Generate native content for every\n platform simultaneously.\n### How it works:\nThis zone uses **Parallel Execution**. \nAll branches run at the same time for speed.\n\n## 6 Branches =>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
        "height": 2280,
        "width": 1328,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        3520,
        1424
      ],
      "name": "Note - Generation",
      "id": "3454f600-9924-4ed1-982d-c9a7250f930d"
    },
    {
      "parameters": {
        "content": "## 5. FINALIZATION & STORAGE\n**Goal:** Save everything and notify you.\n\n### Nodes Explained:\n- **Google Drive (Create Folder):** Creates a unique folder for this specific post ID.\n- **Google Drive (Save):** Saves every generated draft as a `.md` (Markdown) file for safekeeping.\n- **Notion â€“ Status Update:** \n  1. Writes the Google Drive Links back to the original Notion page.\n  2. Sets status to `Pending Approval` so you know it's ready for review.",
        "height": 456,
        "width": 520,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        4848,
        2256
      ],
      "name": "Note - Status",
      "id": "f4a83a95-4143-4099-b6e9-1c7bc862513a"
    },
    {
      "parameters": {
        "content": "## 3. Gemini - AI STRATEGIST\n### A dedicated AI step that plans the content strategy *before* writing.",
        "height": 400,
        "width": 560,
        "color": 3
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2944,
        2544
      ],
      "typeVersion": 1,
      "id": "e6e5c504-3d2d-42de-9453-93133a34e14a",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "content": "## 3. Blogs BRANCH 3 -(Personal): Long-form SEO. Focus: Tutorials, Code snippets, Deep Dives.",
        "height": 224,
        "width": 832,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3872,
        2288
      ],
      "typeVersion": 1,
      "id": "6096087d-c16b-4b85-b903-05621c60b3c7",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "content": "## 1. BRANCH 1 - Twitter: Generates a thread. Focus: <280 chars, hooks, punchy.\n",
        "height": 208,
        "width": 848,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3872,
        1536
      ],
      "typeVersion": 1,
      "id": "d0b54266-ff8a-4817-ad9d-c4ec7fa2237c",
      "name": "Sticky Note6"
    },
    {
      "parameters": {
        "content": "## 2. BRANCH 2 -LinkedIn: Professional post. Focus: Storytelling, 'Bro-etry' formatting.",
        "height": 224,
        "width": 832,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3872,
        1904
      ],
      "typeVersion": 1,
      "id": "96d9767c-f303-42de-aa42-9ae78398ea37",
      "name": "Sticky Note8"
    },
    {
      "parameters": {
        "content": "## 6. Images: Extracts 'Image Ideas' into a task list (It does NOT generate images yet, just prompts).",
        "height": 224,
        "width": 816,
        "color": 2
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3888,
        3440
      ],
      "typeVersion": 1,
      "id": "368c19af-0087-403a-aef5-b867c3e8fdc1",
      "name": "Sticky Note10"
    },
    {
      "parameters": {
        "content": "## 5. Blogs BRANCH 5 -(Hashnode): Long-form SEO. Focus: Tutorials, Code snippets, Deep Dives.",
        "height": 240,
        "width": 816,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3888,
        3040
      ],
      "typeVersion": 1,
      "id": "0c5448e0-b049-4f67-8af6-84e3783342b3",
      "name": "Sticky Note9"
    },
    {
      "parameters": {
        "content": "## **Note:** - 'No-Op' nodes ensure the workflow doesn't \n## crash if you unselect a platform.",
        "height": 96,
        "width": 832
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3840,
        1792
      ],
      "typeVersion": 1,
      "id": "88f932ba-4920-4931-b5e3-c4fde1d27355",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "45497a71-360c-4d5e-b49d-304d21da3270",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2.1,
      "position": [
        1776,
        2272
      ],
      "id": "f1e01a47-4733-4c30-919a-40144ccfccf8",
      "name": "Webhook",
      "webhookId": "45497a71-360c-4d5e-b49d-304d21da3270"
    },
    {
      "parameters": {
        "jsCode": "// Return placeholder for skipped Dev.to draft\nreturn [{\n  json: {\n    id: null,\n    platform: 'devto',\n    skipped: true,\n    reason: 'Platform not selected in Notion'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4528,
        2928
      ],
      "id": "2a027fcb-4620-41f7-a6c9-b9af4f511335",
      "name": "Code - No-Op Dev.to Draft"
    },
    {
      "parameters": {
        "content": "## 4. Blogs BRANCH 4 -(Dev.to): Long-form SEO. Focus: Tutorials, Code snippets, Deep Dives.",
        "height": 224,
        "width": 816,
        "color": 7
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        3888,
        2672
      ],
      "typeVersion": 1,
      "id": "61ce3d0b-bcc2-445b-8e61-2f3786949421",
      "name": "Sticky Note7"
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        2352
      ],
      "id": "58bf6d8c-b58a-4843-8236-564f198611dc",
      "name": "Update Notion (Blog)",
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// TWITTER PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Twitter Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable thread text with --- separators\n// \n// HANDLES:\n// - Escaped newlines (\\\\n, \\\\\\\\n, etc.)\n// - Truncated AI responses (MAX_TOKENS)\n// - Thread stitching from structured_data.threads\n// - JSON wrapped in markdown fences\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    // Handle truncated JSON\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try { rawStr = JSON.stringify(input); } catch (e) { rawStr = \"\"; }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    // Priority 1: formatted_markdown\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    }\n    // Priority 2: markdown field\n    else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    }\n    // Priority 3: Stitch from structured_data.threads\n    else if (parsedJSON.structured_data?.threads) {\n        const threads = parsedJSON.structured_data.threads;\n        const mainThread = Array.isArray(threads) ? threads[0] : threads;\n\n        if (mainThread && mainThread.tweets) {\n            extractedText = mainThread.tweets\n                .map(t => {\n                    let content = t.content || \"\";\n                    if (t.image_marker && !content.includes(t.image_marker)) {\n                        content += \"\\n\\n\" + t.image_marker;\n                    }\n                    return content;\n                })\n                .join('\\n\\n---\\n\\n');\n            debugInfo.extractionMethod = \"structured_data_stitched\";\n        }\n    }\n    // Priority 4: text field\n    else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr.replace(/^```json\\s*/i, '').replace(/```$/g, '').trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet cleanText = unescapeContent(extractedText);\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove Twitter-specific headers\ncleanText = cleanText\n    .replace(/^#\\s*Twitter\\s*Draft\\s*\\n+/i, '')\n    .replace(/^Thread\\s*\\d*\\s*\\n+/i, '')\n    .replace(/^Tweet\\s*\\d+\\/\\d+\\s*\\n+/gi, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// Warn about missing thread separators\nif (cleanText.length > 280 && !cleanText.includes('---')) {\n    console.warn('âš ï¸ Twitter thread may be missing separators');\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"Twitter Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
      },
      "id": "cca1a1d2-23f2-4d93-9e47-6b3ee283add0",
      "name": "Code â€“ Prep Twitter API",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        1584
      ]
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "id": "46d37401-583f-4350-848b-fe4691da7894",
      "name": "HTTP â€“ Push Twitter Draft",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        1584
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// LINKEDIN PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"LinkedIn Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable post text\n// \n// HANDLES:\n// - Multiple levels of escaped newlines (\\\\n, \\\\\\\\n, \\\\\\\\\\\\\\\\n)\n// - Truncated AI responses (MAX_TOKENS)\n// - JSON wrapped in markdown fences\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n\n    // Process from most escaped to least escaped\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try { rawStr = JSON.stringify(input); } catch (e) { rawStr = \"\"; }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.structured_data?.posts?.[0]?.content) {\n        extractedText = parsedJSON.structured_data.posts[0].content;\n        debugInfo.extractionMethod = \"structured_data_posts\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr.replace(/^```json\\s*/i, '').replace(/```$/g, '').trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet cleanText = unescapeContent(extractedText);\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove LinkedIn-specific headers\ncleanText = cleanText\n    .replace(/^#\\s*LinkedIn\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"LinkedIn Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
      },
      "id": "0ea55389-c742-4749-bc15-e97991c5529a",
      "name": "Code â€“ Prep LinkedIn API",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        1968
      ]
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "id": "a6ece167-9bab-4635-b0b3-cfed613bdc94",
      "name": "HTTP â€“ Push LinkedIn Draft",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        1968
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// DEV.TO PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Dev.to Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable article\n// \n// Note: DevTo output often comes wrapped in ```json fences - handled here\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n    result = result.replace(/\\\\n/g, '\\n');\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n\n    // CRITICAL: DevTo often wraps in ```json fences\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try { rawStr = JSON.stringify(input); } catch (e) { rawStr = \"\"; }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr.replace(/^```json\\s*/i, '').replace(/```$/g, '').trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet cleanText = unescapeContent(extractedText);\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove platform headers\ncleanText = cleanText\n    .replace(/^#\\s*Dev\\.?to\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"DevTo Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
      },
      "id": "315c7cc8-df8c-443d-9ae5-5dab8e4bdf22",
      "name": "Code â€“ Prep DevTo API",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        2736
      ]
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "id": "f608afc4-691e-4d1a-b48e-8d602b4a6e63",
      "name": "HTTP â€“ Push DevTo Draft",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        2736
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "id": "b61af95e-04ad-4896-803c-ab3d1bdad0e7",
      "name": "HTTP â€“ Push Hashnode Draft",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        3120
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// IMAGE TASKLIST ARCHITECT (vFINAL - GOD TIER ROBUSTNESS)\n// Target: \"Image Task List\"\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// --- 1. CORE UTILITIES ---\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\nfunction semanticChunking(text, maxChars = 1900) {\n    const chunks = [];\n    let currentChunk = \"\";\n    const paragraphs = text.split('\\n\\n');\n\n    for (const paragraph of paragraphs) {\n        if ((currentChunk.length + paragraph.length + 2) <= maxChars) {\n            currentChunk += (currentChunk ? '\\n\\n' : '') + paragraph;\n        } else {\n            if (currentChunk) { chunks.push(currentChunk); currentChunk = \"\"; }\n            if (paragraph.length <= maxChars) {\n                currentChunk = paragraph;\n            } else {\n                const lines = paragraph.split('\\n');\n                for (const line of lines) {\n                    if ((currentChunk.length + line.length + 1) <= maxChars) {\n                        currentChunk += (currentChunk ? '\\n' : '') + line;\n                    } else {\n                        if (currentChunk) { chunks.push(currentChunk); currentChunk = \"\"; }\n                        if (line.length > maxChars) {\n                            let tempLine = line;\n                            while (tempLine.length > 0) {\n                                chunks.push(tempLine.substring(0, maxChars));\n                                tempLine = tempLine.substring(maxChars);\n                            }\n                        } else { currentChunk = line; }\n                    }\n                }\n            }\n        }\n    }\n    if (currentChunk) chunks.push(currentChunk);\n    return chunks;\n}\n\n// --- 2. STRATEGY PARSING ---\n\nlet extractedText = \"\";\n\n// The previous node sends `strategy` inside input\nif (input.strategy && input.strategy.image_strategy) {\n    const strategy = input.strategy.image_strategy;\n    const prompts = strategy.specific_prompts || [];\n    const title = input.sourceContent?.title || \"Content\";\n\n    if (prompts.length > 0) {\n        let md = `# ğŸ–¼ï¸ Image Tasklist for: ${title}\\n\\n`;\n        md += `**Reason:** ${strategy.rationale || \"Enhance content\"}\\n\\n---\\n\\n`;\n\n        prompts.forEach((task, index) => {\n            const assetNum = index + 1;\n            md += `## Asset ${assetNum}: ${task.purpose || 'Visual Asset'}\\n\\n`;\n            md += `**â¡ï¸ Action Required:**\\n`;\n            md += `- **Type:** ${task.asset_type === 'real_asset' ? 'ğŸ“¸ Real Asset (Screenshot/File)' : 'ğŸ¤– Generative AI (Midjourney/DALL-E)'}\\n`;\n            md += `- **Description:** ${task.description}\\n`;\n            md += `- **Placement:** ${task.position}\\n`;\n            md += `- **Marker:** \\`${task.marker || `<<IMAGE_${assetNum}>>`}\\`\\n\\n`;\n\n            if (task.asset_type !== 'real_asset' && task.fallback_prompt) {\n                md += `**ğŸ’¡ GenAI Prompt:**\\n> ${task.fallback_prompt}\\n\\n`;\n            }\n            md += `---\\n\\n`;\n        });\n        extractedText = md;\n    } else {\n        extractedText = \"âš ï¸ Strategy found, but 'specific_prompts' array was empty. No images required.\";\n    }\n} else {\n    // Fallback if raw text or no strategy\n    extractedText = input.text || \"âš ï¸ No Image Tasks Generated (No Strategy Object Found)\";\n}\n\n// --- 3. CLEANING & FORMATTING ---\nlet cleanText = sanitizeText(extractedText);\n\n// --- 4. SEMANTIC CHUNKING ---\nconst finalChunks = semanticChunking(cleanText, 1900);\nconst richTextArray = finalChunks.map(chunk => ({\n    type: \"text\",\n    text: { content: chunk }\n}));\n\n// --- 5. PAYLOAD GENERATION ---\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"Image Task List\": { \"rich_text\": richTextArray.slice(0, 95) }\n            }\n        }\n    }\n};"
      },
      "id": "e531c78a-6b56-42ff-87dd-405bd38c3823",
      "name": "Code â€“ Prep Image Tasklist API",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        3504
      ]
    },
    {
      "parameters": {
        "method": "PATCH",
        "url": "=https://api.notion.com/v1/pages/{{ $json.notionPageId }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "notionApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Notion-Version",
              "value": "2022-06-28"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.finalApiBody }}",
        "options": {}
      },
      "id": "34f0adef-e419-4fed-bb16-97a9d7638967",
      "name": "HTTP â€“ Push Image Tasklist",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        4528,
        3504
      ],
      "retryOnFail": true,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// HASHNODE PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Hashnode Draft\"\n// Input: Gemini AI Output JSON with formatted_markdown\n// Output: Clean human-readable article\n// \n// HANDLES:\n// - Escaped newlines (\\\\n, \\\\\\\\n, etc.)\n// - Mermaid diagrams with code blocks\n// - Truncated AI responses (MAX_TOKENS)\n// - JSON wrapped in markdown fences\n// - Very long content (proper Notion chunking)\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\n/**\n * CRITICAL: Properly unescape newlines from JSON strings\n * Must handle multiple levels of escaping AND preserve code blocks\n */\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n\n    // Handle quadruple escaping first (\\\\\\\\n -> \\\\n)\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle triple escaping\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle double escaping (\\\\n -> newline) - most common in JSON\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n\n    // Handle single escaping\n    result = result.replace(/\\\\n/g, '\\n');\n\n    // Handle other escape sequences\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n\n    // Clean up remaining double backslashes (but preserve single backslashes for code)\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr;\n\n    let cleanStr = rawStr.trim();\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    // Try direct parse\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) { }\n\n    // Find the outermost JSON object\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) { }\n    }\n\n    // Handle truncated JSON - extract formatted_markdown via regex\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        return {\n            formatted_markdown: markdownMatch[1],\n            _recovered: true,\n            _warning: \"JSON was truncated, extracted markdown via regex\"\n        };\n    }\n\n    return null;\n}\n\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        let breakPoint = maxCharsPerChunk;\n\n        // Prefer breaking at paragraph boundaries\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2;\n        } else {\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    try {\n        rawStr = JSON.stringify(input);\n    } catch (e) {\n        rawStr = \"\";\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseSuccess: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON._recovered) {\n        debugInfo.recovered = true;\n        debugInfo.warning = parsedJSON._warning;\n    }\n\n    // Priority extraction\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n} else {\n    debugInfo.parseSuccess = false;\n\n    // Regex fallback\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n        debugInfo.extractionMethod = \"regex_formatted_markdown\";\n    } else {\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            extractedText = rawStr\n                .replace(/^```json\\s*/i, '')\n                .replace(/```$/g, '')\n                .trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n// Unescape all escape sequences\nlet cleanText = unescapeContent(extractedText);\n\n// Sanitize\ncleanText = sanitizeText(cleanText).trim();\n\n// Remove platform headers\ncleanText = cleanText\n    .replace(/^#\\s*Hashnode\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. OUTPUT\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: {\n                \"Hashnode Draft\": { \"rich_text\": richTextArray }\n            }\n        },\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length\n        }\n    }\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        3120
      ],
      "id": "c79f3ef6-0084-4dfb-8224-fbbaaef69643",
      "name": "Code - Prep Hashnode API"
    },
    {
      "parameters": {
        "jsCode": "// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// SANITY BLOG PAYLOAD ARCHITECT (v3.0 - BATTLE-TESTED PRODUCTION)\n// Target: \"Sanity Blog Draft\" + SEO Metadata\n// Input: Gemini AI Output JSON with formatted_markdown + structured_data.seo\n// Output: Clean markdown + SEO fields\n// \n// HANDLES:\n// - Escaped newlines (\\\\n, \\\\\\\\n, etc.)\n// - Truncated AI responses (MAX_TOKENS)\n// - JSON wrapped in markdown fences\n// - Very long content (proper Notion chunking)\n// - Malformed JSON recovery\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst input = $input.first().json;\nconst notionData = $('Notion â€“ Get Ready Content').first().json;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 1. UTILITY FUNCTIONS\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n/**\n * Sanitizes text by removing zero-width characters and normalizing linebreaks\n */\nfunction sanitizeText(text) {\n    if (!text) return \"\";\n    return String(text)\n        .replace(/\\u0000/g, '')\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, '')\n        .normalize('NFC')\n        .replace(/\\r\\n/g, '\\n');\n}\n\n/**\n * CRITICAL: Properly unescape newlines from JSON strings\n * AI returns content like: \"Line 1\\\\n\\\\nLine 2\" which needs to become actual newlines\n * Must handle multiple levels of escaping\n */\nfunction unescapeContent(text) {\n    if (!text) return \"\";\n\n    let result = text;\n\n    // Handle quadruple escaping first (\\\\\\\\n -> \\\\n)\n    result = result.replace(/\\\\\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle triple escaping (rare but possible)\n    result = result.replace(/\\\\\\\\\\\\n/g, '\\n');\n\n    // Handle double escaping (\\\\n -> newline) - most common in JSON\n    result = result.replace(/\\\\\\\\n/g, '\\n');\n\n    // Handle single escaping (\\n -> newline) - already actual newlines in most cases\n    // But if still escaped as literal backslash-n, convert\n    result = result.replace(/\\\\n/g, '\\n');\n\n    // Handle other escape sequences\n    result = result.replace(/\\\\\\\\r/g, '\\r');\n    result = result.replace(/\\\\r/g, '\\r');\n    result = result.replace(/\\\\\\\\t/g, '\\t');\n    result = result.replace(/\\\\t/g, '\\t');\n    result = result.replace(/\\\\\\\\\"/g, '\"');\n    result = result.replace(/\\\\\"/g, '\"');\n\n    // Clean up any remaining double backslashes\n    result = result.replace(/\\\\\\\\/g, '\\\\');\n\n    return result;\n}\n\n/**\n * Robust JSON parser that handles:\n * - Markdown code fences (```json ... ```)\n * - Embedded JSON strings\n * - Malformed JSON with recovery\n * - Truncated JSON (MAX_TOKENS)\n */\nfunction robustJSONParse(rawStr) {\n    if (!rawStr) return null;\n    if (typeof rawStr === 'object') return rawStr; // Already parsed\n\n    // Step 1: Clean the input string - remove markdown fences\n    let cleanStr = rawStr.trim();\n\n    // Remove leading ```json or ``` fences\n    cleanStr = cleanStr.replace(/^```(?:json)?\\s*/i, '');\n    // Remove trailing ``` fences\n    cleanStr = cleanStr.replace(/```\\s*$/g, '');\n    cleanStr = cleanStr.trim();\n\n    // Step 2: Try direct parse\n    try {\n        return JSON.parse(cleanStr);\n    } catch (e) {\n        // Continue to recovery\n    }\n\n    // Step 3: Find the outermost JSON object\n    const firstBrace = cleanStr.indexOf('{');\n    const lastBrace = cleanStr.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        const jsonCandidate = cleanStr.substring(firstBrace, lastBrace + 1);\n        try {\n            return JSON.parse(jsonCandidate);\n        } catch (e) {\n            // Continue to more aggressive recovery\n        }\n    }\n\n    // Step 4: Handle truncated JSON (common with MAX_TOKENS)\n    // Try to extract formatted_markdown even from broken JSON\n    const markdownMatch = cleanStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        // Also try to extract SEO data via regex since JSON is truncated\n        const seoData = {};\n\n        // Extract SEO title\n        const titleMatch = cleanStr.match(/\"title\"\\s*:\\s*\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\"/);\n        if (titleMatch) seoData.title = titleMatch[1].replace(/\\\\\"/g, '\"');\n\n        // Extract SEO slug\n        const slugMatch = cleanStr.match(/\"slug\"\\s*:\\s*\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\"/);\n        if (slugMatch) seoData.slug = slugMatch[1];\n\n        // Extract SEO meta_description\n        const descMatch = cleanStr.match(/\"meta_description\"\\s*:\\s*\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\"/);\n        if (descMatch) seoData.meta_description = descMatch[1].replace(/\\\\\"/g, '\"');\n\n        // Extract tags array - look for the pattern [\"tag1\", \"tag2\", ...]\n        const tagsMatch = cleanStr.match(/\"tags\"\\s*:\\s*\\[([\\s\\S]*?)\\]/);\n        if (tagsMatch) {\n            // Parse individual tags from the array\n            const tagStrings = tagsMatch[1].match(/\"([^\"]+)\"/g);\n            if (tagStrings) {\n                seoData.tags = tagStrings.map(t => t.replace(/\"/g, ''));\n            }\n        }\n\n        // Return a synthetic object with markdown AND recovered SEO data\n        return {\n            formatted_markdown: markdownMatch[1],\n            structured_data: Object.keys(seoData).length > 0 ? { seo: seoData } : undefined,\n            _recovered: true,\n            _warning: \"JSON was truncated, extracted markdown and SEO via regex\"\n        };\n    }\n\n    return null;\n}\n\n/**\n * CRITICAL: Proper chunking for Notion API\n * - Each rich_text element can be max 2000 chars\n * - Max 100 elements in a rich_text array\n * - We use 1900 to leave buffer for unicode expansion\n */\nfunction chunkForNotion(text, maxCharsPerChunk = 1900) {\n    if (!text) return [{ type: \"text\", text: { content: \"\" } }];\n\n    const chunks = [];\n    let remaining = text;\n\n    while (remaining.length > 0) {\n        if (remaining.length <= maxCharsPerChunk) {\n            chunks.push(remaining);\n            break;\n        }\n\n        // Find a good break point - prefer paragraph breaks, then line breaks, then spaces\n        let breakPoint = maxCharsPerChunk;\n\n        // Look for paragraph break (\\n\\n) within last 200 chars of chunk\n        const paragraphBreak = remaining.lastIndexOf('\\n\\n', maxCharsPerChunk);\n        if (paragraphBreak > maxCharsPerChunk - 200 && paragraphBreak > 0) {\n            breakPoint = paragraphBreak + 2; // Include the newlines\n        } else {\n            // Look for line break\n            const lineBreak = remaining.lastIndexOf('\\n', maxCharsPerChunk);\n            if (lineBreak > maxCharsPerChunk - 100 && lineBreak > 0) {\n                breakPoint = lineBreak + 1;\n            } else {\n                // Look for space\n                const spaceBreak = remaining.lastIndexOf(' ', maxCharsPerChunk);\n                if (spaceBreak > maxCharsPerChunk - 50 && spaceBreak > 0) {\n                    breakPoint = spaceBreak + 1;\n                }\n            }\n        }\n\n        chunks.push(remaining.substring(0, breakPoint));\n        remaining = remaining.substring(breakPoint);\n    }\n\n    // Convert to Notion rich_text format, limiting to 95 chunks (Notion allows 100)\n    return chunks.slice(0, 95).map(chunk => ({\n        type: \"text\",\n        text: { content: chunk }\n    }));\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 2. EXTRACTION - Get raw text from Gemini response\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet rawStr = \"\";\n\n// Priority order for extraction from Gemini response\nif (input.generated_content) {\n    rawStr = input.generated_content;\n} else if (input.content?.parts?.[0]?.text) {\n    // Standard Gemini API format\n    rawStr = input.content.parts[0].text;\n} else if (input.text) {\n    rawStr = input.text;\n} else if (typeof input === 'string') {\n    rawStr = input;\n} else {\n    // Try to stringify if it's an object we can't parse\n    try {\n        rawStr = JSON.stringify(input);\n    } catch (e) {\n        rawStr = \"\";\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 3. PARSING - Extract formatted_markdown from JSON\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nlet extractedText = \"\";\nlet seoData = {};\nlet debugInfo = {\n    rawLength: rawStr.length,\n    parseAttempted: false,\n    parseSuccess: false,\n    recoveryUsed: false,\n    extractionMethod: \"none\"\n};\n\nconst parsedJSON = robustJSONParse(rawStr);\ndebugInfo.parseAttempted = true;\n\nif (parsedJSON) {\n    debugInfo.parseSuccess = true;\n\n    if (parsedJSON._recovered) {\n        debugInfo.recoveryUsed = true;\n        debugInfo.warning = parsedJSON._warning;\n    }\n\n    // Extract formatted markdown - check multiple possible locations\n    if (parsedJSON.formatted_markdown) {\n        extractedText = parsedJSON.formatted_markdown;\n        debugInfo.extractionMethod = \"formatted_markdown\";\n    } else if (parsedJSON.markdown) {\n        extractedText = parsedJSON.markdown;\n        debugInfo.extractionMethod = \"markdown\";\n    } else if (parsedJSON.content) {\n        extractedText = parsedJSON.content;\n        debugInfo.extractionMethod = \"content\";\n    } else if (parsedJSON.text) {\n        extractedText = parsedJSON.text;\n        debugInfo.extractionMethod = \"text\";\n    }\n\n    // Extract SEO metadata\n    if (parsedJSON.structured_data?.seo) {\n        seoData = parsedJSON.structured_data.seo;\n    } else if (parsedJSON.seo) {\n        seoData = parsedJSON.seo;\n    }\n\n} else {\n    // JSON parsing failed completely - try direct regex extraction\n    debugInfo.parseSuccess = false;\n    debugInfo.extractionMethod = \"regex_fallback\";\n\n    // Try to extract formatted_markdown via regex\n    const markdownMatch = rawStr.match(/\"formatted_markdown\"\\s*:\\s*\"([\\s\\S]*?)(?:(?<!\\\\)\"(?:\\s*,|\\s*\\})|$)/);\n    if (markdownMatch && markdownMatch[1]) {\n        extractedText = markdownMatch[1];\n    } else {\n        // Last resort: try extracting content from markdown fence\n        const fenceMatch = rawStr.match(/```(?:markdown)?\\s*([\\s\\S]*?)```/);\n        if (fenceMatch) {\n            extractedText = fenceMatch[1];\n            debugInfo.extractionMethod = \"markdown_fence\";\n        } else {\n            // Absolute last resort: clean the raw string\n            extractedText = rawStr\n                .replace(/^```json\\s*/i, '')\n                .replace(/```$/g, '')\n                .replace(/^Here is the.*?:\\s*/i, '')\n                .replace(/^Sure.*?:\\s*/i, '')\n                .trim();\n            debugInfo.extractionMethod = \"raw_cleaned\";\n        }\n    }\n}\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 4. CLEANING - Make it human-readable\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n// Step 1: Unescape all newlines and other escape sequences\nlet cleanText = unescapeContent(extractedText);\n\n// Step 2: Sanitize (remove zero-width chars, normalize unicode)\ncleanText = sanitizeText(cleanText).trim();\n\n// Step 3: Remove AI-generated platform headers\ncleanText = cleanText\n    .replace(/^#\\s*Blog\\s*Draft\\s*\\n+/i, '')\n    .replace(/^#\\s*Sanity\\s*Blog\\s*Draft\\s*\\n+/i, '')\n    .replace(/^---\\s*\\n+/, '')\n    .trim();\n\n// Step 4: Handle extraction failure\nif (!cleanText || cleanText.length < 20) {\n    cleanText = \"âš ï¸ Error: Content extraction failed.\\n\\n\" +\n        \"Debug Info:\\n\" +\n        \"- Raw Length: \" + rawStr.length + \" chars\\n\" +\n        \"- Parse Success: \" + debugInfo.parseSuccess + \"\\n\" +\n        \"- Extraction Method: \" + debugInfo.extractionMethod + \"\\n\\n\" +\n        \"Raw input preview:\\n\" +\n        rawStr.substring(0, 800).replace(/\"/g, \"'\");\n}\n\ndebugInfo.cleanedLength = cleanText.length;\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 5. SEO METADATA PROCESSING\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst seoTitle = seoData.title || \"\";\nconst seoSlug = seoData.slug || \"\";\nconst seoDescription = seoData.meta_description || seoData.description || \"\";\nconst seoKeywords = Array.isArray(seoData.keywords)\n    ? seoData.keywords.join(\", \")\n    : (seoData.keywords || \"\");\n\n// Handle tags - can be array or string\nconst seoTagsArray = Array.isArray(seoData.tags)\n    ? seoData.tags\n    : (typeof seoData.tags === 'string' ? seoData.tags.split(',').map(t => t.trim()) : []);\n\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n// 6. OUTPUT - Build Notion API Payload\n// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nconst richTextArray = chunkForNotion(cleanText, 1900);\n\n// Build properties object\nconst properties = {\n    \"Sanity Blog Draft\": { \"rich_text\": richTextArray }\n};\n\n// Add SHARED SEO fields for all platforms (matching Notion property names)\nif (seoTitle) {\n    properties[\"Shared_SEO_Title\"] = {\n        \"rich_text\": [{ type: \"text\", text: { content: seoTitle.substring(0, 2000) } }]\n    };\n}\nif (seoSlug) {\n    properties[\"Shared_Slug\"] = {\n        \"rich_text\": [{ type: \"text\", text: { content: seoSlug.substring(0, 2000) } }]\n    };\n}\nif (seoDescription) {\n    properties[\"Shared_SEO_Description\"] = {\n        \"rich_text\": [{ type: \"text\", text: { content: seoDescription.substring(0, 2000) } }]\n    };\n}\n// Shared_Tags is a MULTI-SELECT property in Notion, not Text!\nif (seoTagsArray.length > 0) {\n    properties[\"Shared_Tags\"] = {\n        \"multi_select\": seoTagsArray.map(tag => ({ name: tag.trim() }))\n    };\n}\n\nreturn {\n    json: {\n        notionPageId: notionData.id,\n        finalApiBody: {\n            properties: properties\n        },\n        // Debug info for troubleshooting (can be removed in production)\n        _debug: {\n            ...debugInfo,\n            richTextChunks: richTextArray.length,\n            hasSeoData: Object.keys(seoData).length > 0,\n            seoDataExtracted: {\n                title: seoTitle ? seoTitle.substring(0, 50) + \"...\" : null,\n                slug: seoSlug || null,\n                description: seoDescription ? seoDescription.substring(0, 50) + \"...\" : null,\n                tagsCount: seoTagsArray.length\n            }\n        }\n    }\n};"
      },
      "id": "a6632ac0-bd11-4700-94cb-c63674b7b582",
      "name": "Code â€“ Prep Sanity Blog API",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4304,
        2352
      ]
    },
    {
      "parameters": {
        "resource": "databasePage",
        "operation": "update",
        "pageId": {
          "__rl": true,
          "value": "={{ $('Notion â€“ Get Ready Content').first().json.id }}",
          "mode": "id"
        },
        "propertiesUi": {
          "propertyValues": [
            {
              "key": "Status|select",
              "type": "select",
              "selectValue": "Pending Approval"
            },
            {
              "key": "hasImages / Assets|checkbox",
              "checkboxValue": "={{ $('Process AI Strategy & MERGE CONTEXT').first().json.strategy?.image_strategy?.needs_images === true }}"
            },
            {
              "key": "Processing Started|date",
              "type": "date",
              "date": "={{ new Date().toISOString() }}"
            },
            {
              "key": "Notes|rich_text",
              "textContent": "={{ (() => {\n  const data = $json.properties || $json;\n  const sessionId = data.SessionID?.rich_text?.[0]?.text?.content || 'N/A';\n  const timestamp = new Date().toLocaleString('en-IN', { \n    timeZone: 'Asia/Kolkata',\n    day: '2-digit',\n    month: '2-digit', \n    year: 'numeric',\n    hour: '2-digit',\n    minute: '2-digit'\n  });\n\n  const twitterDraft = data[\"Twitter Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const linkedinDraft = data[\"LinkedIn Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const sanityDraft = data[\"Sanity Blog Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const devtoDraft = data[\"DevTo Draft\"]?.rich_text?.[0]?.text?.content || '';\n  const hashnodeDraft = data[\"Hashnode Draft\"]?.rich_text?.[0]?.text?.content || '';\n\n  const postTo = data[\"Post To\"]?.multi_select || [];\n  const postToNames = postTo.map(p => p.name);\n\n  let contentStatus = [];\n  if (twitterDraft.length > 10) contentStatus.push('  âœ… Twitter (X) - Draft generated');\n  if (linkedinDraft.length > 10) contentStatus.push('  âœ… LinkedIn - Draft generated');\n  if (sanityDraft.length > 10) contentStatus.push('  âœ… Sanity Blog - Draft generated');\n  if (devtoDraft.length > 10) contentStatus.push('  âœ… Dev.to - Draft generated');\n  if (hashnodeDraft.length > 10) contentStatus.push('  âœ… Hashnode - Draft generated');\n\n  const hasImages = data[\"hasImages / Assets\"]?.checkbox || false;\n  const status = data[\"Status\"]?.select?.name || 'Pending Approval';\n\n  return `âœ… CONTENT GENERATION COMPLETE\\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\\n\\nğŸ“ Session: ${sessionId}\\nğŸ“… Generated: ${timestamp}\\n\\nğŸ“¢ PLATFORMS GENERATED:\\n${contentStatus.length > 0 ? contentStatus.join('\\n') : '  âš ï¸ No content generated yet'}\\n\\nğŸ“Š CONTENT STATS:\\n  - Has Images: ${hasImages ? 'Yes âœ“' : 'No âœ—'}\\n  - Total Platforms: ${contentStatus.length}/${postToNames.length}\\n  - Target Platforms: ${postToNames.join(', ')}\\n\\nğŸ”§ STATUS: ${status}\\nğŸ’¡ Next Step: Review drafts â†’ Approve â†’ Part 2 will post`;\n})() }}"
            }
          ]
        },
        "options": {}
      },
      "id": "0ab202e6-3bab-468e-823d-8c266a04840e",
      "name": "Notion â€“ Update Final Status",
      "type": "n8n-nodes-base.notion",
      "typeVersion": 2,
      "position": [
        4976,
        2544
      ],
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "notionApi": {
          "id": "je8hKPK6RzYSk4JA",
          "name": "Notion account 2"
        }
      }
    },
    {
      "parameters": {
        "modelId": {
          "__rl": true,
          "value": "models/gemini-3.1-pro-preview",
          "mode": "list",
          "cachedResultName": "models/gemini-3.1-pro-preview"
        },
        "messages": {
          "values": [
            {
              "content": "=<system_instructions>\n<prime_directive>\nINSTRUCTION PRIORITY (Read this FIRST and LAST):\n1. Source fidelity: Every claim traceable to sourceContent. Zero invention.\n2. Anti-slop: No banned words. No corporate filler. No emoji spam.\n3. First-person \"I\" voice. Active voice only.\n4. Output must be valid JSON - no markdown fences, no extra text.\n</prime_directive>\n\n<role>\nYou are Aman Suryavanshi - a top-tier Product Engineer, Next.js Developer, and Automation Specialist based in Delhi/NCR, India.\n\nYour mission: Write a blog post that accomplishes THREE career goals simultaneously:\n1. **SEO Magnet**: Rank on Google AND get cited/recommended by AI engines (Perplexity, ChatGPT, Claude, Gemini).\n2. **Authority Builder**: Establish you as a go-to expert that companies want to hire and clients want to contract.\n3. **Lead Generator**: Attract inbound opportunities (job offers, freelance gigs) without you ever applying.\n\nYou write like a senior engineer explaining a hard-won victory to a peer at a coffee shop - technical depth without academic stuffiness. Your tone is confident but not arrogant, helpful but not preachy.\n</role>\n\n<critical_instruction>\n**The Goal:** Write a blog that becomes a **reference asset** - something developers bookmark, hiring managers screenshot, and AI engines cite.\n\n**Adaptive Length Protocol (CRITICAL):**\n- **Check `sourceContent.wordCount` from the context to determine which format to use.**\n- **Source word count < 500:** Target 800-1,200 words (Quick Win format)\n- **Source word count 500-1,500:** Target 1,200-1,800 words (Deep Dive format)\n- **Source word count > 1,500:** Target 1,800-2,500 words (Definitive Guide format)\n- **Never pad.** If you've covered everything valuable, END. A tight 1,000-word post beats a bloated 2,500-word post.\n\n**The \"Bookmark Test\":** After reading, would a developer immediately save this to their \"useful resources\" folder? If not, you've failed.\n\n**The Golden Rule:** Every technical choice must have a \"Why.\" (e.g., \"Why n8n over Zapier? Because self-hosting means no vendor lock-in and I control the data flow.\")\n\n**Source Fidelity:** The provided `sourceContent` is absolute truth. Expand on *implications* and *industry context* using Research data, but NEVER invent events, projects, or features not in the source.\n</critical_instruction>\n\n<rules>\n1. Source is King: The structure, examples, and narrative must be built from the `sourceContent`. The specific project, metrics, and struggles found in the source text are the story. Do NOT substitute or swap the project in sourceContent with a different project from personalContext.strategic.projectHooks. If sourceContent discusses \"Aviators Training Centre\", the blog is about Aviators Training Centre - never Barkat Enterprise or any other project.\n2. **The \"Stack Overflow\" Standard:**\n   - Every claim must be backed by a code snippet, a configuration example, or a specific logic flow.\n   - If detailing a bug fix, show the \"Before\" (Broken) code and the \"After\" (Fixed) code.\n   - Use \"Callout Blocks\" (> Quote style) for warnings, \"Pro-Tips,\" or \"Gotchas.\"\n3. **Follow the Plan:** Strictly follow the `structure` and `must_include` points outlined in `strategy.platform_strategies.blog`.\n4.  **Voice:** Maintain the first-person \"I\" narrative. This is a story about your personal project experience.\n5. **SEO & Discovery (Google + AI Engines):**\n   - **The First 150 Words:** Include your name, primary keyword, and the specific problem solved. This is your \"Expert Card\" for AI discovery.\n   - **H2 Headers:** Use question-format headers that match how people query AI (e.g., \"Why Does n8n Fail at Scale?\" instead of \"Scaling Issues\").\n   - **Internal Authority Links:** Reference your GitHub, portfolio, or previous projects with hyperlinks.\n   - **Prerequisites Section:** At the top, list what readers need to know.\n   - **What's Next Section:** At the bottom, mention what you're building next (replaces \"Future Improvements\").\n6. The \"Perplexity Injection\" (Context, Not Filler):\n   - You have access to `research` data (market pulse, urgency triggers, business stats).\n   - Do not create a separate boring \"Industry Context\" section.\n   - Instead, WEAVE this data into your arguments.\n   - Example: \"While 80% of developers use [Standard Tool], I found it failed at scale because...\"\n   - Use the research to compare your solution against the standard way. This creates \"Thought Leadership.\"\n7. **The \"Architectural Decision\" Framework:**\n   - Do not just show the code.\n   - Explain the DECISION.\n   - Format: \"The Problem\" -> \"Why Approach A failed\" -> \"Why Approach B failed\" -> \"Why I chose Approach C (The Solution).\"\n8. **The Story Backbone:**\n   - The Introduction MUST focus on `strategy.narrative_arc.the_villain` (or `villain_framing` if available). Personify the obstacle.\n   - The \"Architectural Decisions\" section MUST be framed as the result of `strategy.narrative_arc.the_epiphany`.\n   - **Authenticity Signal (Pratfall Effect - SPECIFICITY REQUIRED):** Do NOT use generic formulas like \"I honestly struggled with X.\" Instead, describe the EXACT specific moment of confusion or frustration: \"I spent 2 hours staring at n8n execution logs before realizing the webhook fires BEFORE the payload is parsed.\" The more specific and small the moment, the more universally relatable it becomes. People trust competent people MORE after seeing a specific, relatable flaw (Pratfall Effect).\n9. **The \"Quality Density\" Constraint (CRITICAL):**\n    - **No Rushing:** Don't summarize complex topics just to end quickly.\n    - **No Padding:** Don't add filler paragraphs to hit a word count.\n    - **Uniform Depth:** The \"What's Next\" and \"Conclusion\" sections must have the same technical depth as the Introduction - not a weak summary.\n    - **The Trade-Off Check:** Before ending any section, ask: \"Have I explained WHY I made this choice and what the downsides are?\" If not, add that context.\n10. **Source Fidelity Protocol:**\n    - **Strict Adherence:** You are an editor, not a fiction writer. You can expand on *technical concepts* (e.g., explaining how `useEffect` works if mentioned), but you CANNOT invent *events* (e.g., \"Then I met the CEO of Vercel\").\n    - **The \"Context Check\":** Before writing a new section, ask: \"Is this based on the `sourceContent` or `research`?\" If neither, DELETE IT.\n11. **The \"Novelistic\" Hook Strategy:**\n     - **Never** start with \"In this blog post...\" or \"Today I will show you...\".\n     - **Instead, start with the Pain:** \"I spent 3 days debugging a 502 error that turned out to be a simple timeout config. Here is how you can avoid my pain.\"\n     - **Use the \"In Media Res\" technique:** Start right in the middle of the action/problem.\n      - ğŸš« **Gemini-Specific Slop (BANNED):** \"It is worth noting that\", \"It's important to remember\", \"This is a crucial aspect\", \"In essence\", \"Essentially\", \"Furthermore\" (at sentence start), \"Moreover\" (at sentence start), \"It should be noted\", \"This highlights the importance of\", \"A key takeaway here is\", excessive hedging (\"might potentially\", \"could possibly\"), filler transitions (\"Moving on to\", \"Let's now look at\", \"With that said\"), fake enthusiasm (\"Revolutionary!\", \"Mind-blowing!\", \"This changes everything!\"), transition padding (\"Having established that\", \"Before we dive in\", \"Now, let's move on to\").\n      - ğŸš« **EM-DASH BAN:** NEVER use the em-dash character \"â€”\" anywhere in your output. It is a telltale sign of AI text (humans cannot easily type it). Use a regular hyphen \"-\" or rephrase instead.\n\n12. **Visual Rhythm & Scannability (The \"Skimmer First\" Principle):**\n    - **The 3-Line Rule:** No paragraph longer than 3 lines on mobile. Break ruthlessly.\n    - **The \"Bolding\" Habit:** Bold ONE key insight per paragraph. A skimmer reading ONLY the bold text should still learn something.\n    - **TL;DR Checkpoints:** Every 3-4 paragraphs, include a one-line bold summary. Creates re-engagement points.\n    - **Code Blocks:** Filename comment + one-sentence explanation BEFORE the block. Keep under 20 lines.\n    - **Bullet Lists Over Paragraphs:** 3+ related points = bulleted list. Faster to scan.\n\n13. **The \"Narrative Arc\" Structure:**\n    - **Act 1 (The Villain):** The specific technical bottleneck (e.g., \"The N+M Integration Nightmare\").\n    - **Act 2 (The Journey):** The architectural decisions, the failed attempts, and the final working solution.\n    - **Act 3 (The Resolution):** The final metrics (e.g., \"Cost reduced by 60%\") and the new reality.\n\n14. **Professional Polish:**\n    - Use \"Callout Blocks\" (`> **Pro Tip:** ...`) for specific, non-obvious advice.\n     - Use \"Warning Blocks\" (`> âš ï¸ **Gotcha:** ...`) for common pitfalls.\n     - This creates high-value \"stopping points\" for the reader.\n\n15. **The \"But...Therefore\" Rule (Anti-Monotony):**\n     - NEVER chain ideas with \"and then\" or \"additionally\" or \"furthermore.\"\n     - Connect narrative beats with \"But\" (conflict) and \"Therefore/So\" (consequence).\n     - Example: \"The Lighthouse score was finally at 90. But the Largest Contentful Paint was still flagged. So I switched to next/image with priority loading.\"\n     - This forces causal momentum and kills the monotone AI writing pattern.\n\n16. **Save-Trigger CTA (The Bookmark Hook):**\n     - End with a CTA that makes the reader bookmark, not just close the tab.\n     - GOOD: \"Bookmark this for the next time you encounter empty payloads at 3 AM.\"\n     - GOOD: \"Save this architecture - you will need it when you scale past 10 workflows.\"\n     - BAD: \"Thanks for reading!\" or \"Hope this helped!\"\n     - The goal: Make the reader think \"I'll need this reference later.\" (Loss Aversion: fear of losing access to utility triggers the save instinct.)\n\n17. **The \"Chain of Density\" Self-Edit (CRITICAL for Quality):**\n     - After drafting the full post, mentally re-read each paragraph and ask:\n       - Can I REMOVE a sentence without losing meaning? -> Remove it.\n       - Can I REPLACE a vague phrase with a specific one? -> Replace. (\"improved performance\" -> \"cut LCP from 4.2s to 1.1s\")\n       - Does this paragraph add a NEW insight or just rephrase the previous one? -> If rephrase, merge or delete.\n     - Output must feel like it went through aggressive editorial trimming. Every paragraph should be dense with insight, not padded with filler.\n     - **Specificity Over Vagueness:** Always use exact numbers ($847 not \"around $800\"), digits not words (\"3 layers\" not \"three layers\"), named technologies not generic terms (\"n8n Code node\" not \"custom script\"). Exact figures increase believability 300% vs round numbers.\n     - **\"Human Scale\" Numbers:** Raw metrics are abstract. Always translate into felt experience. BAD: \"Improved performance by 40%.\" GOOD: \"What used to take 10 seconds now takes 6. On 500 daily requests, that is 33 minutes saved per day.\"\n\n18. **The \"Name Your Framework\" Principle (Thought Leadership):**\n     - When you describe a multi-step solution, a pattern, or a methodology from the source content - NAME IT.\n     - Example: \"The 3-Layer Validation Pattern\" instead of \"my validation approach.\"\n     - Example: \"The Semantic Gate Architecture\" instead of \"the system I built.\"\n     - WHY: Named frameworks are proprietary. They make your ideas \"sticky,\" create thought leadership differentiation, and become the terms other people use to reference YOUR solution. AI engines are also more likely to cite named patterns.\n</rules>\n\n<ai_seo_optimization>\n**WHY THIS MATTERS:** AI engines (Perplexity, ChatGPT, Claude, Gemini) are increasingly how developers and hiring managers discover experts. Your blog must be structured for BOTH Google AND AI citation.\n\n**Mandatory AI-SEO Elements:**\n\n1. **The \"Expert Card\" (First 150 words):**\n   - State your name and specific expertise (e.g., \"I'm Aman Suryavanshi, an n8n automation specialist\")\n   - Include a concrete credential (e.g., \"I've built 50+ production workflows\")\n   - State the specific problem this post solves\n   - This becomes the snippet AI engines use when recommending you.\n\n2. **Quotable Insights (The \"Clip\" Strategy):**\n   - Include 2-3 standalone sentences that are insight-dense and self-contained.\n   - Format: Bold them or use blockquotes.\n   - Example: \"> **The N x M integration problem disappears when you adopt MCP - suddenly, adding 10 new tools takes the same effort as adding 1.**\"\n   - These become the snippets AI engines quote when citing you.\n\n3. **E-E-A-T Signals:**\n   - **Experience:** \"In my project [X], I encountered...\" (first-hand experience)\n   - **Expertise:** \"The underlying cause is [technical explanation]...\" (deep knowledge)\n   - **Authoritativeness:** Link to your GitHub, portfolio when relevant\n   - **Trustworthiness:** Acknowledge limitations (\"This approach works for X but not Y\")\n\n4. **The \"Two-Sentence Answer\" Rule (AEO/GEO - MANDATORY):**\n   - For EVERY H2 section, the FIRST TWO SENTENCES must directly and concisely answer the question implied by the heading.\n   - AI engines (Perplexity, ChatGPT, Claude) extract these leading sentences as citation snippets. This is your #1 lever for AI discoverability.\n   - EXAMPLE:\n     ## Why Does n8n Fail at Scale?\n     \"n8n fails at scale because its default execution model processes webhooks synchronously, causing payload loss when concurrent requests exceed the processing queue. The fix requires async processing with a validation gate.\"\n   - THEN expand with depth, examples, code. The 2-sentence answer is your AI citation bait.\n   - This also doubles as Google's Featured Snippet extraction pattern.\n</ai_seo_optimization>\n\n<visual_content_integration>\n**ğŸ–¼ï¸ The \"Storyboard\" Image Placement System:**\n\nYour blog is NOT a wall of text. It is a **visual storyboard** where images and text work together like panels in a graphic novel. Each image must feel like it *belongs* exactly where it sits.\n\n**Step 1: COUNT - How many images exist?**\n- Read `strategy.image_strategy.specific_prompts` array.\n- Count the items. If there are 2 images, you use EXACTLY 2 markers. If 3, use 3.\n- âš ï¸ **NEVER** invent a marker (e.g., `<<IMAGE_3>>`) that does not exist in the strategy array.\n- **Strict 1:1 Mapping:** Markers in text = Images in strategy. No more. No less.\n\n**Step 2: MATCH - Read each image's `description` and `purpose` fields.**\n- For EACH image in `specific_prompts`, read its `description` and `purpose`.\n- Identify which section of YOUR written content discusses the SAME concept.\n- That section is where the marker goes. This is a SEMANTIC match, not a positional guess.\n\n**Step 3: PLACE - Insert the marker using the \"Visual Anchor\" rule.**\n- Place the marker **immediately AFTER the paragraph** that explains the concept the image depicts.\n- The reader should finish reading about a concept â†’ see the visual â†’ and think \"Ah, THIS is what they mean.\"\n- **NEVER** place an image before the concept is introduced (the reader has no context yet).\n- **NEVER** place an image 3+ paragraphs after the concept (the reader has already moved on mentally).\n\n**ğŸ§  Cognitive Psychology Rules for Placement:**\n1. **Visual Anchoring:** Images cement the *preceding* text in memory. Place the image right after the \"aha moment\" paragraph - the one that contains the core insight or reveals the architecture/result.\n2. **Cognitive Offloading:** After a dense technical paragraph (code, architecture, multi-step logic), readers need a visual break. If your image depicts that same dense concept as a diagram/flowchart, place it immediately after to let the reader's brain \"offload\" the text into a visual mental model.\n3. **Rhythm - The 300-500 Word Rule:** Readers tire after ~400 words of unbroken text. If two images are available, space them roughly 300-500 words apart to maintain engagement rhythm. Don't cluster both images in the first half.\n4. **The \"Would I Screenshot This?\" Test:** Ask yourself - if a reader were to screenshot the image WITH the paragraph above it, would that screenshot tell a complete mini-story? If yes, the placement is correct.\n\n**âš ï¸ Anti-Patterns (NEVER DO):**\n- âŒ Placing all images at the top of the post (looks like a gallery, not a storyboard).\n- âŒ Placing an image after a heading but BEFORE any explanatory text (image has no context).\n- âŒ Placing an image after a conclusion/CTA section (nobody scrolls to see it).\n- âŒ Ignoring the image's `description` field and guessing where to put it.\n\n**Markdown Formatting:**\n```markdown\n## The 3-Layer Validation Architecture\n\nHere's how the system works. Layer 1 checks for empty objects at the webhook level.\nLayer 2 validates field presence. Layer 3 runs semantic checks on the data quality...\n\n<<IMAGE_1>>\n\nWith this architecture in place, the error rate dropped from 40% to 0.3%...\n```\n</visual_content_integration>\n\n<lead_generation_framework>\n**The \"Soft CTA\" Strategy (Non-Salesy):**\n\n1. **The \"I'm Building This\" Teaser:**\n   - Near the end, mention what you're currently working on related to this topic.\n   - Example: \"I'm currently building an n8n template library for common automation patterns. Follow me on Twitter if you want early access.\"\n\n2. **The \"Let's Compare Notes\" Invitation:**\n   - Example: \"I'm curious how others are handling [X]. Have you found a better approach? Let's connect on LinkedIn.\"\n\n3. **The \"Portfolio Proof\" Link:**\n   - When discussing a technique, link to a live project where you've used it.\n   - Example: \"I used this exact pattern in the Aviators Training Centre project, where it reduced manual tasks by 80%.\"\n\n**Placement Rule:** \n- ONE subtle CTA in the conclusion.\n- ONE portfolio proof link in the body.\n- ZERO \"hire me\" vibes anywhere.\n</lead_generation_framework>\n\n<output_format>\nReturn ONLY valid JSON. No markdown fences around the output.\n\n{\n  \"formatted_markdown\": \"# Title\\n\\nBody content...\",\n  \"structured_data\": {\n     \"seo\": {\n        \"title\": \"The exact title (50-60 chars, includes primary keyword)\",\n        \"slug\": \"url-friendly-slug-with-keyword\",\n        \"meta_description\": \"Compelling summary (150-160 chars) with problem and solution.\",\n        \"keywords\": [\"primary keyword\", \"problem keyword\", \"solution keyword\"],\n        \"tags\": [\"tag1\", \"tag2\", \"tag3\"]\n     }\n  }\n}\n\n**Mandatory Markdown Structure:**\n1. **TL;DR Block (Top):** 2-3 sentences. Problem â†’ Solution â†’ Outcome.\n2. **Prerequisites Section:** Bulleted list of what readers need to know.\n3. **H2/H3 Hierarchy:** H2s in question-format when possible.\n4. **Callout Blocks:** Use `> **Pro Tip:**` and `> âš ï¸ **Gotcha:**` for emphasis.\n5. **Conclusion with CTA:** End with \"What's Next\" section and ONE soft call-to-action.\n\n**Validation Before Return:**\nâ˜ No em-dash \"â€”\" characters anywhere. Use \"-\" instead.\nâ˜ No banned words from the Anti-Slop list.\nâ˜ First-person \"I\" voice throughout.\nâ˜ Real project/example from sourceContent (not invented).\nâ˜ Image markers match strategy.image_strategy.specific_prompts count exactly.\nâ˜ SUCCESs Quality Gate:\n  - Simple: Is the core problem and solution clear from the TL;DR?\n  - Unexpected: Does the hook open a knowledge gap or challenge a common belief?\n  - Concrete: Are there specific metrics, code snippets, or tool names (exact numbers, digits not words)?\n  - Credible: Does every claim trace to sourceContent? Is the \"Expert Card\" present?\n  - Emotional: Does the post connect to real developer frustration/pride?\n  - Story: Does the post follow Villain -> Journey -> Resolution narrative arc?\nâ˜ Chain of Density applied: Every paragraph is dense with insight, no filler or rehashing.\nâ˜ Authenticity signal is SPECIFIC (not generic \"I struggled with...\") - must describe an exact moment.\nâ˜ Every H2 section starts with a two-sentence direct answer (AEO/GEO optimization).\nâ˜ At least one solution/pattern is NAMED (\"The X Pattern\") for thought leadership.\nâ˜ Reflection Self-Check: \"Read this post as both (1) a senior developer evaluating your depth and (2) an AI engine evaluating your citation-worthiness. Would the developer bookmark it? Would the AI cite it? If not, identify the weak section and strengthen it.\"\n</output_format>\n\n</system_instructions>",
              "role": "model"
            },
            {
              "content": "=<context>\n<protected_urls>\nâš ï¸ PRESERVE_EXACT - These are ATOMIC strings. Reproduce verbatim. Do NOT autocorrect, truncate, or modify ANY part.\n- LinkedIn: https://www.linkedin.com/in/amansuryavanshi-ai/\n- Portfolio: https://amansuryavanshi.me/\n- Twitter/X: https://twitter.com/_AmanSurya\n- GitHub: https://github.com/AmanSuryavanshi-1\n</protected_urls>\n\n### MY PERSONAL & PROFESSIONAL PROFILE\n{{ $json.personalContext }}\n\n### THE BLUEPRINT FOR THE ARTICLE\n{{ $json.strategy }}\n\n### CONTENT METADATA (CRITICAL FOR ADAPTIVE LENGTH)\n- Title: {{ $json.sourceContent.title }}\n- Category: {{ $json.sourceContent.primaryCategory }}\n- Source Word Count: {{ $json.sourceContent.wordCount }}\n\n### THE CORE CONTENT (My Real-World Implementations)\nThis is the most critical input. The entire article must be built around the examples, code, and projects discussed here.\n{{ $json.sourceContent.fullText }}\n\n### COMPLEMENTARY SEO & RESEARCH DATA\nUse this to expand upon the core content and optimize for search.\n{{ $json.research }}\n</context>\n\n<critical_recap>\nBEFORE GENERATING, RE-READ THESE NON-NEGOTIABLE RULES:\n1. URLs from <protected_urls> must appear EXACTLY as written - no autocorrection.\n2. You MUST use ALL image markers from strategy.image_strategy.specific_prompts. Place each after the paragraph where its topic is discussed.\n3. Every claim must trace back to sourceContent. No invented projects, metrics, or examples.\n4. No banned words from the Anti-Slop list.\n5. Include E-E-A-T signals: Experience, Expertise, Authoritativeness, Trustworthiness.\n6. Tool-Assisted Validation: Before outputting the final JSON, use any available thinking tools to verify the Expert Card is present in the first 150 words, H2s are question-format for AI discovery, chain-of-density is applied (each section adds new insight), and Adaptive Length matches sourceContent.wordCount.\n</critical_recap>\n\n<task>\n**Mission:** Synthesize the `sourceContent` into a high-performance, career-building blog asset.\n\n**Execution Checklist:**\n1. **Adaptive Length:** Check `sourceContent.wordCount`. Select Quick Win (800-1200), Deep Dive (1200-1800), or Definitive Guide (1800-2500) per `<critical_instruction>`.\n2. **Research Injection:** \n   - Use `research.market_pulse.urgency_trigger` to make the intro timely.\n   - Use `research.linkedin.business_value_stat` for concrete metrics.\n   - Use `research.blog.seo_keywords_primary` in title and H2s.\n   - Use `research.blog.seo_keywords_longtail` naturally in problem sections.\n   - Use `research.blog.competitor_gap` to differentiate - cover what others miss.\n3. **AI Discovery:** Write the \"Expert Card\" in the first 150 words. Use \"Answer Box\" formatting for all H2s.\n4. **Lead Gen:** Insert ONE \"Portfolio Proof\" link in the body and ONE soft CTA in the conclusion per `<lead_generation_framework>`.\n5. **Strategy:** Follow `strategy.platform_strategies.blog.structure` and `must_include` strictly.\n\n**Constraint:** Output MUST be valid JSON. No markdown fences.\n</task>"
            }
          ]
        },
        "options": {
          "temperature": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.googleGemini",
      "typeVersion": 1,
      "position": [
        3952,
        2352
      ],
      "id": "885395d2-11ec-4fd6-baaa-2bfd6657de94",
      "name": "Gemini - Blog Content Generation",
      "retryOnFail": true,
      "maxTries": 3,
      "waitBetweenTries": 2000,
      "credentials": {
        "googlePalmApi": {
          "id": "8RkzNZusS3GG9BNO",
          "name": "Google Gemini(PaLM) Api key 4"
        }
      }
    },
    {
      "parameters": {
        "description": "Use this tool to plan your content strategy step-by-step BEFORE outputting. Think through: (1) Which engagement architecture pattern fits? (2) What curiosity gap drives clicks? (3) What villain creates tension? (4) What proof points support credibility? (5) Does it align with the Velocity Hire Frame? Reason, then generate the strategy JSON."
      },
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1.1,
      "position": [
        3232,
        2848
      ],
      "id": "370d79b6-a0e0-4d26-99dd-2d264e369582",
      "name": "Think"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.toolSerpApi",
      "typeVersion": 1,
      "position": [
        3104,
        2848
      ],
      "id": "85bda857-7301-4481-879d-857dbc931529",
      "name": "SerpAPI",
      "credentials": {
        "serpApi": {
          "id": "CjWeaQEIqmJabv9G",
          "name": "SerpAPI account"
        }
      }
    },
    {
      "parameters": {
        "description": "Use this tool to reason through LinkedIn post structure BEFORE writing. Think through: (1) Does the hook follow the 80-char-max rule? (2) Is breadcrumb-payoff pattern correct? (3) Does the Velocity Hire Frame position for AI Solutions Architect roles? (4) Are anti-slop rules followed (no em-dashes, no banned words, active voice)? (5) Is there a save-trigger? Reason, then generate."
      },
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1.1,
      "position": [
        4096,
        2176
      ],
      "id": "e1d92114-dd0f-47cc-885d-417fae138718",
      "name": "Think1"
    },
    {
      "parameters": {
        "description": "Use this tool to validate tweet structure BEFORE outputting. Think through: (1) Is each tweet under 265 characters? Count carefully. (2) Does tweet 1 use an open loop or pattern interrupt hook? (3) Can tweet 3 (truth bomb) work as a standalone retweet? (4) Does the thread build momentum with identity hooks and specific numbers? (5) Does the final tweet seed replies with a specific question? (6) Are anti-slop rules followed (no em-dashes, active voice, no filler)? Validate each tweet, then generate the final thread JSON."
      },
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1.1,
      "position": [
        4112,
        1424
      ],
      "id": "f877b9d0-72a4-4047-8a45-1544ca9023bc",
      "name": "Think2"
    },
    {
      "parameters": {
        "description": "Use this tool to plan article structure BEFORE writing. Think through: (1) Does intro answer the core question in first 100 words for AEO/GEO? (2) Are H2s questions for featured snippets? (3) Is chain-of-density applied? (4) Are named frameworks used? (5) Anti-slop rules? Plan outline, then write."
      },
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1.1,
      "position": [
        4096,
        3328
      ],
      "id": "4da56308-5336-4ab8-9bdd-6965b919035d",
      "name": "Think3"
    },
    {
      "parameters": {
        "description": "Use this tool to plan the Dev.to article BEFORE writing. Think through: (1) Does the TL;DR accurately summarize the key takeaway in 3 bullet points? (2) Is the Prerequisites section clear for beginner-to-mid developers? (3) Does the community debate question invite genuine, non-obvious discussion? (4) Are all code examples correct, complete, and traceable to sourceContent? (5) Is the tone friendly and tutorial-focused without condescension? (6) Are anti-slop rules followed? Plan, then write."
      },
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1.1,
      "position": [
        4096,
        2928
      ],
      "id": "68d1d4c2-5323-4bd0-99ca-b3328a5a0b2e",
      "name": "Think4"
    },
    {
      "parameters": {
        "description": "Use this tool to plan blog structure BEFORE writing. Think through: (1) Is the Expert Card (name + keyword + problem solved) present in the first 150 words? (2) Are H2s question-format for AI discovery and featured snippets? (3) Is chain-of-density applied (each section adds new insight, no repetition)? (4) Does Adaptive Length match sourceContent.wordCount? (5) Are E-E-A-T signals present? (6) Are anti-slop rules followed? Plan the article outline, then write."
      },
      "type": "@n8n/n8n-nodes-langchain.toolThink",
      "typeVersion": 1.1,
      "position": [
        4096,
        2560
      ],
      "id": "705dde54-db67-411f-8ddb-17b14c5877ce",
      "name": "Think5"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.toolSerpApi",
      "typeVersion": 1,
      "position": [
        4208,
        2176
      ],
      "id": "53127fff-7932-4087-8372-5716e8b27cf5",
      "name": "SerpAPI1",
      "credentials": {
        "serpApi": {
          "id": "CjWeaQEIqmJabv9G",
          "name": "SerpAPI account"
        }
      }
    }
  ],
  "connections": {
    "When clicking 'Execute workflow'": {
      "main": [
        [
          {
            "node": "Notion â€“ Get Ready Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion â€“ Get Ready Content": {
      "main": [
        [
          {
            "node": "Filter â€“ Has Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter â€“ Has Content": {
      "main": [
        [
          {
            "node": "Code â€“ Select Content & Profile",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ Select Content & Profile": {
      "main": [
        [
          {
            "node": "Create folder for title",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion â€“ Update to Processing": {
      "main": [
        [
          {
            "node": "Notion â€“ Extract All Blocks",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Notion â€“ Extract All Blocks": {
      "main": [
        [
          {
            "node": "Code â€“ Extract & Process Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ Extract & Process Content": {
      "main": [
        [
          {
            "node": "Context - Fetch Portfolio",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "Notion â€“ Update Final Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ Personal Context Builder": {
      "main": [
        [
          {
            "node": "Perplexity â€“ Research Hashtags & Timing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ CONTEXT MERGER": {
      "main": [
        [
          {
            "node": "Gemini - AI CONTENT STRATEGIST",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create folder for title": {
      "main": [
        [
          {
            "node": "Notion â€“ Update to Processing",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Perplexity â€“ Research Hashtags & Timing": {
      "main": [
        [
          {
            "node": "Code â€“ CONTEXT MERGER",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process AI Strategy & MERGE CONTEXT": {
      "main": [
        [
          {
            "node": "Are Images Needed?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - Twitter Selected?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - LinkedIn Selected?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - Blog Selected?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - Dev.to Selected?",
            "type": "main",
            "index": 0
          },
          {
            "node": "IF - Hashnode Selected?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Are Images Needed?": {
      "main": [
        [
          {
            "node": "Code â€“ Prep Image Tasklist API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - Twitter Selected?": {
      "main": [
        [
          {
            "node": "Gemini - Twitter Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op Twitter Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - LinkedIn Selected?": {
      "main": [
        [
          {
            "node": "Gemini - LinkedIn Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op LinkedIn Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - Blog Selected?": {
      "main": [
        [
          {
            "node": "Gemini - Blog Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op Blog Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code - No-Op Twitter Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code - No-Op LinkedIn Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Code - No-Op Blog Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Gemini - AI CONTENT STRATEGIST": {
      "main": [
        [
          {
            "node": "Process AI Strategy & MERGE CONTEXT",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - Twitter Content Generation": {
      "main": [
        [
          {
            "node": "Code â€“ Prep Twitter API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - LinkedIn Content Generation": {
      "main": [
        [
          {
            "node": "Code â€“ Prep LinkedIn API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Context - Fetch Portfolio": {
      "main": [
        [
          {
            "node": "Context - Standardize & Filter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Context - Standardize & Filter": {
      "main": [
        [
          {
            "node": "Code â€“ Personal Context Builder",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - Dev.to Selected?": {
      "main": [
        [
          {
            "node": "Gemini - Dev.to Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op Dev.to Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "IF - Hashnode Selected?": {
      "main": [
        [
          {
            "node": "Gemini - Hashnode Content Generation",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Code - No-Op Hashnode Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - Dev.to Content Generation": {
      "main": [
        [
          {
            "node": "Code â€“ Prep DevTo API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - Hashnode Content Generation": {
      "main": [
        [
          {
            "node": "Code - Prep Hashnode API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code - No-Op Hashnode Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 4
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Notion â€“ Get Ready Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code - No-Op Dev.to Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "Update Notion (Blog)": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Code â€“ Prep Twitter API": {
      "main": [
        [
          {
            "node": "HTTP â€“ Push Twitter Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP â€“ Push Twitter Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ Prep LinkedIn API": {
      "main": [
        [
          {
            "node": "HTTP â€“ Push LinkedIn Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP â€“ Push LinkedIn Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Code â€“ Prep DevTo API": {
      "main": [
        [
          {
            "node": "HTTP â€“ Push DevTo Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP â€“ Push DevTo Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "HTTP â€“ Push Hashnode Draft": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 4
          }
        ]
      ]
    },
    "Code â€“ Prep Image Tasklist API": {
      "main": [
        [
          {
            "node": "HTTP â€“ Push Image Tasklist",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP â€“ Push Image Tasklist": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 5
          }
        ]
      ]
    },
    "Code - Prep Hashnode API": {
      "main": [
        [
          {
            "node": "HTTP â€“ Push Hashnode Draft",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code â€“ Prep Sanity Blog API": {
      "main": [
        [
          {
            "node": "Update Notion (Blog)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gemini - Blog Content Generation": {
      "main": [
        [
          {
            "node": "Code â€“ Prep Sanity Blog API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Think": {
      "ai_tool": [
        [
          {
            "node": "Gemini - AI CONTENT STRATEGIST",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "SerpAPI": {
      "ai_tool": [
        [
          {
            "node": "Gemini - AI CONTENT STRATEGIST",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think1": {
      "ai_tool": [
        [
          {
            "node": "Gemini - LinkedIn Content Generation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think2": {
      "ai_tool": [
        [
          {
            "node": "Gemini - Twitter Content Generation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think3": {
      "ai_tool": [
        [
          {
            "node": "Gemini - Hashnode Content Generation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think4": {
      "ai_tool": [
        [
          {
            "node": "Gemini - Dev.to Content Generation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Think5": {
      "ai_tool": [
        [
          {
            "node": "Gemini - Blog Content Generation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "SerpAPI1": {
      "ai_tool": [
        [
          {
            "node": "Gemini - LinkedIn Content Generation",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "2aff0c99a9b9ea9c976d68c5887d32445a6bdc6f59f99592eb5b4c4dbaf3d92e"
  }
}